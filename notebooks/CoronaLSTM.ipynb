{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoronaBasic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htDHburyBuEe",
        "colab_type": "text"
      },
      "source": [
        "# Preliminary Analysis of CoronaVirus Time Series Data\n",
        "In this notebook we will conduct some preliminary analysis and forecasting on the Coronavirus time seires data. For this analysis we will look at \n",
        "\n",
        "**Warning this is a basic analysis/machine learning model. The goal of this notebook is to gage the utility of data augmentation/transfer learning for virus forecasting. NOT provide actionable insights. It would additional rounds of training/validation + verification by epidemiologists and public health experts before I would be confident relying on using it for any actionable insights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA1NxnWmHOAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/CoronaWhy/task-geo.git\n",
        "#!os.chdir('task-geo')\n",
        "import pandas as pd\n",
        "!wget -O coronavirus_timeseries.csv https://coronadatascraper.com/timeseries.csv\n",
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "from tensorflow import keras\n",
        "from wandb.keras import WandbCallback "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmOWKLuxHT7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"coronavirus_timeseries.csv\")\n",
        "df['month'] = pd.to_datetime(df['date']).map(lambda x: x.month)\n",
        "df['weekday'] = pd.to_datetime(df['date']).map(lambda x: x.weekday())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asrssixL6XZo",
        "colab_type": "code",
        "outputId": "34c73d99-c25c-42cf-f2e9-6772e83fa39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "unqiue_counties = df['county'].unique()\n",
        "print(len(unqiue_counties))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc189EXg6pfE",
        "colab_type": "text"
      },
      "source": [
        "## Forecasting in Antwerp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiJyk9YiHaOX",
        "colab_type": "code",
        "outputId": "1e881d25-e337-4f29-8444-2fe3e84a2044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "antwerp_df = df[df['county']=='Antwerp'].fillna(0)\n",
        "antwerp_relevant = antwerp_df[['cases', 'deaths', 'recovered', 'population', 'lat', 'long']].values\n",
        "antwerp_df['new_cases'] = antwerp_df.cases.diff()\n",
        "#antwerp_df.tail()\n",
        "print(len(antwerp_df))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlVWneL_CV3r",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation\n",
        "We will now explore using the tsaug library for forecasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1J98G13HbKM",
        "colab_type": "code",
        "outputId": "8d19cb85-b098-4cab-b433-27fcaa8a620e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "!pip install tsaug"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tsaug\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/6e/8b1be145a32bba360c14322c3b87ad93d6227c46528d482c84eefe54094b/tsaug-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.18.3)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.4.1)\n",
            "Installing collected packages: tsaug\n",
            "Successfully installed tsaug-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXNkSdTFvZ1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tsaug.visualization import plot \n",
        "from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse\n",
        "my_augmenter = (TimeWarp() * 5, # random time warping 5 times in parallel \n",
        "                Crop(size=300),  # random crop subsequences with length 300\n",
        "                Quantize(n_levels=[10, 20, 30]),  # random quantize to 10-, 20-, or 30- level sets\n",
        "                Drift(max_drift=(0.1, 0.5)),   # with 80% probability, random drift the signal up to 10% - 50%\n",
        "                Reverse()) #0.5  # with 50% probability, reverse the sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdVWNhk2XRJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_aug = my_augmenter[0].augment(antwerp_relevant)\n",
        "print(antwerp_relevant.shape)\n",
        "X_aug = TimeWarp(antwerp[:70])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A6ICggnYBlX",
        "colab_type": "text"
      },
      "source": [
        "## Models and Forecasting\n",
        "We will now define some simple models in Keras for forecasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO7ZOB41az1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler_dict = {}\n",
        "config_default = {\"epochs\":30, \"validation_split\":0.1, \n",
        "          \"loss\":\"mean_squared_error\", \"optimizer\":'adam', \n",
        "          \"geo_segment\":\"antwerp\", \"seq_len\":7, \"train_steps\":70, \n",
        "          \"test_steps\":27, \"scaler\":\"RobustScaler\", \"new_cases\":True, \n",
        "          \"beta\":0.899, \"additional_features\":[\"weekday\",\"month\"]}\n",
        "r = RobustScaler()\n",
        "x_train_full = antwerp_df[['deaths', 'new_cases']][1:config_default[\"train_steps\"]]\n",
        "x_train_full = pd.DataFrame(r.fit_transform(x_train_full))\n",
        "y_train_full = x_train_full\n",
        "r_test = RobustScaler()\n",
        "test_orig = antwerp_df[['deaths', 'new_cases']][70:]\n",
        "test = pd.DataFrame(r_test.fit_transform(test_orig))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUR6eM4MZZJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train, Y_train = create_dataset(x_train_full, y_train_full, config_default[\"seq_len\"])\n",
        "X_test, y_test = create_dataset(test, test, config_default[\"seq_len\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OOG9RAp4-ap",
        "colab_type": "code",
        "outputId": "d223f2bb-6963-4a28-a598-30b4aba67522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sweep_config = {\n",
        "  \"name\": \"Default sweep\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "        \"batch_size\": {\n",
        "            \"values\": [2, 3, 4, 5]\n",
        "        },\n",
        "        \"learn\":{\n",
        "            \"values\":[0.001, 0.0015, 0.002, 0.003, 0.004, 0.01]\n",
        "        } \n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"covid-forecast\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: wr9ke1l2\n",
            "Sweep URL: https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXhSxkqdYJbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def train():\n",
        "  run = wandb.init(project=\"covid-forecast\", config=config_default, magic=True)\n",
        "  config = wandb.config\n",
        "  opt = keras.optimizers.Adam(learning_rate=config[\"learn\"], beta_1=config[\"beta\"], beta_2=0.999, amsgrad=False)\n",
        "  model = keras.Sequential()\n",
        "  model.add(\n",
        "    keras.layers.Bidirectional(\n",
        "      keras.layers.LSTM(\n",
        "        units=128,\n",
        "        input_shape=(X_train.shape[1], X_train.shape[2])\n",
        "      )\n",
        "    )\n",
        "  ) \n",
        "  model.add(keras.layers.Dropout(rate=0.2))\n",
        "  model.add(keras.layers.Dense(units=2))\n",
        "  model.compile(loss=config[\"loss\"], optimizer=opt)\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train, Y_train,\n",
        "      epochs=config[\"epochs\"],\n",
        "      batch_size=config[\"batch_size\"],\n",
        "      validation_split=config[\"validation_split\"],\n",
        "      callbacks=[WandbCallback()],\n",
        "      shuffle=False\n",
        "  )\n",
        "  evaluate_single(model, X_test, y_test, r)\n",
        "  evaluate_plot_multi(model, test, config, X_test, r_test)\n",
        "  return model\n",
        "\n",
        "def evaluate_single(model, x_test, y_test, scaler):\n",
        "  y_preds = model.predict(x_test)\n",
        "  y_preds = scaler.inverse_transform(y_preds)\n",
        "  y_test = scaler.inverse_transform(y_test)\n",
        "  complete_mse = tf.keras.losses.MSE( y_preds[:, 1], y_test[:, 1])\n",
        "  wandb.run.summary[\"test_mse\"] = complete_mse\n",
        "  return complete_mse\n",
        "\n",
        "def evaluate_plot_multi(model, test_df, config, x_test, scaler, predictor=\"new_cases\"):\n",
        "  arr = predict_multi(model, len(test)-config[\"seq_len\"], x_test[0, :, :], config)\n",
        "  test_orig['predicted_cases'] = 0\n",
        "  test_orig['predicted_cases'][config[\"seq_len\"]:] = scaler.inverse_transform(arr.squeeze(0))[:, 1]\n",
        "  plt.plot(test_orig['predicted_cases'], label='predicted_cases')\n",
        "  plt.plot(test_orig[predictor], label='actual_cases')\n",
        "  plt.legend();\n",
        "  wandb.log({\"test\":plt})\n",
        "  large_mse = tf.keras.losses.MSE(\n",
        "    scaler.inverse_transform(arr.squeeze(0))[:, 1], test_orig[predictor][config[\"seq_len\"]:].values\n",
        "  )\n",
        "  wandb.run.summary[\"test_mse_full\"] =  large_mse\n",
        "  return large_mse\n",
        "\n",
        "def predict_multi(model, time_steps, start_rows, config):\n",
        "  start_rows=np.expand_dims(start_rows, axis=0)\n",
        "  for i in range(0, time_steps):\n",
        "    out = model.predict(start_rows[:, i:, :])\n",
        "    out = out[np.newaxis, ...]\n",
        "    start_rows = np.concatenate((start_rows, out), axis=1)\n",
        "  return start_rows[:, config[\"seq_len\"]:, :]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0N5tLiZB_IE",
        "colab_type": "code",
        "outputId": "ef823d2e-64bc-4e62-9141-d405bcd94d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wandb.agent(sweep_id, function=train)\n",
        "#train()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Starting Run: u33yh8mt with config:\n",
            "\tbatch_size: 2\n",
            "\tlearn: 0.004\n",
            "wandb: Agent Started Run: u33yh8mt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/u33yh8mt\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/u33yh8mt</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "28/28 [==============================] - 1s 30ms/step - loss: 0.3278 - val_loss: 1.4238\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3808 - val_loss: 5.9648\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4778 - val_loss: 2.5174\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1970 - val_loss: 3.3099\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.6696 - val_loss: 6.0359\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.2783 - val_loss: 1.4070\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.8616 - val_loss: 2.4664\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2483 - val_loss: 1.6853\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3473 - val_loss: 1.1395\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2407 - val_loss: 1.6316\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.8134 - val_loss: 1.2156\n",
            "Epoch 12/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5822 - val_loss: 2.8745\n",
            "Epoch 13/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2311 - val_loss: 1.4297\n",
            "Epoch 14/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3127 - val_loss: 2.2177\n",
            "Epoch 15/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3535 - val_loss: 1.5634\n",
            "Epoch 16/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4293 - val_loss: 3.3205\n",
            "Epoch 17/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.6892 - val_loss: 4.2995\n",
            "Epoch 18/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1.1820 - val_loss: 2.3132\n",
            "Epoch 19/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5106 - val_loss: 2.6022\n",
            "Epoch 20/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4863 - val_loss: 2.9951\n",
            "Epoch 21/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1842 - val_loss: 3.3665\n",
            "Epoch 22/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1675 - val_loss: 2.8430\n",
            "Epoch 23/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2192 - val_loss: 2.8625\n",
            "Epoch 24/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2719 - val_loss: 3.0325\n",
            "Epoch 25/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4808 - val_loss: 2.1584\n",
            "Epoch 26/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2263 - val_loss: 1.7779\n",
            "Epoch 27/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1612 - val_loss: 1.8862\n",
            "Epoch 28/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1130 - val_loss: 2.2479\n",
            "Epoch 29/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1278 - val_loss: 2.2741\n",
            "Epoch 30/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1287 - val_loss: 2.4841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: u33yh8mt \n",
            "\n",
            "wandb: Agent Starting Run: bj9t0goq with config:\n",
            "\tbatch_size: 2\n",
            "\tlearn: 0.01\n",
            "wandb: Agent Started Run: bj9t0goq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/bj9t0goq\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/bj9t0goq</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "28/28 [==============================] - 1s 30ms/step - loss: 0.3543 - val_loss: 1.0730\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5951 - val_loss: 1.4109\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2207 - val_loss: 1.0879\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.2546 - val_loss: 3.8373\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.5179 - val_loss: 7.5307\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5530 - val_loss: 1.4616\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3482 - val_loss: 1.5369\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4011 - val_loss: 4.9492\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4912 - val_loss: 1.8634\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2899 - val_loss: 1.5046\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5338 - val_loss: 3.1713\n",
            "Epoch 12/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2346 - val_loss: 1.3639\n",
            "Epoch 13/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2594 - val_loss: 2.0000\n",
            "Epoch 14/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3575 - val_loss: 5.4294\n",
            "Epoch 15/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3945 - val_loss: 5.3211\n",
            "Epoch 16/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2343 - val_loss: 3.5746\n",
            "Epoch 17/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3219 - val_loss: 2.6566\n",
            "Epoch 18/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2538 - val_loss: 4.9387\n",
            "Epoch 19/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3644 - val_loss: 3.4426\n",
            "Epoch 20/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1.0454 - val_loss: 2.3644\n",
            "Epoch 21/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2940 - val_loss: 5.1350\n",
            "Epoch 22/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4405 - val_loss: 2.7066\n",
            "Epoch 23/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2374 - val_loss: 2.0810\n",
            "Epoch 24/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2297 - val_loss: 2.4468\n",
            "Epoch 25/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2571 - val_loss: 1.8748\n",
            "Epoch 26/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2692 - val_loss: 2.5836\n",
            "Epoch 27/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2004 - val_loss: 1.6925\n",
            "Epoch 28/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1990 - val_loss: 1.2133\n",
            "Epoch 29/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2088 - val_loss: 1.2867\n",
            "Epoch 30/30\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3966 - val_loss: 1.3851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: bj9t0goq \n",
            "\n",
            "wandb: Agent Starting Run: delu7vhn with config:\n",
            "\tbatch_size: 3\n",
            "\tlearn: 0.001\n",
            "wandb: Agent Started Run: delu7vhn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/delu7vhn\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/delu7vhn</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 1.1287 - val_loss: 8.0629\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2785 - val_loss: 1.1660\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2821 - val_loss: 2.4080\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2845 - val_loss: 1.6744\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1416 - val_loss: 2.7434\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1368 - val_loss: 2.9579\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1440 - val_loss: 3.6001\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2218 - val_loss: 2.0980\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2681 - val_loss: 3.9575\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4438 - val_loss: 1.4085\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1325 - val_loss: 2.8689\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1242 - val_loss: 3.2897\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1277 - val_loss: 2.9258\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1831 - val_loss: 4.4455\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3527 - val_loss: 1.2499\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1344 - val_loss: 3.3264\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1221 - val_loss: 2.5812\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1337 - val_loss: 2.9828\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1461 - val_loss: 3.8647\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1782 - val_loss: 2.0856\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2022 - val_loss: 4.2463\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2230 - val_loss: 1.7696\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1253 - val_loss: 4.0953\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1074 - val_loss: 2.5590\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1160 - val_loss: 3.7426\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1510 - val_loss: 4.1797\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1015 - val_loss: 4.3849\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1174 - val_loss: 5.0730\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1721 - val_loss: 3.2596\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2089 - val_loss: 5.1246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: delu7vhn \n",
            "\n",
            "wandb: Agent Starting Run: lx2vriyn with config:\n",
            "\tbatch_size: 3\n",
            "\tlearn: 0.0015\n",
            "wandb: Agent Started Run: lx2vriyn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/lx2vriyn\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/lx2vriyn</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 0.8483 - val_loss: 4.4527\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1944 - val_loss: 1.5968\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2106 - val_loss: 2.4833\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3286 - val_loss: 4.0059\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2574 - val_loss: 3.3205\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2769 - val_loss: 3.3220\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.7183 - val_loss: 2.7914\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2338 - val_loss: 1.4173\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3161 - val_loss: 2.7968\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6033 - val_loss: 2.4767\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2423 - val_loss: 1.0304\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1696 - val_loss: 1.6887\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1486 - val_loss: 1.3295\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1407 - val_loss: 1.9717\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1315 - val_loss: 2.1037\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1318 - val_loss: 1.7935\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1869 - val_loss: 3.0809\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1547 - val_loss: 2.2008\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1888 - val_loss: 3.4672\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2647 - val_loss: 1.5165\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1957 - val_loss: 3.1391\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2797 - val_loss: 1.2972\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1435 - val_loss: 2.5356\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1782 - val_loss: 1.3357\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1250 - val_loss: 2.6742\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1198 - val_loss: 2.2977\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1314 - val_loss: 2.5137\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1484 - val_loss: 3.1410\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1458 - val_loss: 2.4223\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1254 - val_loss: 4.0392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: lx2vriyn \n",
            "\n",
            "wandb: Agent Starting Run: 4hku8e3i with config:\n",
            "\tbatch_size: 3\n",
            "\tlearn: 0.002\n",
            "wandb: Agent Started Run: 4hku8e3i\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/4hku8e3i\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/4hku8e3i</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 0.5665 - val_loss: 1.2880\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4381 - val_loss: 2.4584\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1542 - val_loss: 6.1686\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.3362 - val_loss: 1.2186\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3513 - val_loss: 1.7094\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.5798 - val_loss: 1.8284\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2038 - val_loss: 1.2891\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2673 - val_loss: 1.9303\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3543 - val_loss: 2.1465\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1809 - val_loss: 1.9081\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1532 - val_loss: 2.3001\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1747 - val_loss: 1.8481\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2888 - val_loss: 2.5039\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6830 - val_loss: 2.4937\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2697 - val_loss: 0.9712\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2091 - val_loss: 1.9148\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2246 - val_loss: 1.0030\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1618 - val_loss: 2.0031\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1062 - val_loss: 1.5868\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1447 - val_loss: 1.8379\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1557 - val_loss: 2.0484\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1848 - val_loss: 3.1175\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2710 - val_loss: 1.5623\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1681 - val_loss: 2.8965\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1645 - val_loss: 1.5717\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1725 - val_loss: 2.8978\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2539 - val_loss: 1.0658\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1297 - val_loss: 2.0981\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1168 - val_loss: 1.9608\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1554 - val_loss: 2.5493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 4hku8e3i \n",
            "\n",
            "wandb: Agent Starting Run: cmnpbbao with config:\n",
            "\tbatch_size: 3\n",
            "\tlearn: 0.003\n",
            "wandb: Agent Started Run: cmnpbbao\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/cmnpbbao\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/cmnpbbao</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.2693 - val_loss: 3.3635\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.0388 - val_loss: 2.7905\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3590 - val_loss: 1.5148\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.2042 - val_loss: 1.4703\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.3037 - val_loss: 9.1854\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.6360 - val_loss: 3.2153\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2179 - val_loss: 0.9314\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2478 - val_loss: 1.2822\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2657 - val_loss: 1.8484\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2859 - val_loss: 1.5838\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.5602 - val_loss: 1.8089\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2027 - val_loss: 1.4685\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1904 - val_loss: 1.7160\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1646 - val_loss: 1.7491\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1113 - val_loss: 2.1645\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1289 - val_loss: 2.7735\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0833 - val_loss: 2.4579\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1230 - val_loss: 3.0055\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1978 - val_loss: 2.2861\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4154 - val_loss: 2.5647\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8530 - val_loss: 3.8069\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3837 - val_loss: 1.2896\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2256 - val_loss: 1.0735\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1794 - val_loss: 0.9526\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1358 - val_loss: 1.6038\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1290 - val_loss: 1.5655\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1026 - val_loss: 2.1911\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1629 - val_loss: 2.5516\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1572 - val_loss: 3.7820\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4099 - val_loss: 1.1635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: cmnpbbao \n",
            "\n",
            "wandb: Agent Starting Run: qaog2hsf with config:\n",
            "\tbatch_size: 3\n",
            "\tlearn: 0.004\n",
            "wandb: Agent Started Run: qaog2hsf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/qaog2hsf\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/qaog2hsf</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.2395 - val_loss: 1.4781\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.6129 - val_loss: 3.0991\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.6777 - val_loss: 1.1703\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.3724 - val_loss: 10.2640\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.4791 - val_loss: 1.7233\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.4062 - val_loss: 1.1823\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9280 - val_loss: 4.0498\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2064 - val_loss: 0.9735\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2687 - val_loss: 1.3744\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7560 - val_loss: 2.1767\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1451 - val_loss: 1.0493\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1969 - val_loss: 1.6210\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1686 - val_loss: 1.2813\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1723 - val_loss: 1.7526\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1553 - val_loss: 1.2690\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2087 - val_loss: 1.9240\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3336 - val_loss: 1.3568\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2051 - val_loss: 1.6040\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2635 - val_loss: 1.2851\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1311 - val_loss: 1.7629\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1188 - val_loss: 1.3187\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1551 - val_loss: 1.8156\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1375 - val_loss: 2.5328\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1417 - val_loss: 1.9931\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1686 - val_loss: 2.6507\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4261 - val_loss: 1.2941\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1387 - val_loss: 1.5068\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1279 - val_loss: 1.4432\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1435 - val_loss: 1.8190\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1310 - val_loss: 2.3487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: qaog2hsf \n",
            "\n",
            "wandb: Agent Starting Run: duptwbki with config:\n",
            "\tbatch_size: 3\n",
            "\tlearn: 0.01\n",
            "wandb: Agent Started Run: duptwbki\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/duptwbki\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/duptwbki</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.2015 - val_loss: 5.4888\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.6910 - val_loss: 4.1745\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3735 - val_loss: 0.9214\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.7683 - val_loss: 1.1684\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4040 - val_loss: 5.5003\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.7018 - val_loss: 7.3694\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8904 - val_loss: 4.7936\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8416 - val_loss: 1.0151\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2784 - val_loss: 1.4060\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8567 - val_loss: 5.0541\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4483 - val_loss: 1.1033\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2902 - val_loss: 1.0749\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4000 - val_loss: 2.7343\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2430 - val_loss: 1.4123\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3301 - val_loss: 1.3338\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6815 - val_loss: 2.9387\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4645 - val_loss: 3.9209\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.6914 - val_loss: 0.8212\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.0695 - val_loss: 6.8909\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.2320 - val_loss: 4.4776\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2169 - val_loss: 0.9515\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1464 - val_loss: 1.4252\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1773 - val_loss: 1.6223\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.5473 - val_loss: 2.1038\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2478 - val_loss: 0.9272\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1979 - val_loss: 1.0188\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1680 - val_loss: 0.9527\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1268 - val_loss: 0.8985\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1968 - val_loss: 0.8746\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1597 - val_loss: 0.9185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: duptwbki \n",
            "\n",
            "wandb: Agent Starting Run: gy36nri0 with config:\n",
            "\tbatch_size: 4\n",
            "\tlearn: 0.001\n",
            "wandb: Agent Started Run: gy36nri0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/gy36nri0\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/gy36nri0</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "14/14 [==============================] - 1s 53ms/step - loss: 0.9404 - val_loss: 8.8658\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3729 - val_loss: 2.1394\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1794 - val_loss: 2.0115\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2050 - val_loss: 2.2766\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1689 - val_loss: 2.9002\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1715 - val_loss: 3.4101\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1431 - val_loss: 4.4963\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1673 - val_loss: 3.8386\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1924 - val_loss: 5.5678\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.3136 - val_loss: 1.7826\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2155 - val_loss: 3.2686\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2291 - val_loss: 5.4973\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3161 - val_loss: 1.5704\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1520 - val_loss: 2.9976\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1651 - val_loss: 4.9313\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1557 - val_loss: 2.9336\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1492 - val_loss: 4.4006\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1231 - val_loss: 4.1754\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1470 - val_loss: 4.7666\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1412 - val_loss: 4.3766\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1325 - val_loss: 6.1543\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1359 - val_loss: 5.2113\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1353 - val_loss: 6.4893\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1642 - val_loss: 5.0541\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1580 - val_loss: 7.7162\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2672 - val_loss: 2.9801\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1288 - val_loss: 7.1534\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1105 - val_loss: 4.6391\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1723 - val_loss: 6.4529\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1741 - val_loss: 3.6524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: gy36nri0 \n",
            "\n",
            "wandb: Agent Starting Run: zy7hknm1 with config:\n",
            "\tbatch_size: 4\n",
            "\tlearn: 0.0015\n",
            "wandb: Agent Started Run: zy7hknm1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/zy7hknm1\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/zy7hknm1</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "14/14 [==============================] - 1s 54ms/step - loss: 0.7442 - val_loss: 5.5942\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1975 - val_loss: 1.8293\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2240 - val_loss: 3.5854\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2734 - val_loss: 2.0237\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1629 - val_loss: 3.6444\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1751 - val_loss: 2.5402\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1776 - val_loss: 4.0712\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2155 - val_loss: 1.9195\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2047 - val_loss: 4.3661\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.2497 - val_loss: 1.6527\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1353 - val_loss: 3.4376\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1307 - val_loss: 3.1128\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1513 - val_loss: 3.5046\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1337 - val_loss: 3.5591\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1449 - val_loss: 4.2150\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1708 - val_loss: 3.0216\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2438 - val_loss: 5.3458\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4276 - val_loss: 1.7345\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1821 - val_loss: 3.1738\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2605 - val_loss: 4.8793\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3385 - val_loss: 1.5988\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1594 - val_loss: 2.6535\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1603 - val_loss: 4.0926\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1415 - val_loss: 2.7228\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1326 - val_loss: 3.7653\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1659 - val_loss: 4.0544\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1551 - val_loss: 3.2745\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1395 - val_loss: 5.0736\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1134 - val_loss: 3.9234\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1239 - val_loss: 5.5818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: zy7hknm1 \n",
            "\n",
            "wandb: Agent Starting Run: 1r62sdd8 with config:\n",
            "\tbatch_size: 4\n",
            "\tlearn: 0.002\n",
            "wandb: Agent Started Run: 1r62sdd8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/1r62sdd8\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/1r62sdd8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "14/14 [==============================] - 1s 54ms/step - loss: 0.5977 - val_loss: 3.8420\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2374 - val_loss: 2.3811\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3968 - val_loss: 2.0360\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1616 - val_loss: 2.2481\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1678 - val_loss: 2.3288\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1773 - val_loss: 2.5972\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2142 - val_loss: 3.7377\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.3344 - val_loss: 2.1355\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1873 - val_loss: 3.5599\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2937 - val_loss: 1.8848\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1798 - val_loss: 3.0229\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1989 - val_loss: 1.5734\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1712 - val_loss: 2.8835\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1892 - val_loss: 1.6515\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1797 - val_loss: 3.1916\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2026 - val_loss: 1.7274\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1747 - val_loss: 3.4200\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2257 - val_loss: 1.4488\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1562 - val_loss: 2.7046\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1463 - val_loss: 2.2833\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1326 - val_loss: 2.8092\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1349 - val_loss: 3.4420\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1317 - val_loss: 2.7760\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1891 - val_loss: 4.1227\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3124 - val_loss: 1.6900\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1522 - val_loss: 3.9069\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2155 - val_loss: 2.0569\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1699 - val_loss: 3.4099\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2011 - val_loss: 1.9076\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1648 - val_loss: 3.1494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 1r62sdd8 \n",
            "\n",
            "wandb: Agent Starting Run: db230yrs with config:\n",
            "\tbatch_size: 4\n",
            "\tlearn: 0.003\n",
            "wandb: Agent Started Run: db230yrs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/db230yrs\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/db230yrs</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.4601 - val_loss: 1.6519\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.5387 - val_loss: 2.8430\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1.2091 - val_loss: 12.2819\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6699 - val_loss: 5.7145\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.2522 - val_loss: 1.4329\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.3077 - val_loss: 1.5425\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.5424 - val_loss: 3.2421\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1787 - val_loss: 1.2868\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2496 - val_loss: 1.6732\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3045 - val_loss: 1.4938\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1732 - val_loss: 1.6414\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1593 - val_loss: 1.7426\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1250 - val_loss: 2.0204\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1547 - val_loss: 1.9956\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1795 - val_loss: 2.1759\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1711 - val_loss: 2.6995\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2030 - val_loss: 3.2391\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4151 - val_loss: 2.1407\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2004 - val_loss: 2.3645\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3078 - val_loss: 1.6231\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1762 - val_loss: 2.5142\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1766 - val_loss: 1.5036\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1872 - val_loss: 2.3964\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2215 - val_loss: 1.4442\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2042 - val_loss: 2.2793\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2367 - val_loss: 1.4092\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1537 - val_loss: 2.4151\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1798 - val_loss: 1.4193\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1763 - val_loss: 2.3700\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2710 - val_loss: 1.4231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: db230yrs \n",
            "\n",
            "wandb: Agent Starting Run: 2zqknxp3 with config:\n",
            "\tbatch_size: 4\n",
            "\tlearn: 0.004\n",
            "wandb: Agent Started Run: 2zqknxp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/2zqknxp3\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/2zqknxp3</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "14/14 [==============================] - 1s 54ms/step - loss: 0.2184 - val_loss: 3.9073\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.8295 - val_loss: 3.2717\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1.3000 - val_loss: 14.9642\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6727 - val_loss: 6.0099\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.2449 - val_loss: 1.2234\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3574 - val_loss: 1.9404\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.5883 - val_loss: 3.1866\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2710 - val_loss: 1.2408\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3533 - val_loss: 1.6927\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5189 - val_loss: 3.3240\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2850 - val_loss: 1.4548\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2035 - val_loss: 1.5629\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1708 - val_loss: 1.3520\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1686 - val_loss: 1.4436\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2202 - val_loss: 2.3550\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2348 - val_loss: 2.2122\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1717 - val_loss: 2.2577\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2029 - val_loss: 2.1958\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1564 - val_loss: 2.0526\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2391 - val_loss: 2.4763\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5696 - val_loss: 2.7583\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2251 - val_loss: 1.3337\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2180 - val_loss: 2.2694\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2712 - val_loss: 1.1517\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 1.7069\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1810 - val_loss: 1.5521\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1637 - val_loss: 1.9466\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1283 - val_loss: 2.4333\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1855 - val_loss: 1.7703\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2549 - val_loss: 2.5170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 2zqknxp3 \n",
            "\n",
            "wandb: Agent Starting Run: cfoqiz7p with config:\n",
            "\tbatch_size: 4\n",
            "\tlearn: 0.01\n",
            "wandb: Agent Started Run: cfoqiz7p\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/cfoqiz7p\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/cfoqiz7p</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "14/14 [==============================] - 1s 54ms/step - loss: 0.5207 - val_loss: 2.6388\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4701 - val_loss: 2.7450\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.8807 - val_loss: 1.9031\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1.0714 - val_loss: 10.6301\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2280 - val_loss: 3.6709\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8712 - val_loss: 1.8909\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.3802 - val_loss: 1.3614\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.8846 - val_loss: 6.8859\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.4383 - val_loss: 1.9668\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.4336 - val_loss: 1.0924\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.8335 - val_loss: 6.8928\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4931 - val_loss: 3.3045\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2355 - val_loss: 1.4047\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2217 - val_loss: 1.5911\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1788 - val_loss: 1.0011\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0857 - val_loss: 1.6128\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1459 - val_loss: 3.2384\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5066 - val_loss: 2.7508\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4582 - val_loss: 1.5457\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2598 - val_loss: 1.5039\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4488 - val_loss: 1.5826\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1987 - val_loss: 1.1844\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1790 - val_loss: 1.1027\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1062 - val_loss: 0.9862\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1424 - val_loss: 1.1152\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2960 - val_loss: 2.2811\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1927 - val_loss: 1.7787\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2246 - val_loss: 2.0085\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2919 - val_loss: 1.1970\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1770 - val_loss: 1.2486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: cfoqiz7p \n",
            "\n",
            "wandb: Agent Starting Run: omh2ipql with config:\n",
            "\tbatch_size: 5\n",
            "\tlearn: 0.001\n",
            "wandb: Agent Started Run: omh2ipql\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/omh2ipql\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/omh2ipql</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 0.9361 - val_loss: 14.7298\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5332 - val_loss: 6.5864\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2344 - val_loss: 1.7471\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1797 - val_loss: 1.4233\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1658 - val_loss: 1.3107\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1303 - val_loss: 1.4941\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1364 - val_loss: 2.4592\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1216 - val_loss: 2.0179\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1300 - val_loss: 3.0556\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1274 - val_loss: 2.5368\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1378 - val_loss: 3.1031\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1412 - val_loss: 4.1037\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1189 - val_loss: 2.9106\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1432 - val_loss: 5.4324\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2038 - val_loss: 1.7367\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1306 - val_loss: 4.2986\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0966 - val_loss: 4.2398\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1173 - val_loss: 4.1688\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1105 - val_loss: 3.7857\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1121 - val_loss: 4.2728\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1127 - val_loss: 4.7934\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0841 - val_loss: 4.8088\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0924 - val_loss: 5.1584\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1268 - val_loss: 4.1744\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1840 - val_loss: 6.3869\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3259 - val_loss: 1.4615\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1597 - val_loss: 2.4656\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1508 - val_loss: 5.5031\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1338 - val_loss: 2.2451\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1122 - val_loss: 3.5813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: omh2ipql \n",
            "\n",
            "wandb: Agent Starting Run: 04f07ygp with config:\n",
            "\tbatch_size: 5\n",
            "\tlearn: 0.0015\n",
            "wandb: Agent Started Run: 04f07ygp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/04f07ygp\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/04f07ygp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 0.7412 - val_loss: 10.3257\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2104 - val_loss: 1.5644\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2475 - val_loss: 1.9687\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2228 - val_loss: 1.6042\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1669 - val_loss: 1.1755\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1684 - val_loss: 1.7931\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1526 - val_loss: 1.3153\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1319 - val_loss: 1.8011\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1188 - val_loss: 2.2625\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1137 - val_loss: 2.0981\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1162 - val_loss: 2.8578\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1206 - val_loss: 2.9740\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0971 - val_loss: 3.8707\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1132 - val_loss: 4.4538\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1057 - val_loss: 3.9712\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2143 - val_loss: 5.0248\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5080 - val_loss: 3.6947\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3214 - val_loss: 1.6882\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1768 - val_loss: 1.8167\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1653 - val_loss: 2.9617\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1760 - val_loss: 1.4088\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1237 - val_loss: 2.5743\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1239 - val_loss: 3.0060\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1132 - val_loss: 3.2049\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0939 - val_loss: 3.5420\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0900 - val_loss: 3.6392\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1117 - val_loss: 4.8894\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0876 - val_loss: 4.6002\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0944 - val_loss: 4.5613\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1511 - val_loss: 5.7322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 04f07ygp \n",
            "\n",
            "wandb: Agent Starting Run: b4e0my1z with config:\n",
            "\tbatch_size: 5\n",
            "\tlearn: 0.002\n",
            "wandb: Agent Started Run: b4e0my1z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/b4e0my1z\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/b4e0my1z</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 0.6676 - val_loss: 7.4518\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1714 - val_loss: 1.3128\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2919 - val_loss: 3.1555\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4718 - val_loss: 3.9303\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3012 - val_loss: 2.1524\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1365 - val_loss: 1.1796\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1578 - val_loss: 1.5266\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1662 - val_loss: 1.2474\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1281 - val_loss: 1.5896\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1353 - val_loss: 1.7443\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1183 - val_loss: 1.9890\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1113 - val_loss: 2.2472\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1245 - val_loss: 2.3084\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1121 - val_loss: 2.9106\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1546 - val_loss: 1.6340\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1585 - val_loss: 3.1942\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2618 - val_loss: 1.2122\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1327 - val_loss: 1.9385\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1580 - val_loss: 2.8505\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1828 - val_loss: 1.2664\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1025 - val_loss: 2.6668\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1368 - val_loss: 2.9412\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1604 - val_loss: 1.6909\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1480 - val_loss: 3.2279\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1222 - val_loss: 2.0263\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1082 - val_loss: 3.1948\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1328 - val_loss: 2.5581\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1648 - val_loss: 4.2337\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1940 - val_loss: 1.5885\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0990 - val_loss: 3.4187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: b4e0my1z \n",
            "\n",
            "wandb: Agent Starting Run: 4rkd9ik5 with config:\n",
            "\tbatch_size: 5\n",
            "\tlearn: 0.003\n",
            "wandb: Agent Started Run: 4rkd9ik5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/4rkd9ik5\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/4rkd9ik5</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 0.3785 - val_loss: 1.9747\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4089 - val_loss: 3.1078\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7185 - val_loss: 8.9268\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5374 - val_loss: 6.2729\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2765 - val_loss: 2.6844\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2076 - val_loss: 1.1388\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1449 - val_loss: 1.1369\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1673 - val_loss: 1.4954\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1578 - val_loss: 1.3020\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1976 - val_loss: 2.2450\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3005 - val_loss: 2.3631\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1516 - val_loss: 1.7216\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1622 - val_loss: 2.1816\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2561 - val_loss: 1.2872\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1494 - val_loss: 1.6340\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1419 - val_loss: 1.2952\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0980 - val_loss: 1.6157\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1200 - val_loss: 1.8127\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1443 - val_loss: 2.0675\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1268 - val_loss: 2.1416\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2190 - val_loss: 3.0036\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4543 - val_loss: 3.6153\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2634 - val_loss: 1.8260\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1396 - val_loss: 1.1799\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1320 - val_loss: 1.3098\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1170 - val_loss: 1.3311\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1350 - val_loss: 1.8521\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1578 - val_loss: 1.1271\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1303 - val_loss: 1.8871\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1310 - val_loss: 1.6704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 4rkd9ik5 \n",
            "\n",
            "wandb: Agent Starting Run: ylcey6hh with config:\n",
            "\tbatch_size: 5\n",
            "\tlearn: 0.004\n",
            "wandb: Agent Started Run: ylcey6hh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/ylcey6hh\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/ylcey6hh</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 0.3361 - val_loss: 1.3225\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3535 - val_loss: 2.1306\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0301 - val_loss: 16.0047\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5704 - val_loss: 6.8321\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2138 - val_loss: 1.2487\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2707 - val_loss: 1.9733\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6265 - val_loss: 5.3584\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3100 - val_loss: 3.1095\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1704 - val_loss: 1.1494\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1887 - val_loss: 1.3607\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2357 - val_loss: 1.8652\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1196 - val_loss: 1.9732\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1727 - val_loss: 1.1567\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1744 - val_loss: 1.7997\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1857 - val_loss: 1.3393\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1248 - val_loss: 2.4004\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1851 - val_loss: 1.2193\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1431 - val_loss: 2.2595\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2648 - val_loss: 1.7512\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1298 - val_loss: 1.1162\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1867 - val_loss: 1.4770\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3380 - val_loss: 1.8882\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1205 - val_loss: 1.1071\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1881 - val_loss: 1.8589\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1867 - val_loss: 1.1089\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1139 - val_loss: 1.6465\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1051 - val_loss: 1.2637\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1095 - val_loss: 1.3133\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1970 - val_loss: 3.3464\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3868 - val_loss: 4.8122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: ylcey6hh \n",
            "\n",
            "wandb: Agent Starting Run: bxoqxfl8 with config:\n",
            "\tbatch_size: 5\n",
            "\tlearn: 0.01\n",
            "wandb: Agent Started Run: bxoqxfl8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/sweeps/wr9ke1l2</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/igodfried/covid-forecast/runs/bxoqxfl8\" target=\"_blank\">https://app.wandb.ai/igodfried/covid-forecast/runs/bxoqxfl8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.2129 - val_loss: 2.1111\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5392 - val_loss: 2.2634\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1196 - val_loss: 1.4064\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7789 - val_loss: 11.6041\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3985 - val_loss: 1.9234\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9716 - val_loss: 4.4841\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3247 - val_loss: 1.6685\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5282 - val_loss: 2.4927\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4430 - val_loss: 1.2346\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6177 - val_loss: 7.2011\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3147 - val_loss: 2.1609\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1975 - val_loss: 1.2088\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2742 - val_loss: 1.1961\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3427 - val_loss: 1.0607\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4858 - val_loss: 4.7283\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2680 - val_loss: 2.7643\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1948 - val_loss: 1.3055\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1551 - val_loss: 1.1652\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1321 - val_loss: 1.1878\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1283 - val_loss: 1.5523\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1099 - val_loss: 1.4711\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1838 - val_loss: 1.3352\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4007 - val_loss: 2.8147\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1730 - val_loss: 1.3742\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1217 - val_loss: 1.1377\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1630 - val_loss: 1.0662\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1291 - val_loss: 1.0472\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1389 - val_loss: 0.9865\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1092 - val_loss: 0.8874\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1036 - val_loss: 0.9470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: bxoqxfl8 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR_vweL-bOD1",
        "colab_type": "code",
        "outputId": "f6d40e8b-d959-48ff-85d9-d828cd00779b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 370,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPaMFelHjm-m",
        "colab_type": "text"
      },
      "source": [
        "### Examining Results\n",
        "We will now predict both one step ahead and 20 steps ahead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5zjK1JYf52W",
        "colab_type": "code",
        "outputId": "00fa37da-16a3-428d-bb6c-e6f10371bb94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "res = model.predict(X_test)\n",
        "res = r_test.inverse_transform(res)\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.1279370e-02,  2.0092883e+03],\n",
              "       [-1.8879963e-02,  2.2472920e+03],\n",
              "       [-1.6375745e-02,  2.5275439e+03],\n",
              "       [-1.3892809e-02,  2.8506108e+03],\n",
              "       [-1.1596879e-02,  3.1829221e+03],\n",
              "       [-9.0861954e-03,  3.5029392e+03],\n",
              "       [-6.4477865e-03,  3.7825161e+03],\n",
              "       [-3.6051013e-03,  4.0421055e+03],\n",
              "       [-1.2287628e-03,  4.2927124e+03],\n",
              "       [ 3.3153594e-04,  4.5448154e+03],\n",
              "       [ 1.1798348e-03,  4.7915127e+03],\n",
              "       [ 2.0689592e-03,  5.0360225e+03],\n",
              "       [ 3.3188127e-03,  5.2662153e+03],\n",
              "       [ 5.0343592e-03,  5.5053794e+03],\n",
              "       [ 6.5031778e-03,  5.7533242e+03],\n",
              "       [ 7.2021466e-03,  5.9751943e+03],\n",
              "       [ 7.6369299e-03,  6.1531494e+03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_9dG21n1bJC",
        "colab_type": "code",
        "outputId": "aee9ba88-9e6e-4ec8-ad2c-a114d299538a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "y_true = r_test.inverse_transform(y_test)\n",
        "y_true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0., 3521.],\n",
              "       [   0., 3822.],\n",
              "       [   0., 4086.],\n",
              "       [   0., 4179.],\n",
              "       [   0., 4265.],\n",
              "       [   0., 4330.],\n",
              "       [   0., 4470.],\n",
              "       [   0., 4645.],\n",
              "       [   0., 4855.],\n",
              "       [   0., 4965.],\n",
              "       [   0., 5028.],\n",
              "       [   0., 5079.],\n",
              "       [   0., 5241.],\n",
              "       [   0., 5415.],\n",
              "       [   0., 5449.],\n",
              "       [   0., 5449.],\n",
              "       [   0., 5449.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkob-4bnYdeT",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGXjVazoJ9i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import math\n",
        "from torch.nn.modules import Transformer, TransformerEncoder, TransformerDecoder, TransformerDecoderLayer, TransformerEncoderLayer, LayerNorm\n",
        "class CustomTransformerDecoder(torch.nn.Module):\n",
        "    def __init__(self, seq_length, output_seq_length, n_time_series, d_model=128, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.dense_shape = torch.nn.Linear(n_time_series, d_model)\n",
        "        self.pe = SimplePositionalEncoding(d_model)\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, 8)\n",
        "        encoder_norm = LayerNorm(d_model)\n",
        "        self.transformer_enc = TransformerEncoder(encoder_layer, 6, encoder_norm)\n",
        "        self.output_dim_layer = torch.nn.Linear(d_model, output_dim)\n",
        "        self.output_seq_length = output_seq_length\n",
        "        self.out_length_lay  = torch.nn.Linear(seq_length, output_seq_length)\n",
        "        self.mask = generate_square_subsequent_mask(seq_length)\n",
        "    def forward(self, x):\n",
        "        \"\"\"\"\"\"\n",
        "        x = self.dense_shape(x)\n",
        "        x = self.pe(x)\n",
        "        x = x.permute(1,0,2)\n",
        "        x = self.transformer_enc(x, mask=self.mask)\n",
        "        x = self.output_dim_layer(x)\n",
        "        x = x.permute(1, 2, 0)\n",
        "        x = self.out_length_lay(x)\n",
        "        return x.view(-1, self.output_seq_length)\n",
        "    \n",
        "class SimplePositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(SimplePositionalEncoding, self).__init__()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
        "        \"\"\"Creates a basic positional encoding\"\"\"\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "        \n",
        "def generate_square_subsequent_mask(sz:int)->torch.Tensor:\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK-U7-QhfP5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = CustomTransformerDecoder(50, 1, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtZbZ55tfe0i",
        "colab_type": "code",
        "outputId": "8e42b01b-303a-4fbf-f55e-217198c364e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "c(torch.rand(2, 50, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2974],\n",
              "        [-0.2575]], grad_fn=<ViewBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mFCWLbkktra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "class LSTMForecast(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A very simple baseline LSTM model that returns\n",
        "    an output sequence given a multi-dimensional input seq. Inspired by the StackOverflow link below.\n",
        "    https://stackoverflow.com/questions/56858924/multivariate-input-lstm-in-pytorch\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_length: int, n_time_series: int, output_seq_len=1, hidden_states:int=20, num_layers=2, bias=True, batch_size=100):\n",
        "        super().__init__()\n",
        "        self.forecast_history = seq_length\n",
        "        self.n_time_series = n_time_series\n",
        "        self.hidden_dim = hidden_states\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = torch.nn.LSTM(n_time_series, hidden_states, num_layers, bias, batch_first=True)\n",
        "        self.final_layer = torch.nn.Linear(seq_length*hidden_states, output_seq_len)\n",
        "        self.init_hidden(batch_size)\n",
        "    \n",
        "    def init_hidden(self, batch_size)->None:\n",
        "        # This is what we'll initialise our hidden state\n",
        "        self.hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_dim), torch.zeros(self.num_layers, batch_size, self.hidden_dim))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = x.size()[0]\n",
        "        self.init_hidden(batch_size)\n",
        "        out_x, self.hidden = self.lstm(x, self.hidden)\n",
        "        x = self.final_layer(out_x.contiguous().view(batch_size, -1))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjJ7nHlh8XM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m =LSTMForecast(20, 3, 1)\n",
        "y_pred = m(torch.rand(1, 20, 3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4h4nIWQ8wKV",
        "colab_type": "code",
        "outputId": "84a35acb-39c1-4907-b2a3-5212248b38db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "optimiser = torch.optim.Adam(m.parameters(), lr=.1)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "#####################\n",
        "# Train model\n",
        "#####################\n",
        "loss = loss_fn(y_pred, torch.rand(3,1))\n",
        "hist = loss.item()\n",
        "optimiser.zero_grad()\n",
        "loss.backward()\n",
        "optimiser.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOSSH6T49Ia5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}