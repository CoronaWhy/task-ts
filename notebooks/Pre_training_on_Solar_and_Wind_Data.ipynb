{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre training on Solar and Wind Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gbV7oPZaICl",
        "colab_type": "text"
      },
      "source": [
        "# Pretraining data from Wind and Solar data for Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUPB4tucl_pb",
        "colab_type": "code",
        "outputId": "a407fff8-0060-455a-e908-924537e09e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "from datetime import datetime\n",
        "auth.authenticate_user()\n",
        "!gcloud source repos clone github_aistream-peelout_flow-forecast --project=gmap-997\n",
        "os.chdir('/content/github_aistream-peelout_flow-forecast')\n",
        "!git checkout -t origin/covid_fixes\n",
        "!python setup.py develop\n",
        "!pip install -r requirements.txt\n",
        "!mkdir data\n",
        "from flood_forecast.trainer import train_function\n",
        "!pip install git+https://github.com/CoronaWhy/task-geo.git\n",
        "!wandb login 55c7382c4026d5d2ea3309d36986062e40c75387"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m Repository \"github_aistream-peelout_flow-forecast\" in project \"gmap-997\" is a mirror. Pushing to this clone will have no effect.  Instead, clone the mirrored repository directly with \n",
            "$ git clone https://github.com/AIStream-Peelout/flow-forecast\n",
            "Cloning into '/content/github_aistream-peelout_flow-forecast'...\n",
            "remote: Total 3769 (delta 2433), reused 3769 (delta 2433)\u001b[K\n",
            "Receiving objects: 100% (3769/3769), 2.68 MiB | 11.34 MiB/s, done.\n",
            "Resolving deltas: 100% (2433/2433), done.\n",
            "Project [gmap-997] repository [github_aistream-peelout_flow-forecast] was cloned to [/content/github_aistream-peelout_flow-forecast].\n",
            "Branch 'covid_fixes' set up to track remote branch 'covid_fixes' from 'origin'.\n",
            "Switched to a new branch 'covid_fixes'\n",
            "/usr/local/lib/python3.6/dist-packages/setuptools/dist.py:454: UserWarning: Normalizing '0.01dev' to '0.1.dev0'\n",
            "  warnings.warn(tmpl.format(**locals()))\n",
            "running develop\n",
            "running egg_info\n",
            "creating flood_forecast.egg-info\n",
            "writing flood_forecast.egg-info/PKG-INFO\n",
            "writing dependency_links to flood_forecast.egg-info/dependency_links.txt\n",
            "writing requirements to flood_forecast.egg-info/requires.txt\n",
            "writing top-level names to flood_forecast.egg-info/top_level.txt\n",
            "writing manifest file 'flood_forecast.egg-info/SOURCES.txt'\n",
            "package init file 'flood_forecast/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/transformer_xl/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/preprocessing/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/da_rnn/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/basic/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/custom/__init__.py' not found (or not a regular file)\n",
            "writing manifest file 'flood_forecast.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/flood-forecast.egg-link (link to .)\n",
            "Adding flood-forecast 0.1.dev0 to easy-install.pth file\n",
            "\n",
            "Installed /content/github_aistream-peelout_flow-forecast\n",
            "Processing dependencies for flood-forecast==0.1.dev0\n",
            "Searching for google-cloud\n",
            "Reading https://pypi.org/simple/google-cloud/\n",
            "Downloading https://files.pythonhosted.org/packages/ba/b1/7c54d1950e7808df06642274e677dbcedba57f75307adf2e5ad8d39e5e0e/google_cloud-0.34.0-py2.py3-none-any.whl#sha256=fb1ab7b0548fe44b3d538041f0a374505b7f990d448a935ea36649c5ccab5acf\n",
            "Best match: google-cloud 0.34.0\n",
            "Processing google_cloud-0.34.0-py2.py3-none-any.whl\n",
            "Installing google_cloud-0.34.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding google-cloud 0.34.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/google_cloud-0.34.0-py3.6.egg\n",
            "Searching for pandas==1.0.3\n",
            "Best match: pandas 1.0.3\n",
            "Adding pandas 1.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==2.2.0\n",
            "Best match: tensorflow 2.2.0\n",
            "Adding tensorflow 2.2.0 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.5.0+cu101\n",
            "Best match: torch 1.5.0+cu101\n",
            "Adding torch 1.5.0+cu101 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.4\n",
            "Best match: numpy 1.18.4\n",
            "Adding numpy 1.18.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.28.1\n",
            "Best match: grpcio 1.28.1\n",
            "Adding grpcio 1.28.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.10.0\n",
            "Best match: protobuf 3.10.0\n",
            "Adding protobuf 3.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.12.1\n",
            "Best match: wrapt 1.12.1\n",
            "Adding wrapt 1.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.9.0\n",
            "Best match: absl-py 0.9.0\n",
            "Adding absl-py 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==2.2.0\n",
            "Best match: tensorflow-estimator 2.2.0\n",
            "Adding tensorflow-estimator 2.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.3.3\n",
            "Best match: gast 0.3.3\n",
            "Adding gast 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.34.2\n",
            "Best match: wheel 0.34.2\n",
            "Adding wheel 0.34.2 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opt-einsum==3.2.1\n",
            "Best match: opt-einsum 3.2.1\n",
            "Adding opt-einsum 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==2.2.1\n",
            "Best match: tensorboard 2.2.1\n",
            "Adding tensorboard 2.2.1 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==46.1.3\n",
            "Best match: setuptools 46.1.3\n",
            "Adding setuptools 46.1.3 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.2.1\n",
            "Best match: Markdown 3.2.1\n",
            "Adding Markdown 3.2.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-auth==1.7.2\n",
            "Best match: google-auth 1.7.2\n",
            "Adding google-auth 1.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.6.0.post3\n",
            "Best match: tensorboard-plugin-wit 1.6.0.post3\n",
            "Adding tensorboard-plugin-wit 1.6.0.post3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.1\n",
            "Best match: google-auth-oauthlib 0.4.1\n",
            "Adding google-auth-oauthlib 0.4.1 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cachetools==3.1.1\n",
            "Best match: cachetools 3.1.1\n",
            "Adding cachetools 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for rsa==4.0\n",
            "Best match: rsa 4.0\n",
            "Adding rsa 4.0 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.4.5.1\n",
            "Best match: certifi 2020.4.5.1\n",
            "Adding certifi 2020.4.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.9\n",
            "Best match: idna 2.9\n",
            "Adding idna 2.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests-oauthlib==1.3.0\n",
            "Best match: requests-oauthlib 1.3.0\n",
            "Adding requests-oauthlib 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for oauthlib==3.1.0\n",
            "Best match: oauthlib 3.1.0\n",
            "Adding oauthlib 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for flood-forecast==0.1.dev0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.5.0+cu101)\n",
            "Collecting tb-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/2d/436a8addb5b16877281565bec361dae58bc62c30a0279f020532ff81753a/tb_nightly-2.3.0a20200511-py3-none-any.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.16.0)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/c9/ebbcefa6ef2ba14a7c62a4ee4415a5fecef8fac5e4d1b4e22af26fd9fe22/wandb-0.8.35-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas_gbq in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: google-cloud in /usr/local/lib/python3.6/dist-packages/google_cloud-0.34.0-py3.6.egg (from -r requirements.txt (line 9)) (0.34.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.18.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (3.13)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (0.14.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (1.6.0.post3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (46.1.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (0.34.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (1.28.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (1.7.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly->-r requirements.txt (line 4)) (1.12.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn->-r requirements.txt (line 5)) (3.2.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 7)) (7.352.0)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.7MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7e/19545324e83db4522b885808cd913c3b93ecc0c88b03e037b78c6a417fa8/sentry_sdk-0.14.3-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 39.2MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 7)) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydata-google-auth in /usr/local/lib/python3.6/dist-packages (from pandas_gbq->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas_gbq->-r requirements.txt (line 8)) (1.21.0)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->-r requirements.txt (line 10)) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->-r requirements.txt (line 10)) (0.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->-r requirements.txt (line 12)) (1.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly->-r requirements.txt (line 4)) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly->-r requirements.txt (line 4)) (2020.4.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 4)) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn->-r requirements.txt (line 5)) (2.4.7)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb->-r requirements.txt (line 7)) (2.3)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 4)) (0.4.8)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 10)) (1.51.0)\n",
            "Building wheels for collected packages: gql, watchdog, subprocess32, graphql-core, pathtools\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=5111d7bafc9f8d8ce07b170a6bfb8a10aa4c860e4a81d5cfd601775f8fe87217\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=6e92a2e5a9b9fa61ba948bde899941192f4b8aae34fc65f89835fadc02b3a5bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=28986a3b3dc35337e7c18da38eabf430dfc83ba5465b62cf745221ff839bed4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=2a15f4f8a256c2c08c77a56fa6ea7a7afcd0a736450729b9385c7977ea191c0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=4fd5d2e22818c87c01b275d04a2ed2d4f003a9e87e21b26b99977e955a4e7186\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built gql watchdog subprocess32 graphql-core pathtools\n",
            "Installing collected packages: tb-nightly, configparser, graphql-core, gql, shortuuid, pathtools, watchdog, sentry-sdk, smmap, gitdb, GitPython, docker-pycreds, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.2 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.3 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 tb-nightly-2.3.0a20200511 wandb-0.8.35 watchdog-0.10.2\n",
            "Collecting git+https://github.com/CoronaWhy/task-geo.git\n",
            "  Cloning https://github.com/CoronaWhy/task-geo.git to /tmp/pip-req-build-s5fml38v\n",
            "  Running command git clone -q https://github.com/CoronaWhy/task-geo.git /tmp/pip-req-build-s5fml38v\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from task-geo==0.1.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from task-geo==0.1.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from task-geo==0.1.0.dev0) (1.0.0)\n",
            "Collecting hdx-python-api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/32/7033d6d9ff01fd592ec649756f78460dc66640c1001f39c2d421037866f3/hdx_python_api-4.5.8-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->task-geo==0.1.0.dev0) (1.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->task-geo==0.1.0.dev0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->task-geo==0.1.0.dev0) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->task-geo==0.1.0.dev0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->task-geo==0.1.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->task-geo==0.1.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->task-geo==0.1.0.dev0) (2020.4.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->task-geo==0.1.0.dev0) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->task-geo==0.1.0.dev0) (7.5.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->task-geo==0.1.0.dev0) (5.2.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->task-geo==0.1.0.dev0) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->task-geo==0.1.0.dev0) (4.7.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->task-geo==0.1.0.dev0) (5.6.1)\n",
            "Collecting pyOpenSSL\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1 in /usr/local/lib/python3.6/dist-packages (from hdx-python-api->task-geo==0.1.0.dev0) (0.4.8)\n",
            "Collecting hdx-python-country>=2.5.6\n",
            "  Downloading https://files.pythonhosted.org/packages/24/45/684ec41e237b3e185c268b4ad4cd71581c3dfdb9c3e279d7777473edb8c2/hdx_python_country-2.5.6-py2.py3-none-any.whl\n",
            "Collecting ckanapi>=4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/07/c6/50449e18aaf1600dfda955805c58aa7462493511f3ebbb20d0a65874397c/ckanapi-4.3.tar.gz\n",
            "Collecting ndg-httpsclient\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
            "Collecting quantulum3>=0.7.3; python_version >= \"3\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/d5/60d72e7c9393199eba72f88deb06e0fddc4e357d600bdbe5f86e8cfc4512/quantulum3-0.7.3-py3-none-any.whl (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->task-geo==0.1.0.dev0) (1.12.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->task-geo==0.1.0.dev0) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->task-geo==0.1.0.dev0) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->task-geo==0.1.0.dev0) (2.1.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->task-geo==0.1.0.dev0) (5.3.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->task-geo==0.1.0.dev0) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->task-geo==0.1.0.dev0) (5.0.6)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->task-geo==0.1.0.dev0) (4.3.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->task-geo==0.1.0.dev0) (0.8.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->task-geo==0.1.0.dev0) (4.5.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->task-geo==0.1.0.dev0) (4.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->task-geo==0.1.0.dev0) (2.11.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->task-geo==0.1.0.dev0) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->task-geo==0.1.0.dev0) (19.0.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->task-geo==0.1.0.dev0) (1.9.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->task-geo==0.1.0.dev0) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->task-geo==0.1.0.dev0) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->task-geo==0.1.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->task-geo==0.1.0.dev0) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->task-geo==0.1.0.dev0) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->task-geo==0.1.0.dev0) (3.1.5)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 48.7MB/s \n",
            "\u001b[?25hCollecting libhxl>=4.19; python_version >= \"3\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/bb/7713720c382aad5260694fd5875fe013ee7ccef771e41a3298f661c01c84/libhxl-4.19.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n",
            "\u001b[?25hCollecting hdx-python-utilities>=2.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/0c/dd417c960de745a129d6c0cf63bb0215b179c29674e45ca041c75cf76baf/hdx_python_utilities-2.3.4-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ckanapi>=4.3->hdx-python-api->task-geo==0.1.0.dev0) (46.1.3)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from ckanapi>=4.3->hdx-python-api->task-geo==0.1.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: python-slugify>=1.0 in /usr/local/lib/python3.6/dist-packages (from ckanapi>=4.3->hdx-python-api->task-geo==0.1.0.dev0) (4.0.0)\n",
            "Collecting num2words\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.6/dist-packages (from quantulum3>=0.7.3; python_version >= \"3\"->hdx-python-api->task-geo==0.1.0.dev0) (2.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->task-geo==0.1.0.dev0) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->task-geo==0.1.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->task-geo==0.1.0.dev0) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->task-geo==0.1.0.dev0) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->task-geo==0.1.0.dev0) (0.1.9)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->task-geo==0.1.0.dev0) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->task-geo==0.1.0.dev0) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->task-geo==0.1.0.dev0) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->task-geo==0.1.0.dev0) (20.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->task-geo==0.1.0.dev0) (0.5.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyOpenSSL->hdx-python-api->task-geo==0.1.0.dev0) (1.14.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (from libhxl>=4.19; python_version >= \"3\"->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.1.0)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 41.8MB/s \n",
            "\u001b[?25hCollecting python-io-wrapper\n",
            "  Downloading https://files.pythonhosted.org/packages/76/81/88e02bc603e55883a087811a641fd3836749b7509365778fea29d74fd58c/python-io-wrapper-0.1.tar.gz\n",
            "Collecting jsonpath_rw\n",
            "  Downloading https://files.pythonhosted.org/packages/71/7c/45001b1f19af8c4478489fbae4fc657b21c4c669d7a5a036a86882581d85/jsonpath-rw-1.4.0.tar.gz\n",
            "Collecting ply\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (4.6.3)\n",
            "Collecting sshtunnel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/5c/4b320d7ec4b0d5d4d6df1fdf66a5799625b3623d0ce4efe81719c6f8dfb3/sshtunnel-0.1.5.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting ratelimit\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/38/ff60c8fc9e002d50d48822cc5095deb8ebbc5f91a6b8fdd9731c87a147c9/ratelimit-2.2.1.tar.gz\n",
            "Collecting email-validator\n",
            "  Downloading https://files.pythonhosted.org/packages/45/54/1a1da475b684aa4eb30da169ea5ebd9341a5d3138138bc2b365222b9ac87/email_validator-1.1.0-py2.py3-none-any.whl\n",
            "Collecting psycopg2-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/8a/a7ed55c2c55bd4f5844d72734fedc0cef8a74518a0a19105a21c15628f1e/psycopg2_binary-2.8.5-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.1MB/s \n",
            "\u001b[?25hCollecting pyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Collecting basicauth\n",
            "  Downloading https://files.pythonhosted.org/packages/76/47/08d21ffcc837bebf3306b8295f5d179f9bc498f6235ebf4a4e38be57839c/basicauth-0.4.1-py2.py3-none-any.whl\n",
            "Collecting yamlloader\n",
            "  Downloading https://files.pythonhosted.org/packages/93/a2/2f0c2394af1559021703c8cbb1bc7419bb5a94ea6bde0ab8cd1e973bb605/yamlloader-0.5.5-py3-none-any.whl\n",
            "Collecting tabulator[cchardet]>=1.42.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/9e/d2d48d773caa6cb8a8092695ccd25e08e2e13053baf3fe6195e8a4a54874/tabulator-1.44.2-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/00/0d/22c73c2eccb21dd3498df7d22c0b1d4a30f5a5fb3feb64e1ce06bc247747/colorlog-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify>=1.0->ckanapi>=4.3->hdx-python-api->task-geo==0.1.0.dev0) (1.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->jupyter->task-geo==0.1.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyOpenSSL->hdx-python-api->task-geo==0.1.0.dev0) (2.20)\n",
            "Collecting paramiko>=1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/1e/1e08baaaf6c3d3df1459fd85f0e7d2d6aa916f33958f151ee1ecc9800971/paramiko-2.7.1-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 44.6MB/s \n",
            "\u001b[?25hCollecting dnspython>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d3/3aa0e7213ef72b8585747aa0e271a9523e713813b9a20177ebe1e939deb0/dnspython-1.16.0-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (3.13)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.6/dist-packages (from tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (7.1.2)\n",
            "Collecting ijson>=3.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/82/03c325c85196744658c6d095c1e90dbd408595c596fc136b2157b2edaa10/ijson-3.0.4-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[?25hCollecting linear-tsv>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/82/e5/03207a0f11e1d60df85b97b61704ed701b725a7c2feaf83f7bfbd0c2d83e/linear-tsv-1.1.0.tar.gz\n",
            "Collecting jsonlines>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Collecting openpyxl>=2.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8c/83563c60489954e5b80f9e2596b93a68e1ac4e4a730deb1aae632066d704/openpyxl-3.0.3.tar.gz (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 44.2MB/s \n",
            "\u001b[?25hCollecting unicodecsv>=0.14\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
            "Requirement already satisfied: sqlalchemy>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.3.16)\n",
            "Requirement already satisfied: boto3>=1.9 in /usr/local/lib/python3.6/dist-packages (from tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.13.4)\n",
            "Collecting cchardet>=2.0; extra == \"cchardet\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c5/7e1a0d7b4afd83d6f8de794fce82820ec4c5136c6d52e14000822681a842/cchardet-2.1.6-cp36-cp36m-manylinux2010_x86_64.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 45.2MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/1d/82826443777dd4a624e38a08957b975e75df859b381ae302cfd7a30783ed/bcrypt-3.1.7-cp34-abi3-manylinux1_x86_64.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl>=2.6->tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl>=2.6->tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.9->tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.9->tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (1.16.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.9->tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3>=1.9->tabulator[cchardet]>=1.42.0->hdx-python-utilities>=2.3.4->hdx-python-country>=2.5.6->hdx-python-api->task-geo==0.1.0.dev0) (0.15.2)\n",
            "Building wheels for collected packages: task-geo, ckanapi, libhxl, python-io-wrapper, jsonpath-rw, sshtunnel, ratelimit, linear-tsv, openpyxl, unicodecsv\n",
            "  Building wheel for task-geo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for task-geo: filename=task_geo-0.1.0.dev0-py2.py3-none-any.whl size=177461 sha256=ea54ccf5efce98c84a7fcec707acf31bb784c0a7b9a9b803e08f69a4a94934d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5e1ghnf7/wheels/4f/c4/a4/33f04d80a745ae3ff088cae6f8cda3b46c48e007585d9ff0bf\n",
            "  Building wheel for ckanapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ckanapi: filename=ckanapi-4.3-cp36-none-any.whl size=38647 sha256=ac4004b6293304c85973521905798d6c422379cc87d31ede9bc78af1192fcb67\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/f2/fb/c8ce857007de64cc6b36b8f1048272396bc0817c35ee3a3e73\n",
            "  Building wheel for libhxl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libhxl: filename=libhxl-4.19-cp36-none-any.whl size=81540 sha256=dddde4a3fa0c904a3aecfb32be0f67a02169979b1109da15f1823a0f13f0eb84\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/4e/75/2c1d5d8cd3c34a42dcd9a388562d3dd3fb2197adbb47e20503\n",
            "  Building wheel for python-io-wrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-io-wrapper: filename=python_io_wrapper-0.1-cp36-none-any.whl size=2490 sha256=86c046bde3046bdefad21becbdc223cc20a5defbcce4dcd61ef866c6d5a7a204\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/26/be/da3c0a774901c557a0bee985e7aade5b9db75fe4dc8ef99ced\n",
            "  Building wheel for jsonpath-rw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpath-rw: filename=jsonpath_rw-1.4.0-cp36-none-any.whl size=15146 sha256=37d9a3b0ef8a14d580aa92d0b83462768cbad147b01ba50833076a1c6f02f445\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/00/9a/82822db383c2d96dcebf839786665a185f92d37e5026f9806f\n",
            "  Building wheel for sshtunnel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sshtunnel: filename=sshtunnel-0.1.5-py2.py3-none-any.whl size=23243 sha256=59afd9b0cd1e0304276791376f775990ee56bad96d518cab1367803e3493b37b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/d2/38/b9791b7391f634099194ec6697fa671194f3353906d94c8f92\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-cp36-none-any.whl size=5893 sha256=96f542b23eeb26ee6abae9ff17a4ec2e56c989ab0d00e0704f7f932f6231a3ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/d9/82/3c6044cf1a54aab9151612458446d9b17a38416869e1b1d9b8\n",
            "  Building wheel for linear-tsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for linear-tsv: filename=linear_tsv-1.1.0-cp36-none-any.whl size=7383 sha256=067483241115ecc402f0948c34ab86a5e01151d8677256d714e5b37b3db8969f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/8a/cb/38917fd1ef4356b9870ace7331b83417dc594bf2c029bd991f\n",
            "  Building wheel for openpyxl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openpyxl: filename=openpyxl-3.0.3-py2.py3-none-any.whl size=241262 sha256=d735ef888c526c43dfeec1b5a5656a590c58c73465d3d06c3d211f756ad6c755\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/85/ca/e768ac132e57e75e645a151f8badac71cc0089e7225dddf76b\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp36-none-any.whl size=10768 sha256=e225bb71d10091eb9476ac9a10d330a03e53677df981a69e092bee5a87f5db1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
            "Successfully built task-geo ckanapi libhxl python-io-wrapper jsonpath-rw sshtunnel ratelimit linear-tsv openpyxl unicodecsv\n",
            "\u001b[31mERROR: hdx-python-utilities 2.3.4 has requirement six>=1.14.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cryptography, pyOpenSSL, unidecode, python-io-wrapper, ply, jsonpath-rw, libhxl, bcrypt, pynacl, paramiko, sshtunnel, ratelimit, dnspython, email-validator, psycopg2-binary, pyaml, basicauth, yamlloader, ijson, linear-tsv, jsonlines, openpyxl, unicodecsv, cchardet, tabulator, colorlog, hdx-python-utilities, hdx-python-country, ckanapi, ndg-httpsclient, num2words, quantulum3, hdx-python-api, task-geo\n",
            "  Found existing installation: openpyxl 2.5.9\n",
            "    Uninstalling openpyxl-2.5.9:\n",
            "      Successfully uninstalled openpyxl-2.5.9\n",
            "Successfully installed basicauth-0.4.1 bcrypt-3.1.7 cchardet-2.1.6 ckanapi-4.3 colorlog-4.1.0 cryptography-2.9.2 dnspython-1.16.0 email-validator-1.1.0 hdx-python-api-4.5.8 hdx-python-country-2.5.6 hdx-python-utilities-2.3.4 ijson-3.0.4 jsonlines-1.2.0 jsonpath-rw-1.4.0 libhxl-4.19 linear-tsv-1.1.0 ndg-httpsclient-0.5.1 num2words-0.5.10 openpyxl-3.0.3 paramiko-2.7.1 ply-3.11 psycopg2-binary-2.8.5 pyOpenSSL-19.1.0 pyaml-20.4.0 pynacl-1.3.0 python-io-wrapper-0.1 quantulum3-0.7.3 ratelimit-2.2.1 sshtunnel-0.1.5 tabulator-1.44.2 task-geo-0.1.0.dev0 unicodecsv-0.14.1 unidecode-1.1.1 yamlloader-0.5.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "751Oa4ZvfTei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0c83945f-52e2-4eb5-8a07-754cc48de017"
      },
      "source": [
        "# Get wind data\n",
        "!wget https://storage.googleapis.com/coronaviruspublicdata/forecast_2/wind.csv\n",
        "!wget https://storage.googleapis.com/coronaviruspublicdata/forecast_2/solar.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-11 17:04:48--  https://storage.googleapis.com/coronaviruspublicdata/forecast_2/wind.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c0d::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4936771 (4.7M) [text/csv]\n",
            "Saving to: ‘wind.csv’\n",
            "\n",
            "\rwind.csv              0%[                    ]       0  --.-KB/s               \rwind.csv            100%[===================>]   4.71M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-05-11 17:04:49 (55.2 MB/s) - ‘wind.csv’ saved [4936771/4936771]\n",
            "\n",
            "--2020-05-11 17:04:52--  https://storage.googleapis.com/coronaviruspublicdata/forecast_2/solar.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 2607:f8b0:400c:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6156494 (5.9M) [text/csv]\n",
            "Saving to: ‘solar.csv’\n",
            "\n",
            "solar.csv           100%[===================>]   5.87M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-05-11 17:04:52 (180 MB/s) - ‘solar.csv’ saved [6156494/6156494]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz2yLFM3jwG_",
        "colab_type": "text"
      },
      "source": [
        "## Pre training on Wind Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1JfuXFghPEr",
        "colab_type": "code",
        "outputId": "9378a757-217d-426d-dce5-26f07e7f299b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "import pandas as pd\n",
        "wind = pd.read_csv('wind.csv')\n",
        "wind['datetime'] = pd.to_datetime(wind['time']).dt.date\n",
        "wind.set_index('datetime', drop=False)\n",
        "wind.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>AT</th>\n",
              "      <th>BE</th>\n",
              "      <th>BG</th>\n",
              "      <th>CH</th>\n",
              "      <th>CZ</th>\n",
              "      <th>DE</th>\n",
              "      <th>DK</th>\n",
              "      <th>EE</th>\n",
              "      <th>ES</th>\n",
              "      <th>FI</th>\n",
              "      <th>FR</th>\n",
              "      <th>EL</th>\n",
              "      <th>HR</th>\n",
              "      <th>HU</th>\n",
              "      <th>IE</th>\n",
              "      <th>IT</th>\n",
              "      <th>LT</th>\n",
              "      <th>LU</th>\n",
              "      <th>LV</th>\n",
              "      <th>NL</th>\n",
              "      <th>NO</th>\n",
              "      <th>PL</th>\n",
              "      <th>PT</th>\n",
              "      <th>RO</th>\n",
              "      <th>SI</th>\n",
              "      <th>SK</th>\n",
              "      <th>SE</th>\n",
              "      <th>UK</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1986-01-01 00:00:00</td>\n",
              "      <td>0.047786</td>\n",
              "      <td>0.023020</td>\n",
              "      <td>0.048940</td>\n",
              "      <td>0.065907</td>\n",
              "      <td>0.041685</td>\n",
              "      <td>0.031583</td>\n",
              "      <td>0.017365</td>\n",
              "      <td>0.014149</td>\n",
              "      <td>0.079043</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.049822</td>\n",
              "      <td>0.051933</td>\n",
              "      <td>0.030507</td>\n",
              "      <td>0.025005</td>\n",
              "      <td>0.011889</td>\n",
              "      <td>0.046250</td>\n",
              "      <td>0.035880</td>\n",
              "      <td>0.014839</td>\n",
              "      <td>0.019004</td>\n",
              "      <td>0.014293</td>\n",
              "      <td>0.010351</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>0.076675</td>\n",
              "      <td>0.029107</td>\n",
              "      <td>0.015193</td>\n",
              "      <td>0.054001</td>\n",
              "      <td>0.017463</td>\n",
              "      <td>0.030419</td>\n",
              "      <td>1986-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1986-01-02 00:00:00</td>\n",
              "      <td>0.045921</td>\n",
              "      <td>0.036297</td>\n",
              "      <td>0.067995</td>\n",
              "      <td>0.077502</td>\n",
              "      <td>0.026427</td>\n",
              "      <td>0.023506</td>\n",
              "      <td>0.014981</td>\n",
              "      <td>0.015682</td>\n",
              "      <td>0.119019</td>\n",
              "      <td>0.007176</td>\n",
              "      <td>0.063090</td>\n",
              "      <td>0.115133</td>\n",
              "      <td>0.035716</td>\n",
              "      <td>0.039431</td>\n",
              "      <td>0.016575</td>\n",
              "      <td>0.051848</td>\n",
              "      <td>0.016988</td>\n",
              "      <td>0.019510</td>\n",
              "      <td>0.013771</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.006469</td>\n",
              "      <td>0.031359</td>\n",
              "      <td>0.106900</td>\n",
              "      <td>0.044379</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.034362</td>\n",
              "      <td>0.008086</td>\n",
              "      <td>0.022146</td>\n",
              "      <td>1986-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1986-01-03 00:00:00</td>\n",
              "      <td>0.067308</td>\n",
              "      <td>0.021352</td>\n",
              "      <td>0.101287</td>\n",
              "      <td>0.103680</td>\n",
              "      <td>0.057274</td>\n",
              "      <td>0.046181</td>\n",
              "      <td>0.023478</td>\n",
              "      <td>0.009570</td>\n",
              "      <td>0.106574</td>\n",
              "      <td>0.004687</td>\n",
              "      <td>0.048678</td>\n",
              "      <td>0.123855</td>\n",
              "      <td>0.051901</td>\n",
              "      <td>0.029249</td>\n",
              "      <td>0.054734</td>\n",
              "      <td>0.062773</td>\n",
              "      <td>0.017350</td>\n",
              "      <td>0.056217</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>0.010782</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>0.027554</td>\n",
              "      <td>0.160308</td>\n",
              "      <td>0.047235</td>\n",
              "      <td>0.032093</td>\n",
              "      <td>0.023788</td>\n",
              "      <td>0.010004</td>\n",
              "      <td>0.060345</td>\n",
              "      <td>1986-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1986-01-04 00:00:00</td>\n",
              "      <td>0.043833</td>\n",
              "      <td>0.050756</td>\n",
              "      <td>0.039337</td>\n",
              "      <td>0.075418</td>\n",
              "      <td>0.025843</td>\n",
              "      <td>0.025011</td>\n",
              "      <td>0.020003</td>\n",
              "      <td>0.008595</td>\n",
              "      <td>0.135060</td>\n",
              "      <td>0.004102</td>\n",
              "      <td>0.092991</td>\n",
              "      <td>0.089767</td>\n",
              "      <td>0.055547</td>\n",
              "      <td>0.044340</td>\n",
              "      <td>0.016779</td>\n",
              "      <td>0.055305</td>\n",
              "      <td>0.019638</td>\n",
              "      <td>0.055925</td>\n",
              "      <td>0.013604</td>\n",
              "      <td>0.030366</td>\n",
              "      <td>0.007998</td>\n",
              "      <td>0.025986</td>\n",
              "      <td>0.208236</td>\n",
              "      <td>0.037510</td>\n",
              "      <td>0.028663</td>\n",
              "      <td>0.018115</td>\n",
              "      <td>0.009546</td>\n",
              "      <td>0.030981</td>\n",
              "      <td>1986-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1986-01-05 00:00:00</td>\n",
              "      <td>0.082394</td>\n",
              "      <td>0.014302</td>\n",
              "      <td>0.033055</td>\n",
              "      <td>0.090867</td>\n",
              "      <td>0.065186</td>\n",
              "      <td>0.028168</td>\n",
              "      <td>0.016261</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.095232</td>\n",
              "      <td>0.005172</td>\n",
              "      <td>0.045049</td>\n",
              "      <td>0.074312</td>\n",
              "      <td>0.081576</td>\n",
              "      <td>0.082401</td>\n",
              "      <td>0.038972</td>\n",
              "      <td>0.102499</td>\n",
              "      <td>0.020079</td>\n",
              "      <td>0.018873</td>\n",
              "      <td>0.013913</td>\n",
              "      <td>0.012728</td>\n",
              "      <td>0.007241</td>\n",
              "      <td>0.047764</td>\n",
              "      <td>0.115451</td>\n",
              "      <td>0.037254</td>\n",
              "      <td>0.057101</td>\n",
              "      <td>0.072843</td>\n",
              "      <td>0.013872</td>\n",
              "      <td>0.023346</td>\n",
              "      <td>1986-01-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  time        AT        BE  ...        SE        UK    datetime\n",
              "0  1986-01-01 00:00:00  0.047786  0.023020  ...  0.017463  0.030419  1986-01-01\n",
              "1  1986-01-02 00:00:00  0.045921  0.036297  ...  0.008086  0.022146  1986-01-02\n",
              "2  1986-01-03 00:00:00  0.067308  0.021352  ...  0.010004  0.060345  1986-01-03\n",
              "3  1986-01-04 00:00:00  0.043833  0.050756  ...  0.009546  0.030981  1986-01-04\n",
              "4  1986-01-05 00:00:00  0.082394  0.014302  ...  0.013872  0.023346  1986-01-05\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cXj23RTuefc",
        "colab_type": "code",
        "outputId": "be12ff49-ec58-4c4f-8a33-2892ab81cabd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Getting the real countries' name from 2 letter code\n",
        "\n",
        "!pip install pycountry\n",
        "import pycountry\n",
        "names = {}\n",
        "for code in wind.columns:\n",
        "    try:\n",
        "        names[code] = pycountry.countries.get(alpha_2=code).name\n",
        "    except:\n",
        "        print(code)\n",
        "\n",
        "# For some reason, these two were not present\n",
        "names['EL'] = 'Greece'\n",
        "names['UK'] = 'United Kingdom'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycountry\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/b6/154fe93072051d8ce7bf197690957b6d0ac9a21d51c9a1d05bd7c6fdb16f/pycountry-19.8.18.tar.gz (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycountry\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-19.8.18-py2.py3-none-any.whl size=10627361 sha256=cc9554e8cf6849198cb62e2d68fa6b20b9df33d86087e0184e32b029a6370e70\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/98/bf/f0fa1c6bf8cf2cbdb750d583f84be51c2cd8272460b8b36bd3\n",
            "Successfully built pycountry\n",
            "Installing collected packages: pycountry\n",
            "Successfully installed pycountry-19.8.18\n",
            "time\n",
            "EL\n",
            "UK\n",
            "datetime\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0lVq8z5yP0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wind.rename(columns = names, inplace=True)\n",
        "wind['year'] = pd.to_datetime(wind['time']).map(lambda x: x.year)\n",
        "wind['month'] = pd.to_datetime(wind['time']).map(lambda x: x.month)\n",
        "wind['weekday'] = pd.to_datetime(wind['time']).map(lambda x: x.weekday())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOYWNf8V178S",
        "colab_type": "code",
        "outputId": "812293f5-1c01-4149-d348-cece1ab11acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Making seperate dataframes for each country's data and saving in seperate CSV files\n",
        "!mkdir wind\n",
        "country_wise = {}\n",
        "for country in names.values():\n",
        "    country_wise[country] = wind[['datetime', 'year', 'month', 'weekday', country]]\n",
        "    country_wise[country].to_csv('wind/'+country+'.csv')\n",
        "country_wise[list(country_wise.keys())[5]].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>weekday</th>\n",
              "      <th>Germany</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1986-01-01</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.031583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1986-01-02</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.023506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1986-01-03</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.046181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1986-01-04</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.025011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1986-01-05</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.028168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     datetime  year  month  weekday   Germany\n",
              "0  1986-01-01  1986      1        2  0.031583\n",
              "1  1986-01-02  1986      1        3  0.023506\n",
              "2  1986-01-03  1986      1        4  0.046181\n",
              "3  1986-01-04  1986      1        5  0.025011\n",
              "4  1986-01-05  1986      1        6  0.028168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfdaYt5R5UdL",
        "colab_type": "code",
        "outputId": "d6d9f63f-c32b-47a2-b864-9eebfe56d80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "wind.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Austria</th>\n",
              "      <th>Belgium</th>\n",
              "      <th>Bulgaria</th>\n",
              "      <th>Switzerland</th>\n",
              "      <th>Czechia</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Denmark</th>\n",
              "      <th>Estonia</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Finland</th>\n",
              "      <th>France</th>\n",
              "      <th>Greece</th>\n",
              "      <th>Croatia</th>\n",
              "      <th>Hungary</th>\n",
              "      <th>Ireland</th>\n",
              "      <th>Italy</th>\n",
              "      <th>Lithuania</th>\n",
              "      <th>Luxembourg</th>\n",
              "      <th>Latvia</th>\n",
              "      <th>Netherlands</th>\n",
              "      <th>Norway</th>\n",
              "      <th>Poland</th>\n",
              "      <th>Portugal</th>\n",
              "      <th>Romania</th>\n",
              "      <th>Slovenia</th>\n",
              "      <th>Slovakia</th>\n",
              "      <th>Sweden</th>\n",
              "      <th>United Kingdom</th>\n",
              "      <th>datetime</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10952</th>\n",
              "      <td>2015-12-27 00:00:00</td>\n",
              "      <td>0.119231</td>\n",
              "      <td>0.077324</td>\n",
              "      <td>0.153964</td>\n",
              "      <td>0.134614</td>\n",
              "      <td>0.081821</td>\n",
              "      <td>0.055697</td>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.038722</td>\n",
              "      <td>0.127358</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.102966</td>\n",
              "      <td>0.163328</td>\n",
              "      <td>0.108146</td>\n",
              "      <td>0.044005</td>\n",
              "      <td>0.017154</td>\n",
              "      <td>0.112251</td>\n",
              "      <td>0.014419</td>\n",
              "      <td>0.092283</td>\n",
              "      <td>0.030101</td>\n",
              "      <td>0.019930</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.034805</td>\n",
              "      <td>0.170225</td>\n",
              "      <td>0.136308</td>\n",
              "      <td>0.127401</td>\n",
              "      <td>0.047375</td>\n",
              "      <td>0.008486</td>\n",
              "      <td>0.028426</td>\n",
              "      <td>2015-12-27</td>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10953</th>\n",
              "      <td>2015-12-28 00:00:00</td>\n",
              "      <td>0.128963</td>\n",
              "      <td>0.087688</td>\n",
              "      <td>0.151576</td>\n",
              "      <td>0.125772</td>\n",
              "      <td>0.054648</td>\n",
              "      <td>0.063808</td>\n",
              "      <td>0.024135</td>\n",
              "      <td>0.040206</td>\n",
              "      <td>0.103774</td>\n",
              "      <td>0.011533</td>\n",
              "      <td>0.089861</td>\n",
              "      <td>0.164480</td>\n",
              "      <td>0.096811</td>\n",
              "      <td>0.063488</td>\n",
              "      <td>0.010358</td>\n",
              "      <td>0.121303</td>\n",
              "      <td>0.010499</td>\n",
              "      <td>0.091828</td>\n",
              "      <td>0.036198</td>\n",
              "      <td>0.067833</td>\n",
              "      <td>0.004630</td>\n",
              "      <td>0.023683</td>\n",
              "      <td>0.059809</td>\n",
              "      <td>0.118209</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.048307</td>\n",
              "      <td>0.008479</td>\n",
              "      <td>0.020515</td>\n",
              "      <td>2015-12-28</td>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10954</th>\n",
              "      <td>2015-12-29 00:00:00</td>\n",
              "      <td>0.094872</td>\n",
              "      <td>0.028177</td>\n",
              "      <td>0.070883</td>\n",
              "      <td>0.121686</td>\n",
              "      <td>0.056463</td>\n",
              "      <td>0.054009</td>\n",
              "      <td>0.006732</td>\n",
              "      <td>0.029413</td>\n",
              "      <td>0.126492</td>\n",
              "      <td>0.008377</td>\n",
              "      <td>0.077485</td>\n",
              "      <td>0.170938</td>\n",
              "      <td>0.071934</td>\n",
              "      <td>0.074617</td>\n",
              "      <td>0.011983</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>0.017571</td>\n",
              "      <td>0.031521</td>\n",
              "      <td>0.012752</td>\n",
              "      <td>0.042996</td>\n",
              "      <td>0.004232</td>\n",
              "      <td>0.039898</td>\n",
              "      <td>0.173905</td>\n",
              "      <td>0.033584</td>\n",
              "      <td>0.064835</td>\n",
              "      <td>0.057409</td>\n",
              "      <td>0.011607</td>\n",
              "      <td>0.055220</td>\n",
              "      <td>2015-12-29</td>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10955</th>\n",
              "      <td>2015-12-30 00:00:00</td>\n",
              "      <td>0.086713</td>\n",
              "      <td>0.054810</td>\n",
              "      <td>0.100528</td>\n",
              "      <td>0.114044</td>\n",
              "      <td>0.097525</td>\n",
              "      <td>0.041072</td>\n",
              "      <td>0.006402</td>\n",
              "      <td>0.014740</td>\n",
              "      <td>0.123499</td>\n",
              "      <td>0.003810</td>\n",
              "      <td>0.091785</td>\n",
              "      <td>0.064106</td>\n",
              "      <td>0.076847</td>\n",
              "      <td>0.132149</td>\n",
              "      <td>0.027625</td>\n",
              "      <td>0.108127</td>\n",
              "      <td>0.027267</td>\n",
              "      <td>0.014551</td>\n",
              "      <td>0.031294</td>\n",
              "      <td>0.057475</td>\n",
              "      <td>0.003595</td>\n",
              "      <td>0.067484</td>\n",
              "      <td>0.065125</td>\n",
              "      <td>0.106734</td>\n",
              "      <td>0.026071</td>\n",
              "      <td>0.134139</td>\n",
              "      <td>0.009297</td>\n",
              "      <td>0.011749</td>\n",
              "      <td>2015-12-30</td>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10956</th>\n",
              "      <td>2015-12-31 00:00:00</td>\n",
              "      <td>0.111772</td>\n",
              "      <td>0.095547</td>\n",
              "      <td>0.115314</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.122601</td>\n",
              "      <td>0.029161</td>\n",
              "      <td>0.012323</td>\n",
              "      <td>0.019210</td>\n",
              "      <td>0.092276</td>\n",
              "      <td>0.004629</td>\n",
              "      <td>0.067331</td>\n",
              "      <td>0.077266</td>\n",
              "      <td>0.108809</td>\n",
              "      <td>0.131938</td>\n",
              "      <td>0.022887</td>\n",
              "      <td>0.081279</td>\n",
              "      <td>0.022490</td>\n",
              "      <td>0.078602</td>\n",
              "      <td>0.018948</td>\n",
              "      <td>0.071013</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>0.091865</td>\n",
              "      <td>0.087822</td>\n",
              "      <td>0.132066</td>\n",
              "      <td>0.114436</td>\n",
              "      <td>0.131965</td>\n",
              "      <td>0.015428</td>\n",
              "      <td>0.045504</td>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>2015</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      time   Austria   Belgium  ...  year  month  weekday\n",
              "10952  2015-12-27 00:00:00  0.119231  0.077324  ...  2015     12        6\n",
              "10953  2015-12-28 00:00:00  0.128963  0.087688  ...  2015     12        0\n",
              "10954  2015-12-29 00:00:00  0.094872  0.028177  ...  2015     12        1\n",
              "10955  2015-12-30 00:00:00  0.086713  0.054810  ...  2015     12        2\n",
              "10956  2015-12-31 00:00:00  0.111772  0.095547  ...  2015     12        3\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIvlu81jmNTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config file for WanDB sweeps\n",
        "\n",
        "def make_config_file(file_path, df_len):\n",
        "  run = wandb.init(project=\"pretrain-wind\")\n",
        "  wandb_config = wandb.config\n",
        "  train_number = df_len * .7\n",
        "  validation_number = df_len *.9\n",
        "  config_default={                 \n",
        "    \"model_name\": \"MultiAttnHeadSimple\",\n",
        "    \"model_type\": \"PyTorch\",\n",
        "    \"model_params\": {\n",
        "      \"number_time_series\":4,\n",
        "      \"seq_len\":wandb_config[\"forecast_history\"], \n",
        "      \"output_seq_len\":wandb_config[\"out_seq_length\"],\n",
        "      \"forecast_length\":wandb_config[\"out_seq_length\"]\n",
        "     },\n",
        "    \"dataset_params\":\n",
        "    {  \"class\": \"default\",\n",
        "       \"training_path\": file_path,\n",
        "       \"validation_path\": file_path,\n",
        "       \"test_path\": file_path,\n",
        "       \"batch_size\":wandb_config[\"batch_size\"],\n",
        "       \"forecast_history\":wandb_config[\"forecast_history\"],\n",
        "       \"forecast_length\":wandb_config[\"out_seq_length\"],\n",
        "       \"train_end\": int(train_number),\n",
        "       \"valid_start\":int(train_number+1),\n",
        "       \"valid_end\": int(validation_number),\n",
        "       \"target_col\": [file_path.split('.')[0].split('/')[1]],\n",
        "       \"relevant_cols\": [file_path.split('.')[0].split('/')[1], \"month\", \"weekday\", \"year\"],\n",
        "       \"scaler\": \"StandardScaler\", \n",
        "       \"interpolate\": False\n",
        "    },\n",
        "    \"training_params\":\n",
        "    {\n",
        "       \"criterion\":\"MSE\",\n",
        "       \"optimizer\": \"Adam\",\n",
        "       \"optim_params\":\n",
        "       {\n",
        "\n",
        "       },\n",
        "       \"lr\": wandb_config[\"lr\"],\n",
        "       \"epochs\": 10,\n",
        "       \"batch_size\":wandb_config[\"batch_size\"]\n",
        "    \n",
        "    },\n",
        "    \"GCS\": False,\n",
        "    \n",
        "    \"sweep\":True,\n",
        "    \"wandb\":False,\n",
        "    \"forward_params\":{},\n",
        "   \"metrics\":[\"MSE\"],\n",
        "   \"inference_params\":\n",
        "   {     \n",
        "         \"datetime_start\":\"2010-01-01\",\n",
        "          \"hours_to_forecast\":2000, \n",
        "          \"test_csv_path\":file_path,\n",
        "          \"decoder_params\":{\n",
        "              \"decoder_function\": \"simple_decode\", \n",
        "            \"unsqueeze_dim\": 1\n",
        "          },\n",
        "          \"dataset_params\":{\n",
        "             \"file_path\": file_path,\n",
        "             \"forecast_history\":wandb_config[\"forecast_history\"],\n",
        "             \"forecast_length\":wandb_config[\"out_seq_length\"],\n",
        "             \"relevant_cols\": [file_path.split('.')[0].split('/')[1], \"month\", \"weekday\", \"year\"],\n",
        "             \"target_col\": [file_path.split('.')[0].split('/')[1]],\n",
        "             \"scaling\": \"StandardScaler\",\n",
        "             \"interpolate_param\": False\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "  wandb.config.update(config_default)\n",
        "  return config_default\n",
        "\n",
        "sweep_config = {\n",
        "  \"name\": \"Default sweep\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "        \"batch_size\": {\n",
        "            \"values\": [2]\n",
        "        },\n",
        "        \"lr\":{\n",
        "            \"values\":[0.001]\n",
        "        },\n",
        "        \"forecast_history\":{\n",
        "            \"values\":[1, 2]\n",
        "        },\n",
        "        \"out_seq_length\":{\n",
        "            \"values\":[1, 2]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlGrTTFm2GwI",
        "colab_type": "text"
      },
      "source": [
        "Run sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9klLgR0x1wro",
        "colab_type": "code",
        "outputId": "4d810f42-6db2-4eb1-e0c8-2b5e56358d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# The countries we will be pretraining our wind data on\n",
        "os.listdir('wind')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Lithuania.csv',\n",
              " 'Bulgaria.csv',\n",
              " 'Ireland.csv',\n",
              " 'Netherlands.csv',\n",
              " 'Slovenia.csv',\n",
              " 'Croatia.csv',\n",
              " 'Spain.csv',\n",
              " 'Germany.csv',\n",
              " 'Romania.csv',\n",
              " 'Greece.csv',\n",
              " 'Hungary.csv',\n",
              " 'Portugal.csv',\n",
              " 'Belgium.csv',\n",
              " 'Austria.csv',\n",
              " 'Norway.csv',\n",
              " 'Poland.csv',\n",
              " 'United Kingdom.csv',\n",
              " 'Latvia.csv',\n",
              " 'France.csv',\n",
              " 'Denmark.csv',\n",
              " 'Switzerland.csv',\n",
              " 'Finland.csv',\n",
              " 'Estonia.csv',\n",
              " 'Italy.csv',\n",
              " 'Luxembourg.csv',\n",
              " 'Sweden.csv',\n",
              " 'Slovakia.csv',\n",
              " 'Czechia.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUOcuOCM7COH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "for country in os.listdir('wind'):\n",
        "    file_path = 'wind/'+country\n",
        "    full_len = len(pd.read_csv(file_path))\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"pretrain-wind\")\n",
        "    wandb.agent(sweep_id, lambda:train_function(\"PyTorch\", make_config_file(file_path, full_len)))\n",
        "    !gsutil cp -n -r model_save gs://coronaviruspublicdata/pretrained"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtdZM9BSZB6H",
        "colab_type": "text"
      },
      "source": [
        "Believe me, the above cell executed. It just took... 13 hours to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc8XThQ5_4PJ",
        "colab_type": "text"
      },
      "source": [
        "**Check out the sweeps here :**  *https://app.wandb.ai/pranjalya/pretrain-wind*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X77oP7bEjiSb",
        "colab_type": "text"
      },
      "source": [
        "## Pre Training on Solar Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFggFc-7jp3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "solar = pd.read_csv('solar.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC0geHWVstM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "2c11215d-284e-4b09-f4a8-83257f45209b"
      },
      "source": [
        "solar.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LocalTime</th>\n",
              "      <th>Power(MW)</th>\n",
              "      <th>Power(MW).1</th>\n",
              "      <th>Power(MW).2</th>\n",
              "      <th>Power(MW).3</th>\n",
              "      <th>Power(MW).4</th>\n",
              "      <th>Power(MW).5</th>\n",
              "      <th>Power(MW).6</th>\n",
              "      <th>Power(MW).7</th>\n",
              "      <th>Power(MW).8</th>\n",
              "      <th>Power(MW).9</th>\n",
              "      <th>Power(MW).10</th>\n",
              "      <th>Power(MW).11</th>\n",
              "      <th>Power(MW).12</th>\n",
              "      <th>Power(MW).13</th>\n",
              "      <th>Power(MW).14</th>\n",
              "      <th>Power(MW).15</th>\n",
              "      <th>Power(MW).16</th>\n",
              "      <th>Power(MW).17</th>\n",
              "      <th>Power(MW).18</th>\n",
              "      <th>Power(MW).19</th>\n",
              "      <th>Power(MW).20</th>\n",
              "      <th>Power(MW).21</th>\n",
              "      <th>Power(MW).22</th>\n",
              "      <th>Power(MW).23</th>\n",
              "      <th>Power(MW).24</th>\n",
              "      <th>Power(MW).25</th>\n",
              "      <th>Power(MW).26</th>\n",
              "      <th>Power(MW).27</th>\n",
              "      <th>Power(MW).28</th>\n",
              "      <th>Power(MW).29</th>\n",
              "      <th>Power(MW).30</th>\n",
              "      <th>Power(MW).31</th>\n",
              "      <th>Power(MW).32</th>\n",
              "      <th>Power(MW).33</th>\n",
              "      <th>Power(MW).34</th>\n",
              "      <th>Power(MW).35</th>\n",
              "      <th>Power(MW).36</th>\n",
              "      <th>Power(MW).37</th>\n",
              "      <th>Power(MW).38</th>\n",
              "      <th>...</th>\n",
              "      <th>Power(MW).97</th>\n",
              "      <th>Power(MW).98</th>\n",
              "      <th>Power(MW).99</th>\n",
              "      <th>Power(MW).100</th>\n",
              "      <th>Power(MW).101</th>\n",
              "      <th>Power(MW).102</th>\n",
              "      <th>Power(MW).103</th>\n",
              "      <th>Power(MW).104</th>\n",
              "      <th>Power(MW).105</th>\n",
              "      <th>Power(MW).106</th>\n",
              "      <th>Power(MW).107</th>\n",
              "      <th>Power(MW).108</th>\n",
              "      <th>Power(MW).109</th>\n",
              "      <th>Power(MW).110</th>\n",
              "      <th>Power(MW).111</th>\n",
              "      <th>Power(MW).112</th>\n",
              "      <th>Power(MW).113</th>\n",
              "      <th>Power(MW).114</th>\n",
              "      <th>Power(MW).115</th>\n",
              "      <th>Power(MW).116</th>\n",
              "      <th>Power(MW).117</th>\n",
              "      <th>Power(MW).118</th>\n",
              "      <th>Power(MW).119</th>\n",
              "      <th>Power(MW).120</th>\n",
              "      <th>Power(MW).121</th>\n",
              "      <th>Power(MW).122</th>\n",
              "      <th>Power(MW).123</th>\n",
              "      <th>Power(MW).124</th>\n",
              "      <th>Power(MW).125</th>\n",
              "      <th>Power(MW).126</th>\n",
              "      <th>Power(MW).127</th>\n",
              "      <th>Power(MW).128</th>\n",
              "      <th>Power(MW).129</th>\n",
              "      <th>Power(MW).130</th>\n",
              "      <th>Power(MW).131</th>\n",
              "      <th>Power(MW).132</th>\n",
              "      <th>Power(MW).133</th>\n",
              "      <th>Power(MW).134</th>\n",
              "      <th>Power(MW).135</th>\n",
              "      <th>Power(MW).136</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-01-01 01:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-01-01 02:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-01-01 03:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-01-01 04:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             LocalTime  Power(MW)  ...  Power(MW).135  Power(MW).136\n",
              "0  2006-01-01 00:00:00        0.0  ...            0.0            0.0\n",
              "1  2006-01-01 01:00:00        0.0  ...            0.0            0.0\n",
              "2  2006-01-01 02:00:00        0.0  ...            0.0            0.0\n",
              "3  2006-01-01 03:00:00        0.0  ...            0.0            0.0\n",
              "4  2006-01-01 04:00:00        0.0  ...            0.0            0.0\n",
              "\n",
              "[5 rows x 138 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVac__fWsulf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "2acad0e5-5d29-4f94-d9c0-dd2228c75652"
      },
      "source": [
        "solar.describe()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Power(MW)</th>\n",
              "      <th>Power(MW).1</th>\n",
              "      <th>Power(MW).2</th>\n",
              "      <th>Power(MW).3</th>\n",
              "      <th>Power(MW).4</th>\n",
              "      <th>Power(MW).5</th>\n",
              "      <th>Power(MW).6</th>\n",
              "      <th>Power(MW).7</th>\n",
              "      <th>Power(MW).8</th>\n",
              "      <th>Power(MW).9</th>\n",
              "      <th>Power(MW).10</th>\n",
              "      <th>Power(MW).11</th>\n",
              "      <th>Power(MW).12</th>\n",
              "      <th>Power(MW).13</th>\n",
              "      <th>Power(MW).14</th>\n",
              "      <th>Power(MW).15</th>\n",
              "      <th>Power(MW).16</th>\n",
              "      <th>Power(MW).17</th>\n",
              "      <th>Power(MW).18</th>\n",
              "      <th>Power(MW).19</th>\n",
              "      <th>Power(MW).20</th>\n",
              "      <th>Power(MW).21</th>\n",
              "      <th>Power(MW).22</th>\n",
              "      <th>Power(MW).23</th>\n",
              "      <th>Power(MW).24</th>\n",
              "      <th>Power(MW).25</th>\n",
              "      <th>Power(MW).26</th>\n",
              "      <th>Power(MW).27</th>\n",
              "      <th>Power(MW).28</th>\n",
              "      <th>Power(MW).29</th>\n",
              "      <th>Power(MW).30</th>\n",
              "      <th>Power(MW).31</th>\n",
              "      <th>Power(MW).32</th>\n",
              "      <th>Power(MW).33</th>\n",
              "      <th>Power(MW).34</th>\n",
              "      <th>Power(MW).35</th>\n",
              "      <th>Power(MW).36</th>\n",
              "      <th>Power(MW).37</th>\n",
              "      <th>Power(MW).38</th>\n",
              "      <th>Power(MW).39</th>\n",
              "      <th>...</th>\n",
              "      <th>Power(MW).97</th>\n",
              "      <th>Power(MW).98</th>\n",
              "      <th>Power(MW).99</th>\n",
              "      <th>Power(MW).100</th>\n",
              "      <th>Power(MW).101</th>\n",
              "      <th>Power(MW).102</th>\n",
              "      <th>Power(MW).103</th>\n",
              "      <th>Power(MW).104</th>\n",
              "      <th>Power(MW).105</th>\n",
              "      <th>Power(MW).106</th>\n",
              "      <th>Power(MW).107</th>\n",
              "      <th>Power(MW).108</th>\n",
              "      <th>Power(MW).109</th>\n",
              "      <th>Power(MW).110</th>\n",
              "      <th>Power(MW).111</th>\n",
              "      <th>Power(MW).112</th>\n",
              "      <th>Power(MW).113</th>\n",
              "      <th>Power(MW).114</th>\n",
              "      <th>Power(MW).115</th>\n",
              "      <th>Power(MW).116</th>\n",
              "      <th>Power(MW).117</th>\n",
              "      <th>Power(MW).118</th>\n",
              "      <th>Power(MW).119</th>\n",
              "      <th>Power(MW).120</th>\n",
              "      <th>Power(MW).121</th>\n",
              "      <th>Power(MW).122</th>\n",
              "      <th>Power(MW).123</th>\n",
              "      <th>Power(MW).124</th>\n",
              "      <th>Power(MW).125</th>\n",
              "      <th>Power(MW).126</th>\n",
              "      <th>Power(MW).127</th>\n",
              "      <th>Power(MW).128</th>\n",
              "      <th>Power(MW).129</th>\n",
              "      <th>Power(MW).130</th>\n",
              "      <th>Power(MW).131</th>\n",
              "      <th>Power(MW).132</th>\n",
              "      <th>Power(MW).133</th>\n",
              "      <th>Power(MW).134</th>\n",
              "      <th>Power(MW).135</th>\n",
              "      <th>Power(MW).136</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.00000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>97.990021</td>\n",
              "      <td>72.601543</td>\n",
              "      <td>72.617678</td>\n",
              "      <td>181.308368</td>\n",
              "      <td>163.551646</td>\n",
              "      <td>64.378909</td>\n",
              "      <td>68.242027</td>\n",
              "      <td>118.852452</td>\n",
              "      <td>79.612140</td>\n",
              "      <td>101.382236</td>\n",
              "      <td>75.003927</td>\n",
              "      <td>77.286043</td>\n",
              "      <td>69.262551</td>\n",
              "      <td>78.501012</td>\n",
              "      <td>73.466770</td>\n",
              "      <td>79.956670</td>\n",
              "      <td>78.386968</td>\n",
              "      <td>73.687637</td>\n",
              "      <td>72.940055</td>\n",
              "      <td>73.225892</td>\n",
              "      <td>77.151800</td>\n",
              "      <td>77.681207</td>\n",
              "      <td>77.547582</td>\n",
              "      <td>77.543021</td>\n",
              "      <td>76.565895</td>\n",
              "      <td>76.831962</td>\n",
              "      <td>76.478326</td>\n",
              "      <td>78.114215</td>\n",
              "      <td>77.010734</td>\n",
              "      <td>70.163134</td>\n",
              "      <td>77.808933</td>\n",
              "      <td>70.796005</td>\n",
              "      <td>70.287329</td>\n",
              "      <td>77.684585</td>\n",
              "      <td>76.008676</td>\n",
              "      <td>76.927332</td>\n",
              "      <td>77.182888</td>\n",
              "      <td>72.178669</td>\n",
              "      <td>77.444770</td>\n",
              "      <td>77.269050</td>\n",
              "      <td>...</td>\n",
              "      <td>73.652795</td>\n",
              "      <td>69.244050</td>\n",
              "      <td>72.905161</td>\n",
              "      <td>177.831687</td>\n",
              "      <td>64.941169</td>\n",
              "      <td>73.224571</td>\n",
              "      <td>54.165501</td>\n",
              "      <td>143.012654</td>\n",
              "      <td>78.924091</td>\n",
              "      <td>69.42296</td>\n",
              "      <td>68.952023</td>\n",
              "      <td>54.896039</td>\n",
              "      <td>75.234688</td>\n",
              "      <td>53.857613</td>\n",
              "      <td>64.792473</td>\n",
              "      <td>61.921416</td>\n",
              "      <td>72.592370</td>\n",
              "      <td>54.449314</td>\n",
              "      <td>72.350617</td>\n",
              "      <td>77.925634</td>\n",
              "      <td>72.908951</td>\n",
              "      <td>151.620405</td>\n",
              "      <td>41.334774</td>\n",
              "      <td>77.789300</td>\n",
              "      <td>70.294016</td>\n",
              "      <td>75.423577</td>\n",
              "      <td>41.880676</td>\n",
              "      <td>76.978515</td>\n",
              "      <td>163.736540</td>\n",
              "      <td>76.747531</td>\n",
              "      <td>77.040929</td>\n",
              "      <td>76.639506</td>\n",
              "      <td>123.436848</td>\n",
              "      <td>77.488529</td>\n",
              "      <td>76.994170</td>\n",
              "      <td>123.925892</td>\n",
              "      <td>75.624348</td>\n",
              "      <td>72.612363</td>\n",
              "      <td>61.697565</td>\n",
              "      <td>74.114180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>121.215824</td>\n",
              "      <td>100.775117</td>\n",
              "      <td>102.617019</td>\n",
              "      <td>255.577980</td>\n",
              "      <td>227.711359</td>\n",
              "      <td>91.088087</td>\n",
              "      <td>96.013131</td>\n",
              "      <td>167.768777</td>\n",
              "      <td>109.091165</td>\n",
              "      <td>142.448961</td>\n",
              "      <td>105.413903</td>\n",
              "      <td>106.748239</td>\n",
              "      <td>96.573719</td>\n",
              "      <td>108.095548</td>\n",
              "      <td>103.759917</td>\n",
              "      <td>109.660217</td>\n",
              "      <td>111.123343</td>\n",
              "      <td>104.098793</td>\n",
              "      <td>103.392740</td>\n",
              "      <td>103.677634</td>\n",
              "      <td>108.577382</td>\n",
              "      <td>108.463883</td>\n",
              "      <td>108.651308</td>\n",
              "      <td>106.827237</td>\n",
              "      <td>105.974013</td>\n",
              "      <td>107.632612</td>\n",
              "      <td>105.833609</td>\n",
              "      <td>110.312326</td>\n",
              "      <td>107.852568</td>\n",
              "      <td>98.031765</td>\n",
              "      <td>109.073624</td>\n",
              "      <td>96.789302</td>\n",
              "      <td>97.835354</td>\n",
              "      <td>108.632086</td>\n",
              "      <td>106.472926</td>\n",
              "      <td>107.922032</td>\n",
              "      <td>106.690069</td>\n",
              "      <td>102.596689</td>\n",
              "      <td>107.988948</td>\n",
              "      <td>107.989447</td>\n",
              "      <td>...</td>\n",
              "      <td>92.000652</td>\n",
              "      <td>97.306594</td>\n",
              "      <td>100.894989</td>\n",
              "      <td>216.932139</td>\n",
              "      <td>91.735845</td>\n",
              "      <td>103.566030</td>\n",
              "      <td>75.384950</td>\n",
              "      <td>198.830916</td>\n",
              "      <td>108.327914</td>\n",
              "      <td>96.93925</td>\n",
              "      <td>96.811196</td>\n",
              "      <td>76.699214</td>\n",
              "      <td>105.744341</td>\n",
              "      <td>74.698423</td>\n",
              "      <td>91.477063</td>\n",
              "      <td>85.882681</td>\n",
              "      <td>100.702548</td>\n",
              "      <td>76.392924</td>\n",
              "      <td>101.918631</td>\n",
              "      <td>109.124838</td>\n",
              "      <td>103.196428</td>\n",
              "      <td>186.609687</td>\n",
              "      <td>57.095260</td>\n",
              "      <td>109.048518</td>\n",
              "      <td>96.184135</td>\n",
              "      <td>106.200268</td>\n",
              "      <td>57.693641</td>\n",
              "      <td>108.015106</td>\n",
              "      <td>228.709291</td>\n",
              "      <td>106.271689</td>\n",
              "      <td>107.825797</td>\n",
              "      <td>105.532143</td>\n",
              "      <td>170.698819</td>\n",
              "      <td>109.003895</td>\n",
              "      <td>107.316424</td>\n",
              "      <td>170.578983</td>\n",
              "      <td>93.098493</td>\n",
              "      <td>103.116330</td>\n",
              "      <td>86.162491</td>\n",
              "      <td>104.574143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.650000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.10000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>6.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>215.800000</td>\n",
              "      <td>140.900000</td>\n",
              "      <td>138.150000</td>\n",
              "      <td>353.325000</td>\n",
              "      <td>325.225000</td>\n",
              "      <td>121.050000</td>\n",
              "      <td>132.225000</td>\n",
              "      <td>228.175000</td>\n",
              "      <td>161.750000</td>\n",
              "      <td>200.150000</td>\n",
              "      <td>143.350000</td>\n",
              "      <td>152.850000</td>\n",
              "      <td>135.575000</td>\n",
              "      <td>156.225000</td>\n",
              "      <td>140.550000</td>\n",
              "      <td>160.825000</td>\n",
              "      <td>151.225000</td>\n",
              "      <td>140.525000</td>\n",
              "      <td>136.100000</td>\n",
              "      <td>138.575000</td>\n",
              "      <td>148.400000</td>\n",
              "      <td>152.925000</td>\n",
              "      <td>152.600000</td>\n",
              "      <td>154.750000</td>\n",
              "      <td>151.450000</td>\n",
              "      <td>150.125000</td>\n",
              "      <td>154.325000</td>\n",
              "      <td>149.025000</td>\n",
              "      <td>150.050000</td>\n",
              "      <td>139.025000</td>\n",
              "      <td>151.150000</td>\n",
              "      <td>144.900000</td>\n",
              "      <td>137.725000</td>\n",
              "      <td>150.500000</td>\n",
              "      <td>148.325000</td>\n",
              "      <td>148.900000</td>\n",
              "      <td>151.925000</td>\n",
              "      <td>132.725000</td>\n",
              "      <td>152.850000</td>\n",
              "      <td>152.625000</td>\n",
              "      <td>...</td>\n",
              "      <td>163.325000</td>\n",
              "      <td>134.450000</td>\n",
              "      <td>142.325000</td>\n",
              "      <td>401.125000</td>\n",
              "      <td>124.750000</td>\n",
              "      <td>138.500000</td>\n",
              "      <td>106.200000</td>\n",
              "      <td>290.425000</td>\n",
              "      <td>156.825000</td>\n",
              "      <td>138.25000</td>\n",
              "      <td>131.425000</td>\n",
              "      <td>105.625000</td>\n",
              "      <td>145.925000</td>\n",
              "      <td>105.825000</td>\n",
              "      <td>123.225000</td>\n",
              "      <td>124.125000</td>\n",
              "      <td>141.825000</td>\n",
              "      <td>104.825000</td>\n",
              "      <td>137.325000</td>\n",
              "      <td>154.100000</td>\n",
              "      <td>137.550000</td>\n",
              "      <td>338.775000</td>\n",
              "      <td>84.200000</td>\n",
              "      <td>150.725000</td>\n",
              "      <td>142.300000</td>\n",
              "      <td>142.625000</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>148.525000</td>\n",
              "      <td>327.000000</td>\n",
              "      <td>150.425000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>152.225000</td>\n",
              "      <td>248.400000</td>\n",
              "      <td>148.200000</td>\n",
              "      <td>152.200000</td>\n",
              "      <td>253.475000</td>\n",
              "      <td>170.125000</td>\n",
              "      <td>136.425000</td>\n",
              "      <td>125.025000</td>\n",
              "      <td>139.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>371.100000</td>\n",
              "      <td>349.000000</td>\n",
              "      <td>354.800000</td>\n",
              "      <td>949.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>321.800000</td>\n",
              "      <td>330.300000</td>\n",
              "      <td>608.900000</td>\n",
              "      <td>379.600000</td>\n",
              "      <td>499.700000</td>\n",
              "      <td>371.300000</td>\n",
              "      <td>368.800000</td>\n",
              "      <td>354.900000</td>\n",
              "      <td>381.700000</td>\n",
              "      <td>361.200000</td>\n",
              "      <td>383.200000</td>\n",
              "      <td>403.600000</td>\n",
              "      <td>369.800000</td>\n",
              "      <td>378.500000</td>\n",
              "      <td>378.900000</td>\n",
              "      <td>380.800000</td>\n",
              "      <td>375.000000</td>\n",
              "      <td>392.200000</td>\n",
              "      <td>370.100000</td>\n",
              "      <td>365.800000</td>\n",
              "      <td>371.300000</td>\n",
              "      <td>365.300000</td>\n",
              "      <td>400.400000</td>\n",
              "      <td>388.000000</td>\n",
              "      <td>345.700000</td>\n",
              "      <td>367.900000</td>\n",
              "      <td>341.100000</td>\n",
              "      <td>354.700000</td>\n",
              "      <td>374.700000</td>\n",
              "      <td>378.600000</td>\n",
              "      <td>374.600000</td>\n",
              "      <td>373.100000</td>\n",
              "      <td>356.600000</td>\n",
              "      <td>382.300000</td>\n",
              "      <td>378.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>280.800000</td>\n",
              "      <td>341.400000</td>\n",
              "      <td>345.600000</td>\n",
              "      <td>648.800000</td>\n",
              "      <td>323.200000</td>\n",
              "      <td>373.000000</td>\n",
              "      <td>274.300000</td>\n",
              "      <td>713.200000</td>\n",
              "      <td>383.200000</td>\n",
              "      <td>345.30000</td>\n",
              "      <td>340.400000</td>\n",
              "      <td>273.100000</td>\n",
              "      <td>369.700000</td>\n",
              "      <td>258.000000</td>\n",
              "      <td>326.400000</td>\n",
              "      <td>302.000000</td>\n",
              "      <td>346.600000</td>\n",
              "      <td>279.100000</td>\n",
              "      <td>352.200000</td>\n",
              "      <td>371.900000</td>\n",
              "      <td>356.400000</td>\n",
              "      <td>560.200000</td>\n",
              "      <td>197.900000</td>\n",
              "      <td>376.500000</td>\n",
              "      <td>334.400000</td>\n",
              "      <td>376.300000</td>\n",
              "      <td>202.600000</td>\n",
              "      <td>372.600000</td>\n",
              "      <td>814.400000</td>\n",
              "      <td>365.800000</td>\n",
              "      <td>370.200000</td>\n",
              "      <td>369.400000</td>\n",
              "      <td>615.100000</td>\n",
              "      <td>387.100000</td>\n",
              "      <td>391.400000</td>\n",
              "      <td>592.200000</td>\n",
              "      <td>283.800000</td>\n",
              "      <td>366.800000</td>\n",
              "      <td>299.700000</td>\n",
              "      <td>376.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 137 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Power(MW)  Power(MW).1  ...  Power(MW).135  Power(MW).136\n",
              "count  5832.000000  5832.000000  ...    5832.000000    5832.000000\n",
              "mean     97.990021    72.601543  ...      61.697565      74.114180\n",
              "std     121.215824   100.775117  ...      86.162491     104.574143\n",
              "min       0.000000     0.000000  ...       0.000000       0.000000\n",
              "25%       0.000000     0.000000  ...       0.000000       0.000000\n",
              "50%       5.650000     0.100000  ...       0.100000       0.100000\n",
              "75%     215.800000   140.900000  ...     125.025000     139.800000\n",
              "max     371.100000   349.000000  ...     299.700000     376.100000\n",
              "\n",
              "[8 rows x 137 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Zh5tV4tY52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "3ae67ead-2160-4d40-cf40-8728c64ccb15"
      },
      "source": [
        "solar.tail()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LocalTime</th>\n",
              "      <th>Power(MW)</th>\n",
              "      <th>Power(MW).1</th>\n",
              "      <th>Power(MW).2</th>\n",
              "      <th>Power(MW).3</th>\n",
              "      <th>Power(MW).4</th>\n",
              "      <th>Power(MW).5</th>\n",
              "      <th>Power(MW).6</th>\n",
              "      <th>Power(MW).7</th>\n",
              "      <th>Power(MW).8</th>\n",
              "      <th>Power(MW).9</th>\n",
              "      <th>Power(MW).10</th>\n",
              "      <th>Power(MW).11</th>\n",
              "      <th>Power(MW).12</th>\n",
              "      <th>Power(MW).13</th>\n",
              "      <th>Power(MW).14</th>\n",
              "      <th>Power(MW).15</th>\n",
              "      <th>Power(MW).16</th>\n",
              "      <th>Power(MW).17</th>\n",
              "      <th>Power(MW).18</th>\n",
              "      <th>Power(MW).19</th>\n",
              "      <th>Power(MW).20</th>\n",
              "      <th>Power(MW).21</th>\n",
              "      <th>Power(MW).22</th>\n",
              "      <th>Power(MW).23</th>\n",
              "      <th>Power(MW).24</th>\n",
              "      <th>Power(MW).25</th>\n",
              "      <th>Power(MW).26</th>\n",
              "      <th>Power(MW).27</th>\n",
              "      <th>Power(MW).28</th>\n",
              "      <th>Power(MW).29</th>\n",
              "      <th>Power(MW).30</th>\n",
              "      <th>Power(MW).31</th>\n",
              "      <th>Power(MW).32</th>\n",
              "      <th>Power(MW).33</th>\n",
              "      <th>Power(MW).34</th>\n",
              "      <th>Power(MW).35</th>\n",
              "      <th>Power(MW).36</th>\n",
              "      <th>Power(MW).37</th>\n",
              "      <th>Power(MW).38</th>\n",
              "      <th>...</th>\n",
              "      <th>Power(MW).97</th>\n",
              "      <th>Power(MW).98</th>\n",
              "      <th>Power(MW).99</th>\n",
              "      <th>Power(MW).100</th>\n",
              "      <th>Power(MW).101</th>\n",
              "      <th>Power(MW).102</th>\n",
              "      <th>Power(MW).103</th>\n",
              "      <th>Power(MW).104</th>\n",
              "      <th>Power(MW).105</th>\n",
              "      <th>Power(MW).106</th>\n",
              "      <th>Power(MW).107</th>\n",
              "      <th>Power(MW).108</th>\n",
              "      <th>Power(MW).109</th>\n",
              "      <th>Power(MW).110</th>\n",
              "      <th>Power(MW).111</th>\n",
              "      <th>Power(MW).112</th>\n",
              "      <th>Power(MW).113</th>\n",
              "      <th>Power(MW).114</th>\n",
              "      <th>Power(MW).115</th>\n",
              "      <th>Power(MW).116</th>\n",
              "      <th>Power(MW).117</th>\n",
              "      <th>Power(MW).118</th>\n",
              "      <th>Power(MW).119</th>\n",
              "      <th>Power(MW).120</th>\n",
              "      <th>Power(MW).121</th>\n",
              "      <th>Power(MW).122</th>\n",
              "      <th>Power(MW).123</th>\n",
              "      <th>Power(MW).124</th>\n",
              "      <th>Power(MW).125</th>\n",
              "      <th>Power(MW).126</th>\n",
              "      <th>Power(MW).127</th>\n",
              "      <th>Power(MW).128</th>\n",
              "      <th>Power(MW).129</th>\n",
              "      <th>Power(MW).130</th>\n",
              "      <th>Power(MW).131</th>\n",
              "      <th>Power(MW).132</th>\n",
              "      <th>Power(MW).133</th>\n",
              "      <th>Power(MW).134</th>\n",
              "      <th>Power(MW).135</th>\n",
              "      <th>Power(MW).136</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5827</th>\n",
              "      <td>2006-08-31 19:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5828</th>\n",
              "      <td>2006-08-31 20:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5829</th>\n",
              "      <td>2006-08-31 21:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5830</th>\n",
              "      <td>2006-08-31 22:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5831</th>\n",
              "      <td>2006-08-31 23:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                LocalTime  Power(MW)  ...  Power(MW).135  Power(MW).136\n",
              "5827  2006-08-31 19:00:00        0.0  ...            0.0            0.0\n",
              "5828  2006-08-31 20:00:00        0.0  ...            0.0            0.0\n",
              "5829  2006-08-31 21:00:00        0.0  ...            0.0            0.0\n",
              "5830  2006-08-31 22:00:00        0.0  ...            0.0            0.0\n",
              "5831  2006-08-31 23:00:00        0.0  ...            0.0            0.0\n",
              "\n",
              "[5 rows x 138 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTbw3lEmxgsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "8407a9e9-23f2-4d0d-fb2f-040b263233e5"
      },
      "source": [
        "solar.rename(columns={'LocalTime':'datetime'}, inplace=True)\n",
        "solar = solar[['datetime', 'Power(MW)']]\n",
        "solar.set_index('datetime', drop=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>Power(MW)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-03-03 06:00:00</th>\n",
              "      <td>2006-03-03 06:00:00</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-03-03 07:00:00</th>\n",
              "      <td>2006-03-03 07:00:00</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-03-03 08:00:00</th>\n",
              "      <td>2006-03-03 08:00:00</td>\n",
              "      <td>295.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-03-03 09:00:00</th>\n",
              "      <td>2006-03-03 09:00:00</td>\n",
              "      <td>331.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-03-03 10:00:00</th>\n",
              "      <td>2006-03-03 10:00:00</td>\n",
              "      <td>337.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-08-31 13:00:00</th>\n",
              "      <td>2006-08-31 13:00:00</td>\n",
              "      <td>111.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-08-31 14:00:00</th>\n",
              "      <td>2006-08-31 14:00:00</td>\n",
              "      <td>201.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-08-31 15:00:00</th>\n",
              "      <td>2006-08-31 15:00:00</td>\n",
              "      <td>203.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-08-31 16:00:00</th>\n",
              "      <td>2006-08-31 16:00:00</td>\n",
              "      <td>135.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-08-31 17:00:00</th>\n",
              "      <td>2006-08-31 17:00:00</td>\n",
              "      <td>52.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4356 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                datetime  Power(MW)\n",
              "datetime                                           \n",
              "2006-03-03 06:00:00  2006-03-03 06:00:00       10.5\n",
              "2006-03-03 07:00:00  2006-03-03 07:00:00      202.0\n",
              "2006-03-03 08:00:00  2006-03-03 08:00:00      295.3\n",
              "2006-03-03 09:00:00  2006-03-03 09:00:00      331.3\n",
              "2006-03-03 10:00:00  2006-03-03 10:00:00      337.1\n",
              "...                                  ...        ...\n",
              "2006-08-31 13:00:00  2006-08-31 13:00:00      111.3\n",
              "2006-08-31 14:00:00  2006-08-31 14:00:00      201.1\n",
              "2006-08-31 15:00:00  2006-08-31 15:00:00      203.8\n",
              "2006-08-31 16:00:00  2006-08-31 16:00:00      135.5\n",
              "2006-08-31 17:00:00  2006-08-31 17:00:00       52.9\n",
              "\n",
              "[4356 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQH0oaccujx6",
        "colab_type": "text"
      },
      "source": [
        "So, basically the first 1469 values, and last 6 values are just 0, so let's remove those rows, as they may just add bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaQqySKet9_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e0c45e38-51dd-4bc2-c309-4e575a3f4db3"
      },
      "source": [
        "solar = solar.iloc[1470:5826]\n",
        "solar.describe()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Power(MW)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2886.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>110.812751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>123.216462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>42.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>232.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>365.900000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Power(MW)\n",
              "count  2886.000000\n",
              "mean    110.812751\n",
              "std     123.216462\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%      42.900000\n",
              "75%     232.750000\n",
              "max     365.900000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mINWEKmvt4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting the timeseries relevant columns\n",
        "solar['day'] = pd.to_datetime(solar['datetime']).map(lambda x: x.day)\n",
        "solar['month'] = pd.to_datetime(solar['datetime']).map(lambda x: x.month)\n",
        "solar['weekday'] = pd.to_datetime(solar['datetime']).map(lambda x: x.weekday())\n",
        "solar['hour'] = pd.to_datetime(solar['datetime']).map(lambda x: x.hour)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BQ1p_rGw0Wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bf519ec3-95d7-49bf-8a9d-25b0ddd4c1d0"
      },
      "source": [
        "solar.to_csv('selected_solar.csv')\n",
        "solar.tail()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>Power(MW)</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>weekday</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5821</th>\n",
              "      <td>2006-08-31 13:00:00</td>\n",
              "      <td>111.3</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5822</th>\n",
              "      <td>2006-08-31 14:00:00</td>\n",
              "      <td>201.1</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5823</th>\n",
              "      <td>2006-08-31 15:00:00</td>\n",
              "      <td>203.8</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5824</th>\n",
              "      <td>2006-08-31 16:00:00</td>\n",
              "      <td>135.5</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5825</th>\n",
              "      <td>2006-08-31 17:00:00</td>\n",
              "      <td>52.9</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 datetime  Power(MW)  day  month  weekday  hour\n",
              "5821  2006-08-31 13:00:00      111.3   31      8        3    13\n",
              "5822  2006-08-31 14:00:00      201.1   31      8        3    14\n",
              "5823  2006-08-31 15:00:00      203.8   31      8        3    15\n",
              "5824  2006-08-31 16:00:00      135.5   31      8        3    16\n",
              "5825  2006-08-31 17:00:00       52.9   31      8        3    17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPRAwtvZycTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config file for WanDB sweeps\n",
        "\n",
        "def make_config_file(file_path, df_len):\n",
        "  run = wandb.init(project=\"pretrain-wind\")\n",
        "  wandb_config = wandb.config\n",
        "  train_number = df_len * .7\n",
        "  validation_number = df_len *.9\n",
        "  config_default={                 \n",
        "    \"model_name\": \"MultiAttnHeadSimple\",\n",
        "    \"model_type\": \"PyTorch\",\n",
        "    \"model_params\": {\n",
        "      \"number_time_series\":5,\n",
        "      \"seq_len\":wandb_config[\"forecast_history\"], \n",
        "      \"output_seq_len\":wandb_config[\"out_seq_length\"],\n",
        "      \"forecast_length\":wandb_config[\"out_seq_length\"]\n",
        "     },\n",
        "    \"dataset_params\":\n",
        "    {  \"class\": \"default\",\n",
        "       \"training_path\": file_path,\n",
        "       \"validation_path\": file_path,\n",
        "       \"test_path\": file_path,\n",
        "       \"batch_size\":wandb_config[\"batch_size\"],\n",
        "       \"forecast_history\":wandb_config[\"forecast_history\"],\n",
        "       \"forecast_length\":wandb_config[\"out_seq_length\"],\n",
        "       \"train_end\": int(train_number),\n",
        "       \"valid_start\":int(train_number+1),\n",
        "       \"valid_end\": int(validation_number),\n",
        "       \"target_col\": [\"Power(MW)\"],\n",
        "       \"relevant_cols\": [\"Power(MW)\", \"month\", \"weekday\", \"hour\", \"day\"],\n",
        "       \"scaler\": \"StandardScaler\", \n",
        "       \"interpolate\": False\n",
        "    },\n",
        "    \"training_params\":\n",
        "    {\n",
        "       \"criterion\":\"MSE\",\n",
        "       \"optimizer\": \"Adam\",\n",
        "       \"optim_params\":\n",
        "       {\n",
        "\n",
        "       },\n",
        "       \"lr\": wandb_config[\"lr\"],\n",
        "       \"epochs\": 10,\n",
        "       \"batch_size\":wandb_config[\"batch_size\"]\n",
        "    \n",
        "    },\n",
        "    \"GCS\": False,\n",
        "    \n",
        "    \"sweep\":True,\n",
        "    \"wandb\":False,\n",
        "    \"forward_params\":{},\n",
        "   \"metrics\":[\"MSE\"],\n",
        "   \"inference_params\":\n",
        "   {     \n",
        "         \"datetime_start\":\"2006-08-22\",\n",
        "          \"hours_to_forecast\":150, \n",
        "          \"test_csv_path\":file_path,\n",
        "          \"decoder_params\":{\n",
        "              \"decoder_function\": \"simple_decode\", \n",
        "            \"unsqueeze_dim\": 1\n",
        "          },\n",
        "          \"dataset_params\":{\n",
        "             \"file_path\": file_path,\n",
        "             \"forecast_history\":wandb_config[\"forecast_history\"],\n",
        "             \"forecast_length\":wandb_config[\"out_seq_length\"],\n",
        "             \"relevant_cols\": [\"Power(MW)\", \"month\", \"weekday\", \"hour\", \"day\"],\n",
        "             \"target_col\": [\"Power(MW)\"],\n",
        "             \"scaling\": \"StandardScaler\",\n",
        "             \"interpolate_param\": False\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "  wandb.config.update(config_default)\n",
        "  return config_default\n",
        "\n",
        "sweep_config = {\n",
        "  \"name\": \"Default sweep\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "        \"batch_size\": {\n",
        "            \"values\": [2, 3, 4]\n",
        "        },\n",
        "        \"lr\":{\n",
        "            \"values\":[0.001, 0.01]\n",
        "        },\n",
        "        \"forecast_history\":{\n",
        "            \"values\":[1, 2, 3, 5, 8]\n",
        "        },\n",
        "        \"out_seq_length\":{\n",
        "            \"values\":[1, 2]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le4MYbaS2Del",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "beb0e092-9f24-46ef-a111-4334382209df"
      },
      "source": [
        "# Running the sweep\n",
        "import wandb\n",
        "file_path = 'selected_solar.csv'\n",
        "full_len = len(pd.read_csv(file_path))\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"pretrain-solar\")\n",
        "wandb.agent(sweep_id, lambda:train_function(\"PyTorch\", make_config_file(file_path, full_len)))\n",
        "!gsutil cp -n -r model_save gs://coronaviruspublicdata/pretrained"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: wyhhj2a6\n",
            "Sweep URL: https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\n",
            "wandb: Agent Starting Run: j15aa4jk with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: j15aa4jk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/j15aa4jk\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/j15aa4jk</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "225.75949387002038\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 0\n",
            "0.2237457818335187\n",
            "The running loss is:\n",
            "168.8906795582734\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 1\n",
            "0.16738422156419563\n",
            "The running loss is:\n",
            "170.25132953720458\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 2\n",
            "0.1687327349228985\n",
            "The running loss is:\n",
            "166.20676435675705\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 3\n",
            "0.1647242461414837\n",
            "The running loss is:\n",
            "160.25710399751551\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 4\n",
            "0.1588276551016011\n",
            "The running loss is:\n",
            "155.85809439198783\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 5\n",
            "0.15446788344101867\n",
            "The running loss is:\n",
            "159.47748929887166\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 6\n",
            "0.15805499434972414\n",
            "The running loss is:\n",
            "151.81139983976755\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 7\n",
            "0.15045728428123642\n",
            "The running loss is:\n",
            "151.89980408451083\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 8\n",
            "0.15054489998464898\n",
            "The running loss is:\n",
            "151.51018837586162\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 9\n",
            "0.1501587595400016\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -14.036416\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   17.400223\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   43.600792\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   65.121140\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   34.128967\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798   58.778484\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   78.912422\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   95.010124\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  107.500061\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: j15aa4jk \n",
            "\n",
            "wandb: Agent Starting Run: 559c84u4 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 559c84u4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/559c84u4\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/559c84u4</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "933.7901946306229\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.9263791613399036\n",
            "The running loss is:\n",
            "349.3704765816219\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.3465976950214503\n",
            "The running loss is:\n",
            "274.40974052262027\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.2722318854391074\n",
            "The running loss is:\n",
            "264.9103654276114\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.26280790220993194\n",
            "The running loss is:\n",
            "267.06209781509824\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.2649425573562483\n",
            "The running loss is:\n",
            "262.0323102637194\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.2599526887536899\n",
            "The running loss is:\n",
            "267.5070057804696\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.2653839343060215\n",
            "The running loss is:\n",
            "257.62418994586915\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.2555795535177273\n",
            "The running loss is:\n",
            "256.8631043720525\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.2548245083056076\n",
            "The running loss is:\n",
            "259.1249689129181\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.2570684215405934\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -35.729027\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   16.565025\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   60.050892\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   95.583504\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -110.286934\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -54.536537\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   -7.929787\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   30.420792\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   61.316540\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 559c84u4 \n",
            "\n",
            "wandb: Agent Starting Run: muuraqrs with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: muuraqrs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/muuraqrs\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/muuraqrs</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "225.75949387002038\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 0\n",
            "0.2237457818335187\n",
            "The running loss is:\n",
            "168.8906795582734\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 1\n",
            "0.16738422156419563\n",
            "The running loss is:\n",
            "170.25132953720458\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 2\n",
            "0.1687327349228985\n",
            "The running loss is:\n",
            "166.20676435675705\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 3\n",
            "0.1647242461414837\n",
            "The running loss is:\n",
            "160.25710399751551\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 4\n",
            "0.1588276551016011\n",
            "The running loss is:\n",
            "155.85809439198783\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 5\n",
            "0.15446788344101867\n",
            "The running loss is:\n",
            "159.47748929887166\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 6\n",
            "0.15805499434972414\n",
            "The running loss is:\n",
            "151.81139983976755\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 7\n",
            "0.15045728428123642\n",
            "The running loss is:\n",
            "151.89980408451083\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 8\n",
            "0.15054489998464898\n",
            "The running loss is:\n",
            "151.51018837586162\n",
            "The number of items in train is: \n",
            "1009\n",
            "The loss for epoch 9\n",
            "0.1501587595400016\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -14.036416\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   17.400223\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   43.600792\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   65.121140\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   34.128967\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798   58.778484\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   78.912422\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   95.010124\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  107.500061\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: muuraqrs \n",
            "\n",
            "wandb: Agent Starting Run: xjdrttbq with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: xjdrttbq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/xjdrttbq\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/xjdrttbq</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "933.7901946306229\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.9263791613399036\n",
            "The running loss is:\n",
            "349.3704765816219\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.3465976950214503\n",
            "The running loss is:\n",
            "274.40974052262027\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.2722318854391074\n",
            "The running loss is:\n",
            "264.9103654276114\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.26280790220993194\n",
            "The running loss is:\n",
            "267.06209781509824\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.2649425573562483\n",
            "The running loss is:\n",
            "262.0323102637194\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.2599526887536899\n",
            "The running loss is:\n",
            "267.5070057804696\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.2653839343060215\n",
            "The running loss is:\n",
            "257.62418994586915\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.2555795535177273\n",
            "The running loss is:\n",
            "256.8631043720525\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.2548245083056076\n",
            "The running loss is:\n",
            "259.1249689129181\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.2570684215405934\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -35.729027\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   16.565025\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   60.050892\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   95.583504\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -110.286934\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -54.536537\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   -7.929787\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   30.420792\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   61.316540\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: xjdrttbq \n",
            "\n",
            "wandb: Agent Starting Run: 95d2ak6m with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 95d2ak6m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/95d2ak6m\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/95d2ak6m</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "268.8847557462432\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.26675074974825713\n",
            "The running loss is:\n",
            "190.3122949552819\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.1888018799159543\n",
            "The running loss is:\n",
            "179.56954029053668\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.17814438520886575\n",
            "The running loss is:\n",
            "174.9446345181932\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.17355618503789008\n",
            "The running loss is:\n",
            "167.97849120563114\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.16664532857701503\n",
            "The running loss is:\n",
            "162.44688228465384\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.16115762131414071\n",
            "The running loss is:\n",
            "157.71207322823102\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.15646039010737203\n",
            "The running loss is:\n",
            "167.09941479518596\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.16577322896347815\n",
            "The running loss is:\n",
            "154.3066622615861\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.15308200621189097\n",
            "The running loss is:\n",
            "151.13187272174764\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.14993241341443217\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652   -8.622521\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   -2.584061\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   34.648872\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797    7.901710\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798   43.276329\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   70.522148\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   90.786011\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  105.172302\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 95d2ak6m \n",
            "\n",
            "wandb: Agent Starting Run: ouby3v06 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: ouby3v06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/ouby3v06\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/ouby3v06</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "547.7902656344231\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.5434427238436738\n",
            "The running loss is:\n",
            "263.93586420456995\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.2618411351235813\n",
            "The running loss is:\n",
            "256.02735306468094\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.25399538994512\n",
            "The running loss is:\n",
            "253.4548436467303\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.25144329726858167\n",
            "The running loss is:\n",
            "250.60181285091676\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.2486129095743222\n",
            "The running loss is:\n",
            "246.55281008168822\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.24459604174770658\n",
            "The running loss is:\n",
            "244.45064377749804\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.24251055930307347\n",
            "The running loss is:\n",
            "239.31840878236108\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.23741905633170743\n",
            "The running loss is:\n",
            "240.4956249531824\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.23858692951704605\n",
            "The running loss is:\n",
            "239.42524314066395\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.23752504279827774\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -30.672371\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -1.674439\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  48.440495\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -85.838799\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -22.786095\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  27.085716\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  65.735161\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  94.829727\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: ouby3v06 \n",
            "\n",
            "wandb: Agent Starting Run: oporvdu2 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: oporvdu2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/oporvdu2\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/oporvdu2</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "268.8847557462432\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.26675074974825713\n",
            "The running loss is:\n",
            "190.3122949552819\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.1888018799159543\n",
            "The running loss is:\n",
            "179.56954029053668\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.17814438520886575\n",
            "The running loss is:\n",
            "174.9446345181932\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.17355618503789008\n",
            "The running loss is:\n",
            "167.97849120563114\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.16664532857701503\n",
            "The running loss is:\n",
            "162.44688228465384\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.16115762131414071\n",
            "The running loss is:\n",
            "157.71207322823102\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.15646039010737203\n",
            "The running loss is:\n",
            "167.09941479518596\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.16577322896347815\n",
            "The running loss is:\n",
            "154.3066622615861\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.15308200621189097\n",
            "The running loss is:\n",
            "151.13187272174764\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.14993241341443217\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652   -8.622521\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   -2.584061\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   34.648872\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797    7.901710\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798   43.276329\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   70.522148\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   90.786011\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  105.172302\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: oporvdu2 \n",
            "\n",
            "wandb: Agent Starting Run: z8jokqrd with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: z8jokqrd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/z8jokqrd\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/z8jokqrd</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "547.7902656344231\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.5434427238436738\n",
            "The running loss is:\n",
            "263.93586420456995\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.2618411351235813\n",
            "The running loss is:\n",
            "256.02735306468094\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.25399538994512\n",
            "The running loss is:\n",
            "253.4548436467303\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.25144329726858167\n",
            "The running loss is:\n",
            "250.60181285091676\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.2486129095743222\n",
            "The running loss is:\n",
            "246.55281008168822\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.24459604174770658\n",
            "The running loss is:\n",
            "244.45064377749804\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.24251055930307347\n",
            "The running loss is:\n",
            "239.31840878236108\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.23741905633170743\n",
            "The running loss is:\n",
            "240.4956249531824\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.23858692951704605\n",
            "The running loss is:\n",
            "239.42524314066395\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.23752504279827774\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -30.672371\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -1.674439\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  48.440495\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -85.838799\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -22.786095\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  27.085716\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  65.735161\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  94.829727\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: z8jokqrd \n",
            "\n",
            "wandb: Agent Starting Run: 60jwhvx0 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 60jwhvx0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/60jwhvx0\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/60jwhvx0</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "310.6132285701606\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.30814804421642916\n",
            "The running loss is:\n",
            "199.3861086012039\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.19780367916786099\n",
            "The running loss is:\n",
            "173.47535992788835\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.1720985713570321\n",
            "The running loss is:\n",
            "207.3924678559997\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.2057464958888886\n",
            "The running loss is:\n",
            "157.01501041611482\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.15576885953979644\n",
            "The running loss is:\n",
            "146.65488431609265\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.14549095666279033\n",
            "The running loss is:\n",
            "144.24584371602975\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.1431010354325692\n",
            "The running loss is:\n",
            "145.44982430528762\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.14429546062032503\n",
            "The running loss is:\n",
            "139.57766854360034\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.13846990926944477\n",
            "The running loss is:\n",
            "133.31263014740853\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.13225459340020687\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -21.318291\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653 -10.743669\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -28.506935\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -27.260811\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  19.193550\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  56.063610\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  84.571320\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 60jwhvx0 \n",
            "\n",
            "wandb: Agent Starting Run: ulvk6w38 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: ulvk6w38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/ulvk6w38\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/ulvk6w38</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "413.1037867013365\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 0\n",
            "0.4102321615703441\n",
            "The running loss is:\n",
            "263.73348939116113\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 1\n",
            "0.26190018807463866\n",
            "The running loss is:\n",
            "248.45114698377438\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 2\n",
            "0.24672407843473126\n",
            "The running loss is:\n",
            "242.97195723466575\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 3\n",
            "0.24128297639986668\n",
            "The running loss is:\n",
            "235.91033760271966\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 4\n",
            "0.2342704444912807\n",
            "The running loss is:\n",
            "227.70638415616122\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 5\n",
            "0.22612351951952456\n",
            "The running loss is:\n",
            "221.5770401164773\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 6\n",
            "0.2200367826380112\n",
            "The running loss is:\n",
            "222.17376778105972\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 7\n",
            "0.22062936224534233\n",
            "The running loss is:\n",
            "217.35000186529942\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 8\n",
            "0.21583912796951282\n",
            "The running loss is:\n",
            "216.53994869888993\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 9\n",
            "0.21503470575857986\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -39.941978\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -24.488182\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -63.962013\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -69.866356\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799    8.050612\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   66.421043\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  110.934242\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: ulvk6w38 \n",
            "\n",
            "wandb: Agent Starting Run: 6j2r2opb with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 6j2r2opb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/6j2r2opb\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/6j2r2opb</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "310.6132285701606\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 0\n",
            "0.30814804421642916\n",
            "The running loss is:\n",
            "199.3861086012039\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 1\n",
            "0.19780367916786099\n",
            "The running loss is:\n",
            "173.47535992788835\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 2\n",
            "0.1720985713570321\n",
            "The running loss is:\n",
            "207.3924678559997\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 3\n",
            "0.2057464958888886\n",
            "The running loss is:\n",
            "157.01501041611482\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 4\n",
            "0.15576885953979644\n",
            "The running loss is:\n",
            "146.65488431609265\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 5\n",
            "0.14549095666279033\n",
            "The running loss is:\n",
            "144.24584371602975\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 6\n",
            "0.1431010354325692\n",
            "The running loss is:\n",
            "145.44982430528762\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 7\n",
            "0.14429546062032503\n",
            "The running loss is:\n",
            "139.57766854360034\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 8\n",
            "0.13846990926944477\n",
            "The running loss is:\n",
            "133.31263014740853\n",
            "The number of items in train is: \n",
            "1008\n",
            "The loss for epoch 9\n",
            "0.13225459340020687\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -21.318291\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653 -10.743669\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -28.506935\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -27.260811\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  19.193550\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  56.063610\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  84.571320\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 6j2r2opb \n",
            "\n",
            "wandb: Agent Starting Run: 50tdyen9 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 50tdyen9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/50tdyen9\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/50tdyen9</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "413.1037867013365\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 0\n",
            "0.4102321615703441\n",
            "The running loss is:\n",
            "263.73348939116113\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 1\n",
            "0.26190018807463866\n",
            "The running loss is:\n",
            "248.45114698377438\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 2\n",
            "0.24672407843473126\n",
            "The running loss is:\n",
            "242.97195723466575\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 3\n",
            "0.24128297639986668\n",
            "The running loss is:\n",
            "235.91033760271966\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 4\n",
            "0.2342704444912807\n",
            "The running loss is:\n",
            "227.70638415616122\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 5\n",
            "0.22612351951952456\n",
            "The running loss is:\n",
            "221.5770401164773\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 6\n",
            "0.2200367826380112\n",
            "The running loss is:\n",
            "222.17376778105972\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 7\n",
            "0.22062936224534233\n",
            "The running loss is:\n",
            "217.35000186529942\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 8\n",
            "0.21583912796951282\n",
            "The running loss is:\n",
            "216.53994869888993\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 9\n",
            "0.21503470575857986\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -39.941978\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -24.488182\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -63.962013\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -69.866356\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799    8.050612\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   66.421043\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  110.934242\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 50tdyen9 \n",
            "\n",
            "wandb: Agent Starting Run: bc7dxubu with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: bc7dxubu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/bc7dxubu\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/bc7dxubu</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "252.67449925426627\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 0\n",
            "0.2509180727450509\n",
            "The running loss is:\n",
            "160.3520112684164\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 1\n",
            "0.15923734981967863\n",
            "The running loss is:\n",
            "130.89434963570602\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 2\n",
            "0.129984458426719\n",
            "The running loss is:\n",
            "118.46292745169194\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 3\n",
            "0.11763945129264343\n",
            "The running loss is:\n",
            "108.150761936452\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 4\n",
            "0.1073989691523853\n",
            "The running loss is:\n",
            "105.73167151300731\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 5\n",
            "0.10499669465045414\n",
            "The running loss is:\n",
            "103.14781161440442\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 6\n",
            "0.10243079604210965\n",
            "The running loss is:\n",
            "96.09112086484674\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 7\n",
            "0.09542315875357174\n",
            "The running loss is:\n",
            "89.4836444821176\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 8\n",
            "0.08886161318978908\n",
            "The running loss is:\n",
            "92.90229022515086\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 9\n",
            "0.09225649476181813\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -47.792458\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -45.675468\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -44.148216\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -45.957970\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   9.575294\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: bc7dxubu \n",
            "\n",
            "wandb: Agent Starting Run: jc4r2sb2 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: jc4r2sb2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/jc4r2sb2\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/jc4r2sb2</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "308.4397729054326\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 0\n",
            "0.3066001718741875\n",
            "The running loss is:\n",
            "189.99609787660302\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 1\n",
            "0.18886292035447616\n",
            "The running loss is:\n",
            "197.72661812306615\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 2\n",
            "0.196547334118356\n",
            "The running loss is:\n",
            "171.1795079233707\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 3\n",
            "0.1701585565838675\n",
            "The running loss is:\n",
            "165.40746919131198\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 4\n",
            "0.16442094353013118\n",
            "The running loss is:\n",
            "153.98258249275386\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 5\n",
            "0.15306419730890047\n",
            "The running loss is:\n",
            "148.59281770250527\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 6\n",
            "0.14770657823310662\n",
            "The running loss is:\n",
            "165.14938747498672\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 7\n",
            "0.16416440106857527\n",
            "The running loss is:\n",
            "151.12123375211377\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 8\n",
            "0.15021991426651468\n",
            "The running loss is:\n",
            "173.8011553232791\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 9\n",
            "0.17276456791578437\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647    0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648    0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -16.917732\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -60.528984\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -118.469963\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -111.236183\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   47.900902\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: jc4r2sb2 \n",
            "\n",
            "wandb: Agent Starting Run: xq16e5f9 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: xq16e5f9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/xq16e5f9\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/xq16e5f9</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "252.67449925426627\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 0\n",
            "0.2509180727450509\n",
            "The running loss is:\n",
            "160.3520112684164\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 1\n",
            "0.15923734981967863\n",
            "The running loss is:\n",
            "130.89434963570602\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 2\n",
            "0.129984458426719\n",
            "The running loss is:\n",
            "118.46292745169194\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 3\n",
            "0.11763945129264343\n",
            "The running loss is:\n",
            "108.150761936452\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 4\n",
            "0.1073989691523853\n",
            "The running loss is:\n",
            "105.73167151300731\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 5\n",
            "0.10499669465045414\n",
            "The running loss is:\n",
            "103.14781161440442\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 6\n",
            "0.10243079604210965\n",
            "The running loss is:\n",
            "96.09112086484674\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 7\n",
            "0.09542315875357174\n",
            "The running loss is:\n",
            "89.4836444821176\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 8\n",
            "0.08886161318978908\n",
            "The running loss is:\n",
            "92.90229022515086\n",
            "The number of items in train is: \n",
            "1007\n",
            "The loss for epoch 9\n",
            "0.09225649476181813\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -47.792458\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -45.675468\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -44.148216\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -45.957970\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   9.575294\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: xq16e5f9 \n",
            "\n",
            "wandb: Agent Starting Run: zcd6yy27 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: zcd6yy27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/zcd6yy27\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/zcd6yy27</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "308.4397729054326\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 0\n",
            "0.3066001718741875\n",
            "The running loss is:\n",
            "189.99609787660302\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 1\n",
            "0.18886292035447616\n",
            "The running loss is:\n",
            "197.72661812306615\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 2\n",
            "0.196547334118356\n",
            "The running loss is:\n",
            "171.1795079233707\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 3\n",
            "0.1701585565838675\n",
            "The running loss is:\n",
            "165.40746919131198\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 4\n",
            "0.16442094353013118\n",
            "The running loss is:\n",
            "153.98258249275386\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 5\n",
            "0.15306419730890047\n",
            "The running loss is:\n",
            "148.59281770250527\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 6\n",
            "0.14770657823310662\n",
            "The running loss is:\n",
            "165.14938747498672\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 7\n",
            "0.16416440106857527\n",
            "The running loss is:\n",
            "151.12123375211377\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 8\n",
            "0.15021991426651468\n",
            "The running loss is:\n",
            "173.8011553232791\n",
            "The number of items in train is: \n",
            "1006\n",
            "The loss for epoch 9\n",
            "0.17276456791578437\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647    0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648    0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -16.917732\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -60.528984\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -118.469963\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -111.236183\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   47.900902\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: zcd6yy27 \n",
            "\n",
            "wandb: Agent Starting Run: 1v6kvmfm with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 1v6kvmfm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/1v6kvmfm\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/1v6kvmfm</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "298.32922126601625\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 0\n",
            "0.29684499628459327\n",
            "The running loss is:\n",
            "227.31114723750943\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 1\n",
            "0.22618024600747208\n",
            "The running loss is:\n",
            "193.30239608266857\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 2\n",
            "0.1923406926195707\n",
            "The running loss is:\n",
            "170.0051733738619\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 3\n",
            "0.1691593764914049\n",
            "The running loss is:\n",
            "166.24890763210715\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 4\n",
            "0.1654217986389126\n",
            "The running loss is:\n",
            "149.74719110218575\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 5\n",
            "0.14900218020117986\n",
            "The running loss is:\n",
            "127.84148174877191\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 6\n",
            "0.12720545447638995\n",
            "The running loss is:\n",
            "122.3415934307254\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 7\n",
            "0.12173292878679144\n",
            "The running loss is:\n",
            "111.13901140703001\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 8\n",
            "0.11058608100201991\n",
            "The running loss is:\n",
            "106.88875915050994\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 9\n",
            "0.10635697427911436\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   0.746856\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  16.658180\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  32.731865\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  45.470764\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  89.491692\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 1v6kvmfm \n",
            "\n",
            "wandb: Agent Starting Run: mplojc47 with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: mplojc47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/mplojc47\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/mplojc47</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "427.8330704959226\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 0\n",
            "0.4257045477571369\n",
            "The running loss is:\n",
            "271.02647961641196\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 1\n",
            "0.2696780891705592\n",
            "The running loss is:\n",
            "235.38663783459924\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 2\n",
            "0.23421556003442712\n",
            "The running loss is:\n",
            "201.08433110409533\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 3\n",
            "0.2000839115463635\n",
            "The running loss is:\n",
            "194.26771916932194\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 4\n",
            "0.1933012131038029\n",
            "The running loss is:\n",
            "181.62987797893584\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 5\n",
            "0.1807262467452098\n",
            "The running loss is:\n",
            "191.4855257430754\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 6\n",
            "0.19053286143589593\n",
            "The running loss is:\n",
            "165.01230560266413\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 7\n",
            "0.16419134885837228\n",
            "The running loss is:\n",
            "156.58005148905795\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 8\n",
            "0.1558010462577691\n",
            "The running loss is:\n",
            "155.10277701867744\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 9\n",
            "0.15433112141161934\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644    0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645    0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646    0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647    0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648    0.000000\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   84.037422\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  145.514435\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  155.171829\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  175.245026\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  182.777100\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: mplojc47 \n",
            "\n",
            "wandb: Agent Starting Run: 5yc1zyjg with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 5yc1zyjg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/5yc1zyjg\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/5yc1zyjg</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "298.32922126601625\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 0\n",
            "0.29684499628459327\n",
            "The running loss is:\n",
            "227.31114723750943\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 1\n",
            "0.22618024600747208\n",
            "The running loss is:\n",
            "193.30239608266857\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 2\n",
            "0.1923406926195707\n",
            "The running loss is:\n",
            "170.0051733738619\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 3\n",
            "0.1691593764914049\n",
            "The running loss is:\n",
            "166.24890763210715\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 4\n",
            "0.1654217986389126\n",
            "The running loss is:\n",
            "149.74719110218575\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 5\n",
            "0.14900218020117986\n",
            "The running loss is:\n",
            "127.84148174877191\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 6\n",
            "0.12720545447638995\n",
            "The running loss is:\n",
            "122.3415934307254\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 7\n",
            "0.12173292878679144\n",
            "The running loss is:\n",
            "111.13901140703001\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 8\n",
            "0.11058608100201991\n",
            "The running loss is:\n",
            "106.88875915050994\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 9\n",
            "0.10635697427911436\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   0.746856\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  16.658180\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  32.731865\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  45.470764\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  89.491692\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 5yc1zyjg \n",
            "\n",
            "wandb: Agent Starting Run: oad4lv5h with config:\n",
            "\tbatch_size: 2\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: oad4lv5h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/oad4lv5h\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/oad4lv5h</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 2\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 2\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "427.8330704959226\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 0\n",
            "0.4257045477571369\n",
            "The running loss is:\n",
            "271.02647961641196\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 1\n",
            "0.2696780891705592\n",
            "The running loss is:\n",
            "235.38663783459924\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 2\n",
            "0.23421556003442712\n",
            "The running loss is:\n",
            "201.08433110409533\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 3\n",
            "0.2000839115463635\n",
            "The running loss is:\n",
            "194.26771916932194\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 4\n",
            "0.1933012131038029\n",
            "The running loss is:\n",
            "181.62987797893584\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 5\n",
            "0.1807262467452098\n",
            "The running loss is:\n",
            "191.4855257430754\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 6\n",
            "0.19053286143589593\n",
            "The running loss is:\n",
            "165.01230560266413\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 7\n",
            "0.16419134885837228\n",
            "The running loss is:\n",
            "156.58005148905795\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 8\n",
            "0.1558010462577691\n",
            "The running loss is:\n",
            "155.10277701867744\n",
            "The number of items in train is: \n",
            "1005\n",
            "The loss for epoch 9\n",
            "0.15433112141161934\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644    0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645    0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646    0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647    0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648    0.000000\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   84.037422\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  145.514435\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  155.171829\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  175.245026\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  182.777100\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: oad4lv5h \n",
            "\n",
            "wandb: Agent Starting Run: x4cx1s10 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: x4cx1s10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/x4cx1s10\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/x4cx1s10</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "145.32468241479364\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 0\n",
            "0.21593563508884642\n",
            "The running loss is:\n",
            "116.46407391293906\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 1\n",
            "0.17305211576959742\n",
            "The running loss is:\n",
            "107.0876562561607\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 2\n",
            "0.1591198458486786\n",
            "The running loss is:\n",
            "108.14875853573903\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 3\n",
            "0.16069652085548147\n",
            "The running loss is:\n",
            "107.43900547816884\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 4\n",
            "0.1596419100715733\n",
            "The running loss is:\n",
            "105.17393486155197\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 5\n",
            "0.15627627765460916\n",
            "The running loss is:\n",
            "105.34383070806507\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 6\n",
            "0.15652872319177574\n",
            "The running loss is:\n",
            "106.39942755606899\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 7\n",
            "0.1580972177653328\n",
            "The running loss is:\n",
            "100.39558869751636\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 8\n",
            "0.14917620906020262\n",
            "The running loss is:\n",
            "102.57377034994715\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 9\n",
            "0.15241273454672682\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652    2.746414\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   43.208084\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   75.097450\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   99.873940\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   76.163200\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  102.451309\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  122.580147\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  137.598282\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  148.375824\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: x4cx1s10 \n",
            "\n",
            "wandb: Agent Starting Run: 2cn27u0m with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 2cn27u0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/2cn27u0m\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/2cn27u0m</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "700.5246332213283\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "1.0424473708650719\n",
            "The running loss is:\n",
            "345.5336855677888\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.5141870320949238\n",
            "The running loss is:\n",
            "194.99078989657573\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.29016486591752344\n",
            "The running loss is:\n",
            "175.27101571499952\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.26081996386160644\n",
            "The running loss is:\n",
            "171.99262900301255\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.2559414122068639\n",
            "The running loss is:\n",
            "174.8434474307578\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.2601837015338658\n",
            "The running loss is:\n",
            "172.25317678204738\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.25632913211614194\n",
            "The running loss is:\n",
            "174.17536212387495\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.259189526970052\n",
            "The running loss is:\n",
            "172.04998497129418\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.25602676335014013\n",
            "The running loss is:\n",
            "171.807736213319\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.2556662741269628\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -31.604805\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  17.386505\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  55.665630\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655  84.845367\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -68.406319\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -18.363411\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  20.808975\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  50.747482\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  72.842339\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 2cn27u0m \n",
            "\n",
            "wandb: Agent Starting Run: 4oec6gv8 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 4oec6gv8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/4oec6gv8\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/4oec6gv8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "145.32468241479364\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 0\n",
            "0.21593563508884642\n",
            "The running loss is:\n",
            "116.46407391293906\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 1\n",
            "0.17305211576959742\n",
            "The running loss is:\n",
            "107.0876562561607\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 2\n",
            "0.1591198458486786\n",
            "The running loss is:\n",
            "108.14875853573903\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 3\n",
            "0.16069652085548147\n",
            "The running loss is:\n",
            "107.43900547816884\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 4\n",
            "0.1596419100715733\n",
            "The running loss is:\n",
            "105.17393486155197\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 5\n",
            "0.15627627765460916\n",
            "The running loss is:\n",
            "105.34383070806507\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 6\n",
            "0.15652872319177574\n",
            "The running loss is:\n",
            "106.39942755606899\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 7\n",
            "0.1580972177653328\n",
            "The running loss is:\n",
            "100.39558869751636\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 8\n",
            "0.14917620906020262\n",
            "The running loss is:\n",
            "102.57377034994715\n",
            "The number of items in train is: \n",
            "673\n",
            "The loss for epoch 9\n",
            "0.15241273454672682\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652    2.746414\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   43.208084\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   75.097450\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   99.873940\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797   76.163200\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  102.451309\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  122.580147\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  137.598282\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  148.375824\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 4oec6gv8 \n",
            "\n",
            "wandb: Agent Starting Run: 5qr24mb3 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 5qr24mb3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/5qr24mb3\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/5qr24mb3</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "700.5246332213283\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "1.0424473708650719\n",
            "The running loss is:\n",
            "345.5336855677888\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.5141870320949238\n",
            "The running loss is:\n",
            "194.99078989657573\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.29016486591752344\n",
            "The running loss is:\n",
            "175.27101571499952\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.26081996386160644\n",
            "The running loss is:\n",
            "171.99262900301255\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.2559414122068639\n",
            "The running loss is:\n",
            "174.8434474307578\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.2601837015338658\n",
            "The running loss is:\n",
            "172.25317678204738\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.25632913211614194\n",
            "The running loss is:\n",
            "174.17536212387495\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.259189526970052\n",
            "The running loss is:\n",
            "172.04998497129418\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.25602676335014013\n",
            "The running loss is:\n",
            "171.807736213319\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.2556662741269628\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -31.604805\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  17.386505\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  55.665630\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655  84.845367\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -68.406319\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -18.363411\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  20.808975\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  50.747482\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  72.842339\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 5qr24mb3 \n",
            "\n",
            "wandb: Agent Starting Run: wq0qbc23 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: wq0qbc23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/wq0qbc23\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/wq0qbc23</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "160.2835898270132\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.2385172467663887\n",
            "The running loss is:\n",
            "131.05705622548703\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.19502538128792712\n",
            "The running loss is:\n",
            "115.26158407668117\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.17152021439982318\n",
            "The running loss is:\n",
            "119.77284053905169\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.1782333936593031\n",
            "The running loss is:\n",
            "108.87537902299664\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.16201693306993548\n",
            "The running loss is:\n",
            "107.32264693066827\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.15970631983730396\n",
            "The running loss is:\n",
            "108.08884476087405\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.1608464951798721\n",
            "The running loss is:\n",
            "104.78168833316886\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.15592513144816794\n",
            "The running loss is:\n",
            "102.86266552051529\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.15306944273886205\n",
            "The running loss is:\n",
            "102.88070193893509\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.15309628264722483\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -10.003373\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -6.928421\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  32.216713\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -33.658257\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  10.329619\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  45.619148\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  74.442635\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  97.375786\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: wq0qbc23 \n",
            "\n",
            "wandb: Agent Starting Run: 1vx522u0 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 1vx522u0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/1vx522u0\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/1vx522u0</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "423.2734785247594\n",
            "The number of items in train is: \n",
            "The loss for epoch 0\n",
            "672\n",
            "0.6298712478047015\n",
            "The running loss is:\n",
            "178.99772117874818\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.2663656565159943\n",
            "The running loss is:\n",
            "167.60280217393301\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.24940893180644794\n",
            "The running loss is:\n",
            "164.62128745415248\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.24497215394963168\n",
            "The running loss is:\n",
            "154.51417936198413\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.2299318145267621\n",
            "The running loss is:\n",
            "152.14486617338844\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.2264060508532566\n",
            "The running loss is:\n",
            "146.90142093098257\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.2186033049568193\n",
            "The running loss is:\n",
            "145.32377014914528\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.21625561034099\n",
            "The running loss is:\n",
            "143.3477709252038\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.2133151353053628\n",
            "The running loss is:\n",
            "139.31286315468606\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.20731080826590187\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -19.971840\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -21.307472\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   18.633606\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -75.831978\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -23.927406\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   33.960213\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   79.785110\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  109.187881\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 1vx522u0 \n",
            "\n",
            "wandb: Agent Starting Run: 1crosnld with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 1crosnld\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/1crosnld\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/1crosnld</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "160.2835898270132\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.2385172467663887\n",
            "The running loss is:\n",
            "131.05705622548703\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.19502538128792712\n",
            "The running loss is:\n",
            "115.26158407668117\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.17152021439982318\n",
            "The running loss is:\n",
            "119.77284053905169\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.1782333936593031\n",
            "The running loss is:\n",
            "108.87537902299664\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.16201693306993548\n",
            "The running loss is:\n",
            "107.32264693066827\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.15970631983730396\n",
            "The running loss is:\n",
            "108.08884476087405\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.1608464951798721\n",
            "The running loss is:\n",
            "104.78168833316886\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.15592513144816794\n",
            "The running loss is:\n",
            "102.86266552051529\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.15306944273886205\n",
            "The running loss is:\n",
            "102.88070193893509\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.15309628264722483\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -10.003373\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -6.928421\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  32.216713\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -33.658257\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  10.329619\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  45.619148\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  74.442635\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  97.375786\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 1crosnld \n",
            "\n",
            "wandb: Agent Starting Run: ss4wyi9m with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: ss4wyi9m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/ss4wyi9m\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/ss4wyi9m</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "423.2734785247594\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.6298712478047015\n",
            "The running loss is:\n",
            "178.99772117874818\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.2663656565159943\n",
            "The running loss is:\n",
            "167.60280217393301\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.24940893180644794\n",
            "The running loss is:\n",
            "164.62128745415248\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.24497215394963168\n",
            "The running loss is:\n",
            "154.51417936198413\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.2299318145267621\n",
            "The running loss is:\n",
            "152.14486617338844\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.2264060508532566\n",
            "The running loss is:\n",
            "146.90142093098257\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.2186033049568193\n",
            "The running loss is:\n",
            "145.32377014914528\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.21625561034099\n",
            "The running loss is:\n",
            "143.3477709252038\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.2133151353053628\n",
            "The running loss is:\n",
            "139.31286315468606\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.20731080826590187\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -19.971840\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -21.307472\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   18.633606\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -75.831978\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -23.927406\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   33.960213\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   79.785110\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  109.187881\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: ss4wyi9m \n",
            "\n",
            "wandb: Agent Starting Run: 2cn9c7td with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 2cn9c7td\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/2cn9c7td\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/2cn9c7td</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "200.31047576316632\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.2980810651237594\n",
            "The running loss is:\n",
            "127.05177408736199\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.18906514001095534\n",
            "The running loss is:\n",
            "113.34593993879389\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.16866955348034804\n",
            "The running loss is:\n",
            "104.1250312642951\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.15494796319091533\n",
            "The running loss is:\n",
            "94.18516169404029\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.1401564906161314\n",
            "The running loss is:\n",
            "90.91590645330143\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.13529152746026998\n",
            "The running loss is:\n",
            "86.48784158474882\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.12870214521540002\n",
            "The running loss is:\n",
            "82.2479831717792\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.1223928321008619\n",
            "The running loss is:\n",
            "79.89802166912705\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.11889586557905811\n",
            "The running loss is:\n",
            "79.68442106479051\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.11857800753689064\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -15.499116\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653 -10.331338\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -24.715599\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -25.801338\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   9.913543\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  47.544250\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  89.138863\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 2cn9c7td \n",
            "\n",
            "wandb: Agent Starting Run: gc95qagz with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: gc95qagz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/gc95qagz\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/gc95qagz</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "282.34033377002925\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.42014930620540064\n",
            "The running loss is:\n",
            "178.45184405823238\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.26555333937236963\n",
            "The running loss is:\n",
            "167.05238516186364\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.2485898588718209\n",
            "The running loss is:\n",
            "160.31228574411944\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.23855994902398725\n",
            "The running loss is:\n",
            "154.54049926321022\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.22997098104644378\n",
            "The running loss is:\n",
            "153.61805905413348\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.2285983021638891\n",
            "The running loss is:\n",
            "153.29215721681248\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.22811332919168525\n",
            "The running loss is:\n",
            "148.6991692997981\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.22127852574374715\n",
            "The running loss is:\n",
            "148.1749842602294\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.2204984884824842\n",
            "The running loss is:\n",
            "147.92400988889858\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.2201250147156229\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -29.909447\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -21.620567\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -44.523720\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -51.225471\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   25.174355\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   80.683174\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  121.458008\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: gc95qagz \n",
            "\n",
            "wandb: Agent Starting Run: cxesad83 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: cxesad83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/cxesad83\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/cxesad83</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "200.31047576316632\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.2980810651237594\n",
            "The running loss is:\n",
            "127.05177408736199\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.18906514001095534\n",
            "The running loss is:\n",
            "113.34593993879389\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.16866955348034804\n",
            "The running loss is:\n",
            "104.1250312642951\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.15494796319091533\n",
            "The running loss is:\n",
            "94.18516169404029\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.1401564906161314\n",
            "The running loss is:\n",
            "90.91590645330143\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.13529152746026998\n",
            "The running loss is:\n",
            "86.48784158474882\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.12870214521540002\n",
            "The running loss is:\n",
            "82.2479831717792\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.1223928321008619\n",
            "The running loss is:\n",
            "79.89802166912705\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.11889586557905811\n",
            "The running loss is:\n",
            "79.68442106479051\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.11857800753689064\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652 -15.499116\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653 -10.331338\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -24.715599\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -25.801338\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   9.913543\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  47.544250\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  89.138863\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: cxesad83 \n",
            "\n",
            "wandb: Agent Starting Run: k9x98evi with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: k9x98evi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/k9x98evi\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/k9x98evi</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "282.34033377002925\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 0\n",
            "0.42014930620540064\n",
            "The running loss is:\n",
            "178.45184405823238\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 1\n",
            "0.26555333937236963\n",
            "The running loss is:\n",
            "167.05238516186364\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 2\n",
            "0.2485898588718209\n",
            "The running loss is:\n",
            "160.31228574411944\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 3\n",
            "0.23855994902398725\n",
            "The running loss is:\n",
            "154.54049926321022\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 4\n",
            "0.22997098104644378\n",
            "The running loss is:\n",
            "153.61805905413348\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 5\n",
            "0.2285983021638891\n",
            "The running loss is:\n",
            "153.29215721681248\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 6\n",
            "0.22811332919168525\n",
            "The running loss is:\n",
            "148.6991692997981\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 7\n",
            "0.22127852574374715\n",
            "The running loss is:\n",
            "148.1749842602294\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 8\n",
            "0.2204984884824842\n",
            "The running loss is:\n",
            "147.92400988889858\n",
            "The number of items in train is: \n",
            "672\n",
            "The loss for epoch 9\n",
            "0.2201250147156229\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -29.909447\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -21.620567\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797  -44.523720\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -51.225471\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   25.174355\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   80.683174\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  121.458008\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: k9x98evi \n",
            "\n",
            "wandb: Agent Starting Run: oaugdtue with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: oaugdtue\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/oaugdtue\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/oaugdtue</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "167.8957697872247\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 0\n",
            "0.25021724260391165\n",
            "The running loss is:\n",
            "92.12747396043778\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 1\n",
            "0.13729876894253024\n",
            "The running loss is:\n",
            "80.6067989137373\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 2\n",
            "0.12012935754655334\n",
            "The running loss is:\n",
            "76.22210351243848\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 3\n",
            "0.11359478913925258\n",
            "The running loss is:\n",
            "74.18731573145487\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 4\n",
            "0.11056231852675838\n",
            "The running loss is:\n",
            "72.11988831723284\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 5\n",
            "0.10748120464565251\n",
            "The running loss is:\n",
            "70.40085715983878\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 6\n",
            "0.10491931022330668\n",
            "The running loss is:\n",
            "64.19870440318482\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 7\n",
            "0.09567616155467186\n",
            "The running loss is:\n",
            "66.1726555483474\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 8\n",
            "0.09861796654001102\n",
            "The running loss is:\n",
            "62.281757922435645\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 9\n",
            "0.09281931135981467\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -17.722435\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -22.622490\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -29.980446\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -30.161186\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  27.433037\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: oaugdtue \n",
            "\n",
            "wandb: Agent Starting Run: 1jca6shv with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 1jca6shv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/1jca6shv\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/1jca6shv</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "192.81321585690603\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 0\n",
            "0.28735203555425637\n",
            "The running loss is:\n",
            "121.0410763915861\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 1\n",
            "0.18038908553142488\n",
            "The running loss is:\n",
            "115.27447543130256\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 2\n",
            "0.17179504535216478\n",
            "The running loss is:\n",
            "110.75675887730904\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 3\n",
            "0.16506223379628768\n",
            "The running loss is:\n",
            "105.55804394168081\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 4\n",
            "0.15731452152262415\n",
            "The running loss is:\n",
            "104.08330041670706\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 5\n",
            "0.15511669212624002\n",
            "The running loss is:\n",
            "101.33097073534736\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 6\n",
            "0.15101485951616597\n",
            "The running loss is:\n",
            "99.79089563060552\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 7\n",
            "0.1487196656193823\n",
            "The running loss is:\n",
            "97.7596383888158\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 8\n",
            "0.14569245661522473\n",
            "The running loss is:\n",
            "97.2276455082465\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 9\n",
            "0.1448996207276401\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -63.169044\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -63.210060\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -69.999199\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -71.091499\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  48.602482\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 1jca6shv \n",
            "\n",
            "wandb: Agent Starting Run: bhvbj7z0 with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: bhvbj7z0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/bhvbj7z0\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/bhvbj7z0</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "167.8957697872247\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 0\n",
            "0.25021724260391165\n",
            "The running loss is:\n",
            "92.12747396043778\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 1\n",
            "0.13729876894253024\n",
            "The running loss is:\n",
            "80.6067989137373\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 2\n",
            "0.12012935754655334\n",
            "The running loss is:\n",
            "76.22210351243848\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 3\n",
            "0.11359478913925258\n",
            "The running loss is:\n",
            "74.18731573145487\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 4\n",
            "0.11056231852675838\n",
            "The running loss is:\n",
            "72.11988831723284\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 5\n",
            "0.10748120464565251\n",
            "The running loss is:\n",
            "70.40085715983878\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 6\n",
            "0.10491931022330668\n",
            "The running loss is:\n",
            "64.19870440318482\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 7\n",
            "0.09567616155467186\n",
            "The running loss is:\n",
            "66.1726555483474\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 8\n",
            "0.09861796654001102\n",
            "The running loss is:\n",
            "62.281757922435645\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 9\n",
            "0.09281931135981467\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -17.722435\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -22.622490\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -29.980446\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -30.161186\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  27.433037\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: bhvbj7z0 \n",
            "\n",
            "wandb: Agent Starting Run: wdn4rt3v with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: wdn4rt3v\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/wdn4rt3v\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/wdn4rt3v</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "192.81321585690603\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 0\n",
            "0.28735203555425637\n",
            "The running loss is:\n",
            "121.0410763915861\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 1\n",
            "0.18038908553142488\n",
            "The running loss is:\n",
            "115.27447543130256\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 2\n",
            "0.17179504535216478\n",
            "The running loss is:\n",
            "110.75675887730904\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 3\n",
            "0.16506223379628768\n",
            "The running loss is:\n",
            "105.55804394168081\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 4\n",
            "0.15731452152262415\n",
            "The running loss is:\n",
            "104.08330041670706\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 5\n",
            "0.15511669212624002\n",
            "The running loss is:\n",
            "101.33097073534736\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 6\n",
            "0.15101485951616597\n",
            "The running loss is:\n",
            "99.79089563060552\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 7\n",
            "0.1487196656193823\n",
            "The running loss is:\n",
            "97.7596383888158\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 8\n",
            "0.14569245661522473\n",
            "The running loss is:\n",
            "97.2276455082465\n",
            "The number of items in train is: \n",
            "671\n",
            "The loss for epoch 9\n",
            "0.1448996207276401\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -63.169044\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -63.210060\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -69.999199\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -71.091499\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  48.602482\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: wdn4rt3v \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:11.447875, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Starting Run: 3um2zdtp with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 3um2zdtp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/3um2zdtp\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/3um2zdtp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:11.103906, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is:\n",
            "257.7247743103653\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 0\n",
            "0.3846638422542766\n",
            "The running loss is:\n",
            "161.962570019532\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 1\n",
            "0.24173517913362985\n",
            "The running loss is:\n",
            "133.3472663569264\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 2\n",
            "0.1990257706819797\n",
            "The running loss is:\n",
            "127.32758991396986\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 3\n",
            "0.19004117897607442\n",
            "The running loss is:\n",
            "125.20265228301287\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 4\n",
            "0.18686963027315354\n",
            "The running loss is:\n",
            "119.43329036352225\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 5\n",
            "0.1782586423336153\n",
            "The running loss is:\n",
            "112.04531666147523\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 6\n",
            "0.1672318159126496\n",
            "The running loss is:\n",
            "109.93093851348385\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 7\n",
            "0.16407602763206544\n",
            "The running loss is:\n",
            "103.84241046430543\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 8\n",
            "0.15498867233478422\n",
            "The running loss is:\n",
            "108.39421826961916\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 9\n",
            "0.16178241532778978\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -31.084648\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -25.342186\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -45.334129\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -17.535286\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801 -11.124352\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 3um2zdtp \n",
            "\n",
            "wandb: Agent Starting Run: zl629r7v with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: zl629r7v\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/zl629r7v\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/zl629r7v</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "179.92859912890708\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 0\n",
            "0.26855014795359267\n",
            "The running loss is:\n",
            "135.87861181766493\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 1\n",
            "0.2028038982353208\n",
            "The running loss is:\n",
            "115.70388403066318\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 2\n",
            "0.17269236422487041\n",
            "The running loss is:\n",
            "110.37320532614831\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 3\n",
            "0.16473612735246015\n",
            "The running loss is:\n",
            "103.14512282429496\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 4\n",
            "0.15394794451387306\n",
            "The running loss is:\n",
            "102.95642410794972\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 5\n",
            "0.1536663046387309\n",
            "The running loss is:\n",
            "93.86792059746222\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 6\n",
            "0.140101374026063\n",
            "The running loss is:\n",
            "88.62026767712086\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 7\n",
            "0.13226905623450874\n",
            "The running loss is:\n",
            "81.85145175183425\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 8\n",
            "0.12216634589826007\n",
            "The running loss is:\n",
            "70.86909741644922\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 9\n",
            "0.10577477226335705\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -15.229989\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -7.901070\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   6.253677\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   6.120208\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  58.550800\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: zl629r7v \n",
            "\n",
            "wandb: Agent Starting Run: x73x5ngb with config:\n",
            "\tbatch_size: 3\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: x73x5ngb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/x73x5ngb\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/x73x5ngb</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 3\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 3\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "257.7247743103653\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 0\n",
            "0.3846638422542766\n",
            "The running loss is:\n",
            "161.962570019532\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 1\n",
            "0.24173517913362985\n",
            "The running loss is:\n",
            "133.3472663569264\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 2\n",
            "0.1990257706819797\n",
            "The running loss is:\n",
            "127.32758991396986\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 3\n",
            "0.19004117897607442\n",
            "The running loss is:\n",
            "125.20265228301287\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 4\n",
            "0.18686963027315354\n",
            "The running loss is:\n",
            "119.43329036352225\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 5\n",
            "0.1782586423336153\n",
            "The running loss is:\n",
            "112.04531666147523\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 6\n",
            "0.1672318159126496\n",
            "The running loss is:\n",
            "109.93093851348385\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 7\n",
            "0.16407602763206544\n",
            "The running loss is:\n",
            "103.84241046430543\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 8\n",
            "0.15498867233478422\n",
            "The running loss is:\n",
            "108.39421826961916\n",
            "The number of items in train is: \n",
            "670\n",
            "The loss for epoch 9\n",
            "0.16178241532778978\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -31.084648\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -25.342186\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -45.334129\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -17.535286\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801 -11.124352\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: x73x5ngb \n",
            "\n",
            "wandb: Agent Starting Run: 8ayffi88 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 8ayffi88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/8ayffi88\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/8ayffi88</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "106.50183541962178\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 0\n",
            "0.21089472360321146\n",
            "The running loss is:\n",
            "85.44492420053575\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 1\n",
            "0.1691978697040312\n",
            "The running loss is:\n",
            "81.5426599184284\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 2\n",
            "0.1614706136998582\n",
            "The running loss is:\n",
            "79.08744200353976\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 3\n",
            "0.1566087960466134\n",
            "The running loss is:\n",
            "80.65137544739991\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 4\n",
            "0.15970569395524736\n",
            "The running loss is:\n",
            "78.02460212807637\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 5\n",
            "0.1545041626298542\n",
            "The running loss is:\n",
            "78.02246088185348\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 6\n",
            "0.1544999225383237\n",
            "The running loss is:\n",
            "77.41432459652424\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 7\n",
            "0.15329569227034504\n",
            "The running loss is:\n",
            "75.30790879554115\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 8\n",
            "0.14912457187235872\n",
            "The running loss is:\n",
            "76.10199938120786\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 9\n",
            "0.15069702847763933\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -26.728233\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   -1.702950\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   18.974953\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   35.672806\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -203.021790\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -166.013824\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -134.365707\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -107.624519\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  -85.375694\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 8ayffi88 \n",
            "\n",
            "wandb: Agent Starting Run: 3hz7b1qr with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 3hz7b1qr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/3hz7b1qr\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/3hz7b1qr</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "557.2717424631119\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "1.1056979017125235\n",
            "The running loss is:\n",
            "328.97836297750473\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.6527348471775888\n",
            "The running loss is:\n",
            "181.39039003290236\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.35990156752559993\n",
            "The running loss is:\n",
            "135.35250611323863\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.26855655974848935\n",
            "The running loss is:\n",
            "130.84117375477217\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.2596055034816908\n",
            "The running loss is:\n",
            "126.72581805521622\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.25144011518892107\n",
            "The running loss is:\n",
            "129.2045273259282\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.2563581891387465\n",
            "The running loss is:\n",
            "127.90318114403635\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.2537761530635642\n",
            "The running loss is:\n",
            "127.23056576540694\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.2524415987408868\n",
            "The running loss is:\n",
            "126.96789362281561\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.25192042385479285\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -34.590569\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   11.851714\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   48.074196\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   75.584900\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -107.935417\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -53.418465\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  -10.312783\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   23.065453\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   48.151608\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 3hz7b1qr \n",
            "\n",
            "wandb: Agent Starting Run: omd91ymr with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: omd91ymr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/omd91ymr\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/omd91ymr</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "106.50183541962178\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 0\n",
            "0.21089472360321146\n",
            "The running loss is:\n",
            "85.44492420053575\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 1\n",
            "0.1691978697040312\n",
            "The running loss is:\n",
            "81.5426599184284\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 2\n",
            "0.1614706136998582\n",
            "The running loss is:\n",
            "79.08744200353976\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 3\n",
            "0.1566087960466134\n",
            "The running loss is:\n",
            "80.65137544739991\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 4\n",
            "0.15970569395524736\n",
            "The running loss is:\n",
            "78.02460212807637\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 5\n",
            "0.1545041626298542\n",
            "The running loss is:\n",
            "78.02246088185348\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 6\n",
            "0.1544999225383237\n",
            "The running loss is:\n",
            "77.41432459652424\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 7\n",
            "0.15329569227034504\n",
            "The running loss is:\n",
            "75.30790879554115\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 8\n",
            "0.14912457187235872\n",
            "The running loss is:\n",
            "76.10199938120786\n",
            "The number of items in train is: \n",
            "505\n",
            "The loss for epoch 9\n",
            "0.15069702847763933\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -26.728233\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   -1.702950\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   18.974953\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   35.672806\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -203.021790\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -166.013824\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -134.365707\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -107.624519\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  -85.375694\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: omd91ymr \n",
            "\n",
            "wandb: Agent Starting Run: 8yp6it7u with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 1\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: 8yp6it7u\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/8yp6it7u\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/8yp6it7u</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 1\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 1\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 1\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 1\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "557.2717424631119\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "1.1056979017125235\n",
            "The running loss is:\n",
            "328.97836297750473\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.6527348471775888\n",
            "The running loss is:\n",
            "181.39039003290236\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.35990156752559993\n",
            "The running loss is:\n",
            "135.35250611323863\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.26855655974848935\n",
            "The running loss is:\n",
            "130.84117375477217\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.2596055034816908\n",
            "The running loss is:\n",
            "126.72581805521622\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.25144011518892107\n",
            "The running loss is:\n",
            "129.2045273259282\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.2563581891387465\n",
            "The running loss is:\n",
            "127.90318114403635\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.2537761530635642\n",
            "The running loss is:\n",
            "127.23056576540694\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.2524415987408868\n",
            "The running loss is:\n",
            "126.96789362281561\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.25192042385479285\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 1, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -34.590569\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653   11.851714\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   48.074196\n",
            "2655        5595 2006-08-22 03:00:00  ...            2655   75.584900\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -107.935417\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -53.418465\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  -10.312783\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   23.065453\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   48.151608\n",
            "\n",
            "[151 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 8yp6it7u \n",
            "\n",
            "wandb: Agent Starting Run: 46qi5t42 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 46qi5t42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/46qi5t42\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/46qi5t42</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "120.07235805527307\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.23823880566522435\n",
            "The running loss is:\n",
            "89.40195317310281\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.17738482772441033\n",
            "The running loss is:\n",
            "88.23260280652903\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.1750646881081925\n",
            "The running loss is:\n",
            "80.35663147247396\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.15943776085808326\n",
            "The running loss is:\n",
            "81.3506485261023\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.16141001691686965\n",
            "The running loss is:\n",
            "79.65543029922992\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.15804648868894824\n",
            "The running loss is:\n",
            "80.07404162315652\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.15887706671261215\n",
            "The running loss is:\n",
            "78.64794937102124\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.1560475185932961\n",
            "The running loss is:\n",
            "77.1476397496881\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.15307071378906367\n",
            "The running loss is:\n",
            "76.9405389202293\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.1526597994448994\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -5.082856\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -7.013710\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  34.019577\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -29.640678\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  17.000801\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  50.845219\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  74.243225\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  90.008469\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 46qi5t42 \n",
            "\n",
            "wandb: Agent Starting Run: lnqnbxgr with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: lnqnbxgr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/lnqnbxgr\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/lnqnbxgr</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "349.7666872367263\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.6939815222950918\n",
            "The running loss is:\n",
            "141.57476020790637\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.2809023019998142\n",
            "The running loss is:\n",
            "126.98461383674294\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.25195359888242647\n",
            "The running loss is:\n",
            "119.43351993942633\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.23697126972108398\n",
            "The running loss is:\n",
            "114.40059022721834\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.22698529806987766\n",
            "The running loss is:\n",
            "114.05798162845895\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.22630551910408522\n",
            "The running loss is:\n",
            "108.45086457207799\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.21518028684936108\n",
            "The running loss is:\n",
            "106.22482504416257\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.21076354175429082\n",
            "The running loss is:\n",
            "107.29193259216845\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.21288081863525485\n",
            "The running loss is:\n",
            "104.82055429695174\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.20797729027172965\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -23.800087\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653    2.447319\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   53.359665\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -105.415504\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -36.818047\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   36.108078\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   98.221909\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  144.574524\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: lnqnbxgr \n",
            "\n",
            "wandb: Agent Starting Run: 4liyf0np with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 4liyf0np\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/4liyf0np\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/4liyf0np</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "120.07235805527307\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.23823880566522435\n",
            "The running loss is:\n",
            "89.40195317310281\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.17738482772441033\n",
            "The running loss is:\n",
            "88.23260280652903\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.1750646881081925\n",
            "The running loss is:\n",
            "80.35663147247396\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.15943776085808326\n",
            "The running loss is:\n",
            "81.3506485261023\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.16141001691686965\n",
            "The running loss is:\n",
            "79.65543029922992\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.15804648868894824\n",
            "The running loss is:\n",
            "80.07404162315652\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.15887706671261215\n",
            "The running loss is:\n",
            "78.64794937102124\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.1560475185932961\n",
            "The running loss is:\n",
            "77.1476397496881\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.15307071378906367\n",
            "The running loss is:\n",
            "76.9405389202293\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.1526597994448994\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -5.082856\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -7.013710\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654  34.019577\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -29.640678\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  17.000801\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  50.845219\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  74.243225\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  90.008469\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 4liyf0np \n",
            "\n",
            "wandb: Agent Starting Run: rt9vw7ja with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 2\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: rt9vw7ja\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/rt9vw7ja\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/rt9vw7ja</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 2\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 2\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 2\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 2\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "349.7666872367263\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.6939815222950918\n",
            "The running loss is:\n",
            "141.57476020790637\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.2809023019998142\n",
            "The running loss is:\n",
            "126.98461383674294\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.25195359888242647\n",
            "The running loss is:\n",
            "119.43351993942633\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.23697126972108398\n",
            "The running loss is:\n",
            "114.40059022721834\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.22698529806987766\n",
            "The running loss is:\n",
            "114.05798162845895\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.22630551910408522\n",
            "The running loss is:\n",
            "108.45086457207799\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.21518028684936108\n",
            "The running loss is:\n",
            "106.22482504416257\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.21076354175429082\n",
            "The running loss is:\n",
            "107.29193259216845\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.21288081863525485\n",
            "The running loss is:\n",
            "104.82055429695174\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.20797729027172965\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 2, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -23.800087\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653    2.447319\n",
            "2654        5594 2006-08-22 02:00:00  ...            2654   53.359665\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -105.415504\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -36.818047\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   36.108078\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   98.221909\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  144.574524\n",
            "\n",
            "[152 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: rt9vw7ja \n",
            "\n",
            "wandb: Agent Starting Run: 8e8y7te6 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 8e8y7te6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/8e8y7te6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/8e8y7te6</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "150.76347963500302\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.29913388816468856\n",
            "The running loss is:\n",
            "100.61865028290777\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.1996401791327535\n",
            "The running loss is:\n",
            "87.66522326297127\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.17393893504557792\n",
            "The running loss is:\n",
            "79.37502496165689\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.15749012889217637\n",
            "The running loss is:\n",
            "81.09844061324839\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.16090960439136584\n",
            "The running loss is:\n",
            "73.06609116005711\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.14497240309535142\n",
            "The running loss is:\n",
            "72.6316595392127\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.144110435593676\n",
            "The running loss is:\n",
            "72.37297577073332\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.14359717414828038\n",
            "The running loss is:\n",
            "68.34778873156756\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.1356106919277134\n",
            "The running loss is:\n",
            "70.53053408052074\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.1399415358740491\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -25.345436\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -15.776971\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -101.608070\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -102.203835\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  -53.439491\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  -13.487466\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   19.278763\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 8e8y7te6 \n",
            "\n",
            "wandb: Agent Starting Run: ee5zrlkz with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: ee5zrlkz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/ee5zrlkz\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/ee5zrlkz</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "211.8019266948104\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.42024191804525873\n",
            "The running loss is:\n",
            "135.54967197868973\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.26894776186247965\n",
            "The running loss is:\n",
            "120.14834518544376\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.23838957378064238\n",
            "The running loss is:\n",
            "110.10778152896091\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.21846782049397007\n",
            "The running loss is:\n",
            "104.90327774325851\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.2081414240937669\n",
            "The running loss is:\n",
            "97.63826307374984\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.19372671244791634\n",
            "The running loss is:\n",
            "99.3914605928585\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.19720527895408432\n",
            "The running loss is:\n",
            "92.35198956588283\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.1832380745354818\n",
            "The running loss is:\n",
            "91.87536029471084\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.18229238153712468\n",
            "The running loss is:\n",
            "91.91122704208829\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.18236354571842914\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -23.292824\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -26.440331\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -153.609863\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -164.233032\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  -68.498070\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   30.482826\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  142.719116\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: ee5zrlkz \n",
            "\n",
            "wandb: Agent Starting Run: vkbb1sts with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: vkbb1sts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/vkbb1sts\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/vkbb1sts</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "150.76347963500302\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.29913388816468856\n",
            "The running loss is:\n",
            "100.61865028290777\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.1996401791327535\n",
            "The running loss is:\n",
            "87.66522326297127\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.17393893504557792\n",
            "The running loss is:\n",
            "79.37502496165689\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.15749012889217637\n",
            "The running loss is:\n",
            "81.09844061324839\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.16090960439136584\n",
            "The running loss is:\n",
            "73.06609116005711\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.14497240309535142\n",
            "The running loss is:\n",
            "72.6316595392127\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.144110435593676\n",
            "The running loss is:\n",
            "72.37297577073332\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.14359717414828038\n",
            "The running loss is:\n",
            "68.34778873156756\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.1356106919277134\n",
            "The running loss is:\n",
            "70.53053408052074\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.1399415358740491\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -25.345436\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -15.776971\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -101.608070\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -102.203835\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  -53.439491\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800  -13.487466\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   19.278763\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: vkbb1sts \n",
            "\n",
            "wandb: Agent Starting Run: zyikh3l2 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 3\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: zyikh3l2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/zyikh3l2\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/zyikh3l2</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 3\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 3\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 3\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 3\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "211.8019266948104\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.42024191804525873\n",
            "The running loss is:\n",
            "135.54967197868973\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.26894776186247965\n",
            "The running loss is:\n",
            "120.14834518544376\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.23838957378064238\n",
            "The running loss is:\n",
            "110.10778152896091\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.21846782049397007\n",
            "The running loss is:\n",
            "104.90327774325851\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.2081414240937669\n",
            "The running loss is:\n",
            "97.63826307374984\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.19372671244791634\n",
            "The running loss is:\n",
            "99.3914605928585\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.19720527895408432\n",
            "The running loss is:\n",
            "92.35198956588283\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.1832380745354818\n",
            "The running loss is:\n",
            "91.87536029471084\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.18229238153712468\n",
            "The running loss is:\n",
            "91.91122704208829\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.18236354571842914\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 3, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "2652        5592 2006-08-22 00:00:00  ...            2652  -23.292824\n",
            "2653        5593 2006-08-22 01:00:00  ...            2653  -26.440331\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -153.609863\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -164.233032\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799  -68.498070\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   30.482826\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  142.719116\n",
            "\n",
            "[153 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: zyikh3l2 \n",
            "\n",
            "wandb: Agent Starting Run: 9gv3gmht with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 9gv3gmht\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/9gv3gmht\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/9gv3gmht</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "123.77089679217897\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.24557717617495828\n",
            "The running loss is:\n",
            "74.14997040273738\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.14712295714828846\n",
            "The running loss is:\n",
            "59.28485483012628\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.11762868021850452\n",
            "The running loss is:\n",
            "54.904141225037165\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.108936788144915\n",
            "The running loss is:\n",
            "50.91604336106684\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.1010238955576723\n",
            "The running loss is:\n",
            "50.11147533985559\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.0994275304362214\n",
            "The running loss is:\n",
            "47.96242800724576\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.09516354763342413\n",
            "The running loss is:\n",
            "45.169400300248526\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.0896218259925566\n",
            "The running loss is:\n",
            "45.303195672342554\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.08988729300067967\n",
            "The running loss is:\n",
            "45.057794505904894\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.08940038592441447\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647    0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648    0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -106.880165\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -105.727196\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -116.877068\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -123.239143\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  -54.683113\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 9gv3gmht \n",
            "\n",
            "wandb: Agent Starting Run: qe28zcdg with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: qe28zcdg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/qe28zcdg\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/qe28zcdg</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "139.8953040004708\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 0\n",
            "0.2781218767404986\n",
            "The running loss is:\n",
            "92.41099839133676\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 1\n",
            "0.18371967871041106\n",
            "The running loss is:\n",
            "81.9870515151415\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 2\n",
            "0.16299612627264712\n",
            "The running loss is:\n",
            "76.69749985821545\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 3\n",
            "0.1524801190024164\n",
            "The running loss is:\n",
            "77.59441928099841\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 4\n",
            "0.15426325900794913\n",
            "The running loss is:\n",
            "76.68320445902646\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 5\n",
            "0.15245169872569872\n",
            "The running loss is:\n",
            "72.71107590617612\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 6\n",
            "0.14455482287510163\n",
            "The running loss is:\n",
            "70.56740246294066\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 7\n",
            "0.14029304664600528\n",
            "The running loss is:\n",
            "70.07262587849982\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 8\n",
            "0.1393093953846915\n",
            "The running loss is:\n",
            "70.07997756521218\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 9\n",
            "0.1393240110640401\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -44.244911\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -49.530220\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -59.219887\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -61.664665\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  53.801132\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: qe28zcdg \n",
            "\n",
            "wandb: Agent Starting Run: neqdh7xa with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: neqdh7xa\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/neqdh7xa\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/neqdh7xa</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "123.77089679217897\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 0\n",
            "0.24557717617495828\n",
            "The running loss is:\n",
            "74.14997040273738\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 1\n",
            "0.14712295714828846\n",
            "The running loss is:\n",
            "59.28485483012628\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 2\n",
            "0.11762868021850452\n",
            "The running loss is:\n",
            "54.904141225037165\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 3\n",
            "0.108936788144915\n",
            "The running loss is:\n",
            "50.91604336106684\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 4\n",
            "0.1010238955576723\n",
            "The running loss is:\n",
            "50.11147533985559\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 5\n",
            "0.0994275304362214\n",
            "The running loss is:\n",
            "47.96242800724576\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 6\n",
            "0.09516354763342413\n",
            "The running loss is:\n",
            "45.169400300248526\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 7\n",
            "0.0896218259925566\n",
            "The running loss is:\n",
            "45.303195672342554\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 8\n",
            "0.08988729300067967\n",
            "The running loss is:\n",
            "45.057794505904894\n",
            "The number of items in train is: \n",
            "504\n",
            "The loss for epoch 9\n",
            "0.08940038592441447\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index       preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647    0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648    0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649    0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650    0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651    0.000000\n",
            "...          ...                 ...  ...             ...         ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -106.880165\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -105.727196\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -116.877068\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -123.239143\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  -54.683113\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: neqdh7xa \n",
            "\n",
            "wandb: Agent Starting Run: fothoa6q with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 5\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: fothoa6q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/fothoa6q\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/fothoa6q</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 5\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 5\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 5\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 5\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "139.8953040004708\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 0\n",
            "0.2781218767404986\n",
            "The running loss is:\n",
            "92.41099839133676\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 1\n",
            "0.18371967871041106\n",
            "The running loss is:\n",
            "81.9870515151415\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 2\n",
            "0.16299612627264712\n",
            "The running loss is:\n",
            "76.69749985821545\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 3\n",
            "0.1524801190024164\n",
            "The running loss is:\n",
            "77.59441928099841\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 4\n",
            "0.15426325900794913\n",
            "The running loss is:\n",
            "76.68320445902646\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 5\n",
            "0.15245169872569872\n",
            "The running loss is:\n",
            "72.71107590617612\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 6\n",
            "0.14455482287510163\n",
            "The running loss is:\n",
            "70.56740246294066\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 7\n",
            "0.14029304664600528\n",
            "The running loss is:\n",
            "70.07262587849982\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 8\n",
            "0.1393093953846915\n",
            "The running loss is:\n",
            "70.07997756521218\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 9\n",
            "0.1393240110640401\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 5, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "2649        5589 2006-08-21 21:00:00  ...            2649   0.000000\n",
            "2650        5590 2006-08-21 22:00:00  ...            2650   0.000000\n",
            "2651        5591 2006-08-21 23:00:00  ...            2651   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -44.244911\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -49.530220\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -59.219887\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800 -61.664665\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  53.801132\n",
            "\n",
            "[155 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: fothoa6q \n",
            "\n",
            "wandb: Agent Starting Run: 5744k4s9 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: 5744k4s9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/5744k4s9\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/5744k4s9</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "124.22717230999842\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 0\n",
            "0.24697250956262112\n",
            "The running loss is:\n",
            "94.413825226482\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 1\n",
            "0.1877014418021511\n",
            "The running loss is:\n",
            "89.3096115073422\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 2\n",
            "0.1775538996169825\n",
            "The running loss is:\n",
            "79.36376452445984\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 3\n",
            "0.15778084398500963\n",
            "The running loss is:\n",
            "72.3258047675481\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 4\n",
            "0.14378887627743162\n",
            "The running loss is:\n",
            "75.5414239760139\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 5\n",
            "0.1501817574075823\n",
            "The running loss is:\n",
            "65.9851330916863\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 6\n",
            "0.13118316718029085\n",
            "The running loss is:\n",
            "59.6030374042457\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 7\n",
            "0.11849510418339104\n",
            "The running loss is:\n",
            "53.51942183615756\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 8\n",
            "0.10640044102615817\n",
            "The running loss is:\n",
            "54.225176904234104\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 9\n",
            "0.10780353261279146\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -12.088754\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -6.425675\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   1.923896\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   3.044319\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  27.620117\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: 5744k4s9 \n",
            "\n",
            "wandb: Agent Starting Run: wy3i73f6 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.001\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: wy3i73f6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/wy3i73f6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/wy3i73f6</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.001\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "178.13083760999143\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 0\n",
            "0.3541368540954104\n",
            "The running loss is:\n",
            "115.13872042251751\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 1\n",
            "0.22890401674456762\n",
            "The running loss is:\n",
            "98.40264919353649\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 2\n",
            "0.19563150933108647\n",
            "The running loss is:\n",
            "90.27932223677635\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 3\n",
            "0.17948175394985358\n",
            "The running loss is:\n",
            "90.14429173385724\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 4\n",
            "0.17921330364583946\n",
            "The running loss is:\n",
            "86.70043769944459\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 5\n",
            "0.17236667534680833\n",
            "The running loss is:\n",
            "83.56739421142265\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 6\n",
            "0.16613796065889194\n",
            "The running loss is:\n",
            "81.4917670560535\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 7\n",
            "0.1620114653201859\n",
            "The running loss is:\n",
            "78.43845805944875\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 8\n",
            "0.1559412685078504\n",
            "The running loss is:\n",
            "78.3071673035156\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 9\n",
            "0.1556802530885002\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -12.428269\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -11.582688\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -35.455238\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   4.994682\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   4.506309\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: wy3i73f6 \n",
            "\n",
            "wandb: Agent Starting Run: fcxejz18 with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 1\n",
            "wandb: Agent Started Run: fcxejz18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/fcxejz18\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/fcxejz18</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 1\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 1\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 1\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 1\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 1\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "124.22717230999842\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 0\n",
            "0.24697250956262112\n",
            "The running loss is:\n",
            "94.413825226482\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 1\n",
            "0.1877014418021511\n",
            "The running loss is:\n",
            "89.3096115073422\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 2\n",
            "0.1775538996169825\n",
            "The running loss is:\n",
            "79.36376452445984\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 3\n",
            "0.15778084398500963\n",
            "The running loss is:\n",
            "72.3258047675481\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 4\n",
            "0.14378887627743162\n",
            "The running loss is:\n",
            "75.5414239760139\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 5\n",
            "0.1501817574075823\n",
            "The running loss is:\n",
            "65.9851330916863\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 6\n",
            "0.13118316718029085\n",
            "The running loss is:\n",
            "59.6030374042457\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 7\n",
            "0.11849510418339104\n",
            "The running loss is:\n",
            "53.51942183615756\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 8\n",
            "0.10640044102615817\n",
            "The running loss is:\n",
            "54.225176904234104\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 9\n",
            "0.10780353261279146\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -12.088754\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798  -6.425675\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799   1.923896\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   3.044319\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801  27.620117\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: fcxejz18 \n",
            "\n",
            "wandb: Agent Starting Run: y0jtd5ru with config:\n",
            "\tbatch_size: 4\n",
            "\tforecast_history: 8\n",
            "\tlr: 0.01\n",
            "\tout_seq_length: 2\n",
            "wandb: Agent Started Run: y0jtd5ru\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project='pretrain-wind' passed to wandb.init when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/sweeps/wyhhj2a6</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/pranjalya/pretrain-solar/runs/y0jtd5ru\" target=\"_blank\">https://app.wandb.ai/pranjalya/pretrain-solar/runs/y0jtd5ru</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "Using Wandb config:\n",
            "wandb_version: 1\n",
            "\n",
            "GCS:\n",
            "  desc: null\n",
            "  value: false\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: torch\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 4\n",
            "dataset_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    class: default\n",
            "    forecast_history: 8\n",
            "    forecast_length: 2\n",
            "    interpolate: false\n",
            "    relevant_cols:\n",
            "    - Power(MW)\n",
            "    - month\n",
            "    - weekday\n",
            "    - hour\n",
            "    - day\n",
            "    scaler: StandardScaler\n",
            "    target_col:\n",
            "    - Power(MW)\n",
            "    test_path: selected_solar.csv\n",
            "    train_end: 2020\n",
            "    training_path: selected_solar.csv\n",
            "    valid_end: 2597\n",
            "    valid_start: 2021\n",
            "    validation_path: selected_solar.csv\n",
            "forecast_history:\n",
            "  desc: null\n",
            "  value: 8\n",
            "forward_params:\n",
            "  desc: null\n",
            "  value: {}\n",
            "inference_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    dataset_params:\n",
            "      file_path: selected_solar.csv\n",
            "      forecast_history: 8\n",
            "      forecast_length: 2\n",
            "      interpolate_param: false\n",
            "      relevant_cols:\n",
            "      - Power(MW)\n",
            "      - month\n",
            "      - weekday\n",
            "      - hour\n",
            "      - day\n",
            "      scaling: StandardScaler\n",
            "      target_col:\n",
            "      - Power(MW)\n",
            "    datetime_start: '2006-08-22'\n",
            "    decoder_params:\n",
            "      decoder_function: simple_decode\n",
            "      unsqueeze_dim: 1\n",
            "    hours_to_forecast: 150\n",
            "    test_csv_path: selected_solar.csv\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.01\n",
            "metrics:\n",
            "  desc: null\n",
            "  value:\n",
            "  - MSE\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: MultiAttnHeadSimple\n",
            "model_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    forecast_length: 2\n",
            "    number_time_series: 5\n",
            "    output_seq_len: 2\n",
            "    seq_len: 8\n",
            "model_type:\n",
            "  desc: null\n",
            "  value: PyTorch\n",
            "out_seq_length:\n",
            "  desc: null\n",
            "  value: 2\n",
            "sweep:\n",
            "  desc: null\n",
            "  value: true\n",
            "training_params:\n",
            "  desc: null\n",
            "  value:\n",
            "    batch_size: 4\n",
            "    criterion: MSE\n",
            "    epochs: 10\n",
            "    lr: 0.01\n",
            "    optim_params: {}\n",
            "    optimizer: Adam\n",
            "wandb:\n",
            "  desc: null\n",
            "  value: false\n",
            "\n",
            "Torch is using cpu\n",
            "The running loss is:\n",
            "178.13083760999143\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 0\n",
            "0.3541368540954104\n",
            "The running loss is:\n",
            "115.13872042251751\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 1\n",
            "0.22890401674456762\n",
            "The running loss is:\n",
            "98.40264919353649\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 2\n",
            "0.19563150933108647\n",
            "The running loss is:\n",
            "90.27932223677635\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 3\n",
            "0.17948175394985358\n",
            "The running loss is:\n",
            "90.14429173385724\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 4\n",
            "0.17921330364583946\n",
            "The running loss is:\n",
            "86.70043769944459\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 5\n",
            "0.17236667534680833\n",
            "The running loss is:\n",
            "83.56739421142265\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 6\n",
            "0.16613796065889194\n",
            "The running loss is:\n",
            "81.4917670560535\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 7\n",
            "0.1620114653201859\n",
            "The running loss is:\n",
            "78.43845805944875\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 8\n",
            "0.1559412685078504\n",
            "The running loss is:\n",
            "78.3071673035156\n",
            "The number of items in train is: \n",
            "503\n",
            "The loss for epoch 9\n",
            "0.1556802530885002\n",
            "interpolate should be below\n",
            "Now loading and scaling selected_solar.csv\n",
            "CSV Path below\n",
            "selected_solar.csv\n",
            "torch.Size([1, 8, 5])\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'] = 0\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor.numpy().tolist()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:1042: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_with(key, value)\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df, end_tensor, forecast_history, junk, test_data = infer_on_torch_model(model, **inference_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150])\n",
            "test_data scale\n",
            "Un-transforming data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/evaluator.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['preds'][history_length:] = end_tensor_list\n",
            "/content/github_aistream-peelout_flow-forecast/flood_forecast/trainer.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_acc = evaluate_model(trained_model, model_type, params[\"dataset_params\"][\"target_col\"], params[\"metrics\"], params[\"inference_params\"], {})\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Current historical dataframe\n",
            "      Unnamed: 0            datetime  ...  original_index      preds\n",
            "2644        5584 2006-08-21 16:00:00  ...            2644   0.000000\n",
            "2645        5585 2006-08-21 17:00:00  ...            2645   0.000000\n",
            "2646        5586 2006-08-21 18:00:00  ...            2646   0.000000\n",
            "2647        5587 2006-08-21 19:00:00  ...            2647   0.000000\n",
            "2648        5588 2006-08-21 20:00:00  ...            2648   0.000000\n",
            "...          ...                 ...  ...             ...        ...\n",
            "2797        5737 2006-08-28 01:00:00  ...            2797 -12.428269\n",
            "2798        5738 2006-08-28 02:00:00  ...            2798 -11.582688\n",
            "2799        5739 2006-08-28 03:00:00  ...            2799 -35.455238\n",
            "2800        5740 2006-08-28 04:00:00  ...            2800   4.994682\n",
            "2801        5741 2006-08-28 05:00:00  ...            2801   4.506309\n",
            "\n",
            "[158 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mplexporter/exporter.py:84: UserWarning:\n",
            "\n",
            "Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
            "\n",
            "\n",
            "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Finished Run: y0jtd5ru \n",
            "\n",
            "Copying file://model_save/11_May_202006_23PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_12PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_23PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_26PM_model.pth [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying file://model_save/11_May_202006_38PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_18PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_16PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202005_57PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_21PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_26PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_12PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_19PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_40PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_19PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_22PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_30PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_17PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_07PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_29PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_33PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_42PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_08PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_10PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_02PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_07PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_13PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_37PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_40PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_00PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_28PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_04PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_25PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_24PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_10PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_34PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_13PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_02PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_18PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_34PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_32PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_20PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_14PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_44PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202005_57PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_27PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_32PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202005_59PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_43PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_31PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_37PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_15PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_03PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_11PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_42PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_06PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_28PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_27PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_29PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_36PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_38PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_33PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_36PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_25PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_08PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_03PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_30PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_17PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_09PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_35PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_14PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_09PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_15PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_44PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_43PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_31PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_21PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_00PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202005_59PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_20PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_05PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_35PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_39PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_39PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_04PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_41PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_22PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_11PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_16PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_41PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_24PM.json [Content-Type=application/json]...\n",
            "Copying file://model_save/11_May_202006_05PM_model.pth [Content-Type=application/octet-stream]...\n",
            "Copying file://model_save/11_May_202006_06PM_model.pth [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "\n",
            "Operation completed over 92 objects/124.2 MiB.                                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg3Bq_3YAQxY",
        "colab_type": "text"
      },
      "source": [
        "Similarly, this cell ran too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx810NKkAU0_",
        "colab_type": "text"
      },
      "source": [
        "**Check out the sweeps here :**  *https://app.wandb.ai/pranjalya/pretrain-solar*"
      ]
    }
  ]
}