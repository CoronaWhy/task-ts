{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "DIR='C:/Users/Cafral/Desktop/ICLR/favorita-grocery-sales-forecasting/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holidays_events.csv',\n",
       " 'items.csv',\n",
       " 'oil.csv',\n",
       " 'sample_submission.csv',\n",
       " 'stores.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'transactions.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#loading the data\n",
    "training = pd.read_csv(os.path.join(DIR,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DIR,'test.csv'))\n",
    "holidays_events = pd.read_csv(os.path.join(DIR,'holidays_events.csv'))\n",
    "oil = pd.read_csv(os.path.join(DIR,'oil.csv'))\n",
    "stores = pd.read_csv(os.path.join(DIR,'stores.csv'))\n",
    "transactions = pd.read_csv(os.path.join(DIR,'transactions.csv'))\n",
    "items =pd.read_csv(os.path.join(DIR,'items.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_nbr', 'family', 'class', 'perishable'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['date'] = pd.to_datetime(training['date'] )\n",
    "holidays_events['date'] = pd.to_datetime(holidays_events['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_nbr    125497040\n",
       "item_nbr     125497040\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ids_to_keep = ~training[['store_nbr', 'item_nbr']].isna()\n",
    "_ids_to_keep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125497040, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.drop_duplicates(inplace=True)\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21828208, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figuring out the embeddings\n",
    "embeddings_df = training.merge(holidays_events,on=['date'])\n",
    "embeddings_df = embeddings_df.merge(stores,on=['store_nbr'])\n",
    "embeddings_df = embeddings_df.merge(items,on=['item_nbr'])\n",
    "embeddings_df.rename(columns={'type_x':'holiday_type','type_y':'store_type'},inplace=True)\n",
    "embeddings_df.shape\n",
    "\n",
    "group_by_cols = ['holiday_type',\n",
    "                 'locale',\n",
    "                 'locale_name',\n",
    "                 'description',\n",
    "                 'transferred',\n",
    "                 'city',\n",
    "                 'state',\n",
    "                 'store_type',\n",
    "                 'cluster',\n",
    "                 'family',\n",
    "                 'class',\n",
    "                 'perishable']\n",
    "\n",
    "group_ids = embeddings_df.groupby(by=group_by_cols,as_index=False).ngroup()\n",
    "embeddings_df['metadata_id'] = group_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010343"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_ids.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21828208, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assigning embeddings id to non-static training data\n",
    "training = training.merge(embeddings_df[['date','store_nbr','item_nbr','metadata_id']],on = ['date','store_nbr','item_nbr'])\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15204171, 8)\n",
      "(15202453, 9)\n"
     ]
    }
   ],
   "source": [
    "# they use all the data so merging : how to incorporate meta data?\n",
    "training = training.merge(oil,on=['date'])\n",
    "print(training.shape)\n",
    "training = training.merge(transactions,on=['date', 'store_nbr'])\n",
    "print(training.shape)\n",
    "\n",
    "#training = training.merge(holidays_events,on=['date'])\n",
    "#print(training.shape)\n",
    "#training = training.merge(stores,on=['store_nbr'])\n",
    "#print(training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15202453, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processing the data : for details refer to APPENDIX of https://arxiv.org/pdf/1912.09363.pdf\n",
    "\n",
    "# 1. We treat each product number-store number pair as a separate entity, with over 135k entities in total. \n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training set is made up of 450k samples taken between 2015-01-01 to 2015-12-01\n",
    "train_period_mask = ((training['date']>=pd.to_datetime('2015-01-01')) & (training['date']<=pd.to_datetime('2015-12-01')))\n",
    "training_paper = training[train_period_mask]\n",
    "\n",
    "# validation set of 50k samples from the 30 days after the training set,\n",
    "end_val_period = training['date'][(training['date']>pd.to_datetime('2015-12-01'))].unique()[30]\n",
    "val_period_mask = ((training['date']>pd.to_datetime('2015-12-01')) & \\\n",
    "                   (training['date']<=end_val_period))\n",
    "validation_paper = training[val_period_mask]\n",
    "\n",
    "# test set of all entities over the 30-day horizon following the validation set.\n",
    "end_test_period = training['date'][(training['date']>end_val_period)].unique()[30]\n",
    "test_period_mask = (((training['date']>end_val_period)) & (training['date']<=end_test_period))\n",
    "test_paper = training[test_period_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2487480, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_paper.shape #doesn't add up with nos in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3121416, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_paper.shape  #doesn't add up with nos in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3251181, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paper.shape  #doesn't add up with nos in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133656, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_paper[['store_nbr', 'item_nbr']].drop_duplicates().shape #around the no. mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139223, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_paper[['store_nbr', 'item_nbr']].drop_duplicates().shape  #around the no. mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155702, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paper[['store_nbr', 'item_nbr']].drop_duplicates().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Cafral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# We include an additional ’open’ flag to denote whether data is present on a given day.\n",
    "training_paper['open'] = training_paper.isna().apply(lambda x: all(x), axis=1)\n",
    "validation_paper['open'] = validation_paper.isna().apply(lambda x: all(x), axis=1)\n",
    "test_paper['open'] = test_paper.isna().apply(lambda x: all(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is resampled at regular daily intervals (????????????????????????),\n",
    "#imputing any missing days using the last available observation\n",
    "training_paper = training_paper.ffill()\n",
    "validation_paper = validation_paper.ffill()\n",
    "test_paper = test_paper.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cafral\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# We apply a log-transform on the sales data, and adopt z-score normalization across all entities\n",
    "training_paper['unit_sales'] = np.log(training_paper['unit_sales'])\n",
    "validation_paper['unit_sales'] = np.log(validation_paper['unit_sales'])\n",
    "test_paper['unit_sales'] =np.log(test_paper['unit_sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>metadata_id</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>transactions</th>\n",
       "      <th>open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4352619</th>\n",
       "      <td>38594264</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>False</td>\n",
       "      <td>865940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352620</th>\n",
       "      <td>38594265</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105575</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>False</td>\n",
       "      <td>866042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352621</th>\n",
       "      <td>38594266</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>866057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352622</th>\n",
       "      <td>38594267</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108698</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "      <td>865996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352623</th>\n",
       "      <td>38594268</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108786</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>False</td>\n",
       "      <td>865967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840094</th>\n",
       "      <td>63590977</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>54</td>\n",
       "      <td>2026650</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "      <td>142009</td>\n",
       "      <td>40.43</td>\n",
       "      <td>835</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840095</th>\n",
       "      <td>63590978</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>54</td>\n",
       "      <td>2026801</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "      <td>142024</td>\n",
       "      <td>40.43</td>\n",
       "      <td>835</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840096</th>\n",
       "      <td>63590979</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>54</td>\n",
       "      <td>2026858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>142009</td>\n",
       "      <td>40.43</td>\n",
       "      <td>835</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840097</th>\n",
       "      <td>63590980</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>54</td>\n",
       "      <td>2026983</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "      <td>142009</td>\n",
       "      <td>40.43</td>\n",
       "      <td>835</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840098</th>\n",
       "      <td>63590981</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>54</td>\n",
       "      <td>2027090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>142024</td>\n",
       "      <td>40.43</td>\n",
       "      <td>835</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2487480 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       date  store_nbr  item_nbr  unit_sales onpromotion  \\\n",
       "4352619  38594264 2015-01-01         25    103665    2.484907       False   \n",
       "4352620  38594265 2015-01-01         25    105575    3.135494       False   \n",
       "4352621  38594266 2015-01-01         25    108634    0.000000       False   \n",
       "4352622  38594267 2015-01-01         25    108698    1.791759       False   \n",
       "4352623  38594268 2015-01-01         25    108786    1.791759       False   \n",
       "...           ...        ...        ...       ...         ...         ...   \n",
       "6840094  63590977 2015-11-30         54   2026650    0.693147       False   \n",
       "6840095  63590978 2015-11-30         54   2026801    1.609438       False   \n",
       "6840096  63590979 2015-11-30         54   2026858    0.000000       False   \n",
       "6840097  63590980 2015-11-30         54   2026983    1.386294       False   \n",
       "6840098  63590981 2015-11-30         54   2027090    0.000000       False   \n",
       "\n",
       "         metadata_id  dcoilwtico  transactions   open  \n",
       "4352619       865940         NaN          2202  False  \n",
       "4352620       866042         NaN          2202  False  \n",
       "4352621       866057         NaN          2202  False  \n",
       "4352622       865996         NaN          2202  False  \n",
       "4352623       865967         NaN          2202  False  \n",
       "...              ...         ...           ...    ...  \n",
       "6840094       142009       40.43           835  False  \n",
       "6840095       142024       40.43           835  False  \n",
       "6840096       142009       40.43           835  False  \n",
       "6840097       142009       40.43           835  False  \n",
       "6840098       142024       40.43           835  False  \n",
       "\n",
       "[2487480 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We consider log sales, transactions, oil to be real-valued and the rest to be categorical - does encoding things matter in this case?\n",
    "\n",
    "#The onpromotion column tells whether that item_nbr was on promotion for a specified date and store_nbr.\n",
    "le_onpromotion = LabelEncoder()\n",
    "le_open = LabelEncoder()\n",
    "training_paper['onpromotion'] = le_onpromotion.fit_transform(training_paper['onpromotion'].values)\n",
    "training_paper['open'] = le_open.fit_transform(training_paper['open'].values)\n",
    "validation_paper['onpromotion'] = le_onpromotion.transform(validation_paper['onpromotion'].values)\n",
    "validation_paper['open'] = le_open.transform(validation_paper['open'].values)\n",
    "test_paper['onpromotion'] = le_onpromotion.transform(test_paper['onpromotion'].values)\n",
    "test_paper['open'] = le_open.transform(test_paper['open'].values)\n",
    "\n",
    "# QESTION : should we encode the embedings too?\n",
    "\n",
    "# to do encode these or not?\n",
    "# training_paper['item_nbr'] = le.fit_transform(training_paper['item_nbr'].values)\n",
    "# training_paper['store_nbr'] = le.fit_transform(training_paper['store_nbr'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR='C:/Users/Cafral/Desktop/ICLR/favorita-grocery-sales-forecasting/final_dfs'\n",
    "training_paper.to_csv('training_data.csv',index=False)\n",
    "validation_paper.to_csv('validation_paper.csv',index=False)\n",
    "test_paper.to_csv('test_paper.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adopt z-score normalization across all entities - to be done in flow forecast pipeline : std scaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
